{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c1ef1f-2372-44c0-9703-b8ac660cce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4441684d-fa5d-4f8d-9967-84753fd5a4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time \n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import umap.umap_ as umap\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
    "from node2vec import Node2Vec\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import spektral\n",
    "from spektral.layers import GCNConv, GATConv\n",
    "from spektral.layers import GraphSageConv\n",
    "from spektral.data import Graph, Dataset, BatchLoader\n",
    "from scipy.sparse import csr_matrix\n",
    "from spektral.datasets import Cora\n",
    "from torch_geometric.nn import DeepGraphInfomax, VGAE\n",
    "from torch_geometric.utils import from_networkx\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import normalize\n",
    "from joblib import Parallel, delayed\n",
    "from torch_geometric.nn import GCNConv as PyG_GCNConv, VGAE as PyG_VGAE\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46e18457-6dbb-4928-adad-4b279400977c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 46\n",
    "\n",
    "# Set seed for Python's built-in random module\n",
    "random.seed(SEED)\n",
    "\n",
    "# Set seed for NumPy\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Set seed for PyTorch\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b95802d-543f-4b3e-803a-cdbdb518595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom Dataset for the graph\n",
    "class CoraDataset(Dataset):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        data = Cora()  # Load the dataset\n",
    "        graph = data.graphs[0]  # Access the first graph in the dataset\n",
    "        return [Graph(x=graph.x, a=graph.a, y=graph.y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90c18215-d57c-47a9-957d-5f98fa330e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimensionality=150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b67b75-8102-41b3-b7d9-faac9a95ca1d",
   "metadata": {},
   "source": [
    "## Extracting modularity embedding and using it for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e46cf19-a136-404f-9c2a-a2d8404b874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian Eigenmaps Embedding\n",
    "def deepwalk_embedding(G, k=2, walk_length=10, num_walks=80, workers=4):\n",
    "    node2vec = Node2Vec(G, dimensions=k, walk_length=walk_length, num_walks=num_walks, workers=workers)\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "    return np.array([model.wv[str(node)] for node in G.nodes()])\n",
    "\n",
    "# Node2Vec Embedding\n",
    "def node2vec_embedding(G, k=2, seed=SEED):\n",
    "    node2vec = Node2Vec(G, dimensions=k, walk_length=10, num_walks=100, workers=2, seed=seed)\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "    return np.array([model.wv[str(node)] for node in G.nodes()])\n",
    "\n",
    "\n",
    "# VGAE Embedding \n",
    "class VGAEEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = PyG_GCNConv(in_channels, 2 * out_channels)  # Use PyG_GCNConv\n",
    "        self.conv_mu = PyG_GCNConv(2 * out_channels, out_channels)  # Separate layer for mu\n",
    "        self.conv_logstd = PyG_GCNConv(2 * out_channels, out_channels)  # Separate layer for logstd\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = torch.relu(self.conv1(x, edge_index))\n",
    "        mu = self.conv_mu(x, edge_index)\n",
    "        logstd = self.conv_logstd(x, edge_index)\n",
    "        return mu, logstd\n",
    "\n",
    "def vgae_embedding(data, k=128):\n",
    "    # Use one-hot encoded node IDs as features\n",
    "    num_nodes = data.num_nodes\n",
    "    x = torch.eye(num_nodes)  # One-hot encoded node features\n",
    "\n",
    "    in_channels = x.shape[1]  # Feature dimension is equal to the number of nodes\n",
    "    model = PyG_VGAE(VGAEEncoder(in_channels, k))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    for _ in tqdm(range(200)):\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(x, data.edge_index)  # Use one-hot encoded features\n",
    "        loss = model.recon_loss(z, data.edge_index) + (1 / data.num_nodes) * model.kl_loss()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model.encode(x, data.edge_index).detach().numpy()\n",
    "\n",
    "# DGI Embedding\n",
    "def dgi_embedding(data, k=128):\n",
    "    class GCNEncoder(torch.nn.Module):\n",
    "        def __init__(self, in_channels, out_channels):\n",
    "            super().__init__()\n",
    "            self.conv1 = PyG_GCNConv(in_channels, 2 * out_channels)  # Use PyG_GCNConv\n",
    "            self.conv2 = PyG_GCNConv(2 * out_channels, out_channels)  # Use PyG_GCNConv\n",
    "\n",
    "        def forward(self, x, edge_index):\n",
    "            x = torch.relu(self.conv1(x, edge_index))\n",
    "            return self.conv2(x, edge_index)\n",
    "\n",
    "    # Use one-hot encoded node IDs as features\n",
    "    num_nodes = data.num_nodes\n",
    "    x = torch.eye(num_nodes)  # One-hot encoded node features\n",
    "\n",
    "    in_channels = x.shape[1]  # Feature dimension is equal to the number of nodes\n",
    "    model = DeepGraphInfomax(\n",
    "        hidden_channels=k,\n",
    "        encoder=GCNEncoder(in_channels, k),\n",
    "        summary=lambda z, *args, **kwargs: z.mean(dim=0),  # Ensure `summary` only takes `z`\n",
    "        corruption=lambda x, edge_index: (x[torch.randperm(x.size(0))], edge_index)  # Correct corruption function\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    for _ in tqdm(range(200)):\n",
    "        optimizer.zero_grad()\n",
    "        pos_z, neg_z, summary = model(x, data.edge_index)  # Use one-hot encoded features\n",
    "        loss = model.loss(pos_z, neg_z, summary)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return pos_z.detach().numpy()\n",
    "\n",
    "\n",
    "# Unsupervised gradient ascent for modularity maximization\n",
    "def gradient_ascent_modularity_unsupervised(G, k=2, eta=0.01, iterations=1000, seed=SEED):\n",
    "    np.random.seed(seed)  # Ensure deterministic initialization\n",
    "\n",
    "    A = nx.to_numpy_array(G)\n",
    "    l = A.sum(axis=1)\n",
    "    m = np.sum(l) / 2\n",
    "    B = A - np.outer(l, l) / (2 * m)\n",
    "    n = B.shape[0]\n",
    "\n",
    "    S = np.random.randn(n, k)  # Random Initialization\n",
    "    S, _ = np.linalg.qr(S)  # Ensure initial orthonormality\n",
    "\n",
    "    for i in tqdm(range(iterations), desc=\"Gradient Ascent Progress\"):\n",
    "        grad = (1 / (2 * m)) * B @ S\n",
    "        S += eta * grad\n",
    "        S, _ = np.linalg.qr(S)  # Orthonormalize using QR decomposition\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08173103-6488-4269-b6a4-517a08cd583c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_labeled_random_walks(G, label_mask, labels, num_walks, walk_length, walk_length_labelled=3):\n",
    "    walks = {node: [] for node in G.nodes()}\n",
    "    for node in G.nodes():\n",
    "        for _ in range(num_walks):\n",
    "            walk = [node]\n",
    "            labeled_count = 0\n",
    "            for _ in range(walk_length - 1):\n",
    "                cur = walk[-1]\n",
    "                neighbors = list(G.neighbors(cur))\n",
    "                if not neighbors:\n",
    "                    break\n",
    "                labeled_neighbors = [n for n in neighbors if label_mask[n]]\n",
    "                if labeled_neighbors and labeled_count < walk_length_labelled:\n",
    "                    next_node = random.choice(labeled_neighbors)\n",
    "                    labeled_count += 1\n",
    "                else:\n",
    "                    next_node = random.choice(neighbors)\n",
    "                walk.append(next_node)\n",
    "            walks[node].extend([n for n in walk if label_mask[n]])\n",
    "    return walks\n",
    "\n",
    "def compute_attention_weights(S, labeled_nodes):\n",
    "    weights = {}\n",
    "    for node, labeled in labeled_nodes.items():\n",
    "        if labeled:\n",
    "            similarities = {n: np.dot(S[node], S[n]) for n in labeled}\n",
    "            exp_sims = {n: np.exp(sim) for n, sim in similarities.items()}\n",
    "            total = sum(exp_sims.values())\n",
    "            weights[node] = {n: exp_sims[n] / total for n in labeled}\n",
    "    return weights\n",
    "\n",
    "def semi_supervised_gradient_ascent_modularity(G, labels, label_mask, k=2, eta=0.01, lambda_supervised=1.0, \n",
    "                                                      lambda_semi=2.0, iterations=5000, initialization='random',\n",
    "                                                      num_walks=10, walk_length=5, walk_length_labelled=3):\n",
    "    # Convert graph to sparse adjacency matrix\n",
    "    A = csr_matrix(nx.to_scipy_sparse_array(G, format='csr'))\n",
    "    degrees = np.array(A.sum(axis=1)).flatten()\n",
    "    m = G.number_of_edges()\n",
    "    n = A.shape[0]\n",
    "\n",
    "    # Initialize embeddings\n",
    "    if initialization == 'random':\n",
    "        S = np.random.randn(n, k)\n",
    "    S, _ = np.linalg.qr(S)\n",
    "\n",
    "    # Compute labeled random walks and attention weights\n",
    "    labeled_walks = perform_labeled_random_walks(G, label_mask, labels, num_walks, walk_length, walk_length_labelled)\n",
    "    attention_weights = compute_attention_weights(S, labeled_walks)\n",
    "\n",
    "    for _ in tqdm(range(iterations), desc=\"Gradient Ascent with Linear Modularity\"):\n",
    "        # Compute modularity gradient using linear approximation\n",
    "        neighbor_agg = A @ S  # Efficient aggregation of neighbor embeddings\n",
    "        global_correction = (degrees[:, None] / (2 * m)) * S.sum(axis=0)\n",
    "        grad_modularity = (1 / (2 * m)) * (neighbor_agg - global_correction)\n",
    "\n",
    "        # Compute supervised gradient\n",
    "        grad_supervised = np.zeros_like(S)\n",
    "        unique_labels = np.unique(labels[label_mask])\n",
    "        for label in unique_labels:\n",
    "            mask = (labels == label) & label_mask\n",
    "            mean_embedding = np.mean(S[mask], axis=0, keepdims=True)\n",
    "            grad_supervised[mask] = S[mask] - mean_embedding\n",
    "\n",
    "        # Compute semi-supervised gradient using adaptive attention\n",
    "        grad_semi_supervised = np.zeros_like(S)\n",
    "        for i in range(n):\n",
    "            if not label_mask[i] and i in attention_weights:\n",
    "                weighted_embedding = sum(weight * S[n] for n, weight in attention_weights[i].items())\n",
    "                grad_semi_supervised[i] = S[i] - weighted_embedding\n",
    "\n",
    "        # Update embeddings\n",
    "        grad_total = grad_modularity - lambda_supervised * grad_supervised - lambda_semi * grad_semi_supervised\n",
    "        S += eta * grad_total\n",
    "        S, _ = np.linalg.qr(S)\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d1fa1ef-526c-4ecb-a4e5-6c344f0412c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_networkx(A):\n",
    "    return nx.from_scipy_sparse_array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7fbba5b-3f7c-4821-9af5-d9d6e982b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CoraDataset()\n",
    "ground_truth_labels = dataset[0].y\n",
    "labels=np.argmax(ground_truth_labels,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c92de7a7-bab8-4ee8-9601-e4f95f0386e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_be_masked=np.random.choice(np.arange(len(labels)),int(len(labels)*.7),replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0cf50e3-56e5-4187-b4ef-9f05cd3bc76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_labels=[]\n",
    "for i in np.arange(len(labels)):\n",
    "    if i in labels_to_be_masked:\n",
    "        masked_labels.append(-1)\n",
    "    else:\n",
    "        masked_labels.append(labels[i])\n",
    "masked_labels=np.array(masked_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77562c2a-8c15-4b37-a4d3-674776a0edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask = masked_labels != -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "517544ea-62e6-495c-bce9-6733a551c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[0].x\n",
    "A = dataset[0].a\n",
    "G = convert_to_networkx(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17de4d41-86a4-40c3-bf4d-217511591a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency Matrix Shape: (2708, 2708)\n",
      "Graph Nodes: 2708\n",
      "Graph Edges: 5278\n"
     ]
    }
   ],
   "source": [
    "print(\"Adjacency Matrix Shape:\", A.shape)\n",
    "print(\"Graph Nodes:\", G.number_of_nodes())\n",
    "print(\"Graph Edges:\", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0346f826-0826-4b89-8328-054b3295fdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert your preprocessed data into a PyTorch Geometric Data object\n",
    "X_py = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float),  # Node features\n",
    "    edge_index=torch.tensor(np.array(A.nonzero()), dtype=torch.long),  # Edge indices\n",
    "    y=torch.tensor(labels, dtype=torch.long)  # Labels\n",
    ")\n",
    "\n",
    "# Ensure edge_index is in the correct shape (2, num_edges)\n",
    "X_py.edge_index = X_py.edge_index.to(torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b4f8f4-20eb-4804-a2e7-b04c6e80d08d",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49cada09-7de5-438e-b980-7d5e703615d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing DeepWalk embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 2708/2708 [00:00<00:00, 3713.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepWalk embedding computed in 96.89 seconds.\n",
      "Computing VGAE embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:14<00:00, 14.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGAE embedding computed in 14.26 seconds.\n",
      "Computing DGI embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:19<00:00, 10.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGI embedding computed in 19.35 seconds.\n",
      "Computing Modularity embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gradient Ascent with Linear Modularity: 100%|██████████| 200/200 [00:26<00:00,  7.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modularity embedding computed in 26.95 seconds.\n",
      "Computing Node2Vec embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 2708/2708 [00:01<00:00, 2494.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node2Vec embedding computed in 143.57 seconds.\n",
      "Generating Random embedding...\n",
      "Random embedding generated in 0.02 seconds.\n",
      "All embeddings computed and stored in the dictionary successfully.\n",
      "\n",
      "Execution times saved to 'embedding_execution_times.csv'.\n",
      "        Model  Time (seconds)\n",
      "0    DeepWalk       96.889719\n",
      "1        VGAE       14.257295\n",
      "2         DGI       19.349364\n",
      "3  Modularity       26.949443\n",
      "4    Node2Vec      143.572014\n",
      "5      Random        0.015800\n"
     ]
    }
   ],
   "source": [
    "# Dictionary for embeddings\n",
    "embedding_dict = {}\n",
    "execution_times = []  # List to store execution times\n",
    "\n",
    "# Compute embeddings and store them with time tracking\n",
    "def record_time(model_name, func, *args, **kwargs):\n",
    "    print(f\"Computing {model_name} embedding...\")\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    execution_times.append((model_name, elapsed_time))\n",
    "    print(f\"{model_name} embedding computed in {elapsed_time:.2f} seconds.\")\n",
    "    return result\n",
    "\n",
    "X_deepwalk = record_time(\"DeepWalk\", deepwalk_embedding, G, k=embedding_dimensionality)\n",
    "X_deepwalk = tf.convert_to_tensor(X_deepwalk, dtype=tf.float32)\n",
    "embedding_dict['deepwalk'] = X_deepwalk\n",
    "\n",
    "X_vgae = record_time(\"VGAE\", vgae_embedding, X_py, k=embedding_dimensionality)\n",
    "embedding_dict['vgae'] = X_vgae\n",
    "\n",
    "X_dgi = record_time(\"DGI\", dgi_embedding, X_py, k=embedding_dimensionality)\n",
    "embedding_dict['dgi'] = X_dgi\n",
    "\n",
    "X_modularity = record_time(\"Modularity\", semi_supervised_gradient_ascent_modularity,\n",
    "                           G, labels, label_mask, k=embedding_dimensionality,\n",
    "                           eta=0.05, lambda_supervised=1.0, lambda_semi=2.0, iterations=200, initialization='random')\n",
    "embedding_dict['modularity'] = X_modularity\n",
    "\n",
    "X_node2vec = record_time(\"Node2Vec\", node2vec_embedding, G, k=embedding_dimensionality)\n",
    "X_node2vec = tf.convert_to_tensor(X_node2vec, dtype=tf.float32)\n",
    "embedding_dict['node2vec'] = X_node2vec\n",
    "\n",
    "# Generate random embedding\n",
    "print(\"Generating Random embedding...\")\n",
    "start_time = time.time()\n",
    "shape = (len(ground_truth_labels), embedding_dimensionality)\n",
    "X_random = np.random.randn(*shape)\n",
    "X_random = tf.convert_to_tensor(X_random, dtype=tf.float32)\n",
    "end_time = time.time()\n",
    "execution_times.append((\"Random\", end_time - start_time))\n",
    "print(f\"Random embedding generated in {end_time - start_time:.2f} seconds.\")\n",
    "embedding_dict['random'] = X_random\n",
    "\n",
    "# Use original node features as 'given' embedding\n",
    "embedding_dict['given'] = X\n",
    "\n",
    "print(\"All embeddings computed and stored in the dictionary successfully.\")\n",
    "\n",
    "# Store execution times in a DataFrame and save\n",
    "execution_df = pd.DataFrame(execution_times, columns=[\"Model\", \"Time (seconds)\"])\n",
    "execution_df.to_csv(\"./cora_analysis_results/embedding_execution_times_cora_\"+str(SEED)+\".csv\", index=False)\n",
    "\n",
    "print(\"\\nExecution times saved to 'embedding_execution_times.csv'.\")\n",
    "print(execution_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a98e7ea-fd83-440b-a479-bed7c46185a4",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7297774-e5c4-4b87-9cc9-cab07deb7978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_all_embeddings(all_embeddings, labels, label_mask):\n",
    "    \"\"\"\n",
    "    Visualize all embeddings in a grid with 4 columns per row using UMAP.\n",
    "\n",
    "    Parameters:\n",
    "    - all_embeddings: Dictionary where keys are embedding methods, and values are embeddings.\n",
    "    - labels: Labels (numpy array of shape [n_nodes]).\n",
    "    - label_mask: Boolean array indicating known labels (True for known, False for unknown).\n",
    "    \"\"\"\n",
    "    num_embeddings = len(all_embeddings)\n",
    "    num_rows = (num_embeddings + 3) // 4  # Ensure enough rows for all embeddings\n",
    "    fig, axes = plt.subplots(num_rows, 4, figsize=(8.27, 11.69))  # A4 size\n",
    "\n",
    "    for i, (embedding_type, embedding) in tqdm(enumerate(all_embeddings.items()), \n",
    "                                               total=num_embeddings, desc=\"Visualizing embeddings\"):\n",
    "        row, col = divmod(i, 4)\n",
    "        ax = axes[row, col] if num_rows > 1 else axes[col]  # Adjust for single-row case\n",
    "\n",
    "        # Ensure embedding is a NumPy array\n",
    "        if isinstance(embedding, tf.Tensor):\n",
    "            embedding = embedding.numpy()\n",
    "\n",
    "        # Reduce dimensionality using UMAP\n",
    "        reducer = umap.UMAP(n_components=2)\n",
    "        embedding_2d = reducer.fit_transform(embedding)\n",
    "\n",
    "        # Known labels\n",
    "        ax.scatter(embedding_2d[label_mask, 0], embedding_2d[label_mask, 1], \n",
    "                   c=labels[label_mask], cmap=\"Set1\", s=3, alpha=0.7, label=\"Known Labels\",\n",
    "                   edgecolors='none')\n",
    "\n",
    "        # Unknown labels\n",
    "        ax.scatter(embedding_2d[~label_mask, 0], embedding_2d[~label_mask, 1], \n",
    "                   c=labels[~label_mask], cmap=\"Set1\", s=5, alpha=0.7, \n",
    "                   label=\"Unknown Labels\", edgecolors='black', linewidths=0.2)\n",
    "\n",
    "        # Title with smaller font size\n",
    "        ax.set_title(embedding_type.upper(), fontsize=8, pad=2)\n",
    "\n",
    "        # Remove axis labels, ticks, and frames\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "    # Remove empty subplots if num_embeddings is not a multiple of 4\n",
    "    for j in range(i + 1, num_rows * 4):\n",
    "        row, col = divmod(j, 4)\n",
    "        fig.delaxes(axes[row, col])\n",
    "\n",
    "    plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05, wspace=0.2, hspace=0.2)  # Adjust margins\n",
    "    save_path = \"./cora_analysis_results/embedding_grid_plot_cora.png\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Visualization saved to {save_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73add6f8-ad97-49f5-8f66-88df3b717390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance using accuracy, F1-score, and confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.array): Ground truth labels (integers).\n",
    "        predicted_labels (np.array): Predicted labels (integers).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing accuracy, F1-score, and confusion matrix.\n",
    "    \"\"\"\n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    \n",
    "    # Compute F1-score (macro-averaged)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    #\n",
    "    print(cm)\n",
    "    \n",
    "    # Return results as a dictionary\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc2b387-1e6d-49a3-b28f-23f59c1c789c",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f934d79-76c2-4d0e-81f4-486a1dc34d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(tf.keras.Model):\n",
    "    def __init__(self, n_labels, seed=42):  # Use an explicit seed\n",
    "        super().__init__()\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=seed)  # Define initializer\n",
    "        \n",
    "        self.conv1 = GCNConv(16, activation='relu', kernel_initializer=initializer)\n",
    "        self.conv2 = GCNConv(n_labels, activation='softmax', kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        intermediate_embeddings = self.conv1([x, a])  # Store intermediate embeddings\n",
    "        x = self.conv2([intermediate_embeddings, a])\n",
    "        return x, intermediate_embeddings  # Return both final output and intermediate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75c02975-3867-49ee-bfd3-f74cd6d8dbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GAT model\n",
    "class GAT(tf.keras.Model):\n",
    "    def __init__(self, n_labels, num_heads=8, seed=42):\n",
    "        super().__init__()\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=seed)\n",
    "\n",
    "        self.conv1 = GATConv(16, attn_heads=num_heads, concat_heads=True, activation='elu', kernel_initializer=initializer)\n",
    "        self.conv2 = GATConv(n_labels, attn_heads=1, concat_heads=False, activation='softmax', kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        intermediate_embeddings = self.conv1([x, a])  # Store intermediate embeddings\n",
    "        x = self.conv2([intermediate_embeddings, a])\n",
    "        return x, intermediate_embeddings  # Return both final output and intermediate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1805e34a-bed9-410b-a719-49a9df09c377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphSAGE model\n",
    "class GraphSAGE(tf.keras.Model):\n",
    "    def __init__(self, n_labels, hidden_dim=16, aggregator='mean', seed=42):\n",
    "        super().__init__()\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=seed)\n",
    "\n",
    "        self.conv1 = GraphSageConv(hidden_dim, activation='relu', aggregator=aggregator, kernel_initializer=initializer)\n",
    "        self.conv2 = GraphSageConv(n_labels, activation='softmax', aggregator=aggregator, kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        intermediate_embeddings = self.conv1([x, a])  # Store intermediate embeddings\n",
    "        x = self.conv2([intermediate_embeddings, a])\n",
    "        return x, intermediate_embeddings  # Return both final output and intermediate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7378d826-fa06-4a7d-8891-f46888320d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers=['gcn','gat','graphsage']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad91add-83d2-4b32-a97b-a7b48487c7fe",
   "metadata": {},
   "source": [
    "## Classification using different node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f36b9cb-be80-465d-852e-ded40e6f7eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(embedding_dict, embedding, classifier, ground_truth_labels=ground_truth_labels, masked_labels=masked_labels):\n",
    "    \"the labels have to be one hot encoded\"\n",
    "    \"model take values: gcn, gat, graphsage\"\n",
    "    print('embedding: ' + embedding.upper())\n",
    "    print('model: ' + classifier.upper())\n",
    "\n",
    "    X = embedding_dict[embedding]\n",
    "\n",
    "    print(\"Processing...\")\n",
    "    # Create boolean mask for training\n",
    "    train_mask = masked_labels != -1\n",
    "\n",
    "    # Split the data into training and prediction sets\n",
    "    X_train = X[train_mask]  # Training node features\n",
    "    Y_train = ground_truth_labels[train_mask]  # Training labels (one-hot encoded)\n",
    "    Y_train = tf.cast(Y_train, dtype='int32')\n",
    "    \n",
    "    # Reduce the adjacency matrix to only include training nodes\n",
    "    A_train = A[train_mask, :][:, train_mask]  # Correctly reduce the adjacency matrix\n",
    "    \n",
    "    # Convert sparse adjacency matrix to COO format\n",
    "    A_coo = A_train.tocoo()\n",
    "    indices = np.column_stack((A_coo.row, A_coo.col))  # Corrected indices format\n",
    "    values = A_coo.data\n",
    "    shape = A_coo.shape  # Shape: (num_nodes, num_nodes)\n",
    "    \n",
    "    # Create a sparse tensor for the adjacency matrix\n",
    "    A_train_tensor = tf.sparse.SparseTensor(indices=indices, values=values, dense_shape=shape)\n",
    "    \n",
    "    # Ensure the sparse tensor is ordered correctly\n",
    "    A_train_tensor = tf.sparse.reorder(A_train_tensor)\n",
    "\n",
    "    print(\"Training...\")\n",
    "    # Initialize the model\n",
    "    if classifier == 'gcn':\n",
    "        n_labels = ground_truth_labels.shape[1]  # Number of classes\n",
    "        model = GCN(n_labels)\n",
    "    elif classifier == 'gat':\n",
    "        n_labels = ground_truth_labels.shape[1]  # Number of classes\n",
    "        model = GAT(n_labels)\n",
    "    elif classifier == 'graphsage':\n",
    "        n_labels = ground_truth_labels.shape[1]  # Number of classes\n",
    "        model = GraphSAGE(n_labels)\n",
    "    \n",
    "    # Compile the model (not strictly necessary when using GradientTape, but useful for metrics)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.01),\n",
    "        loss=CategoricalCrossentropy(),\n",
    "        metrics=[CategoricalAccuracy()]\n",
    "    )\n",
    "    \n",
    "    # Print shapes for debugging\n",
    "    print(f\"Shape of X_train: {X_train.shape}\")\n",
    "    print(f\"Shape of A_train_tensor: {A_train_tensor.shape}\")\n",
    "    print(f\"Shape of Y_train: {Y_train.shape}\")\n",
    "    \n",
    "    # Define the optimizer and loss function\n",
    "    optimizer = Adam(learning_rate=0.01)\n",
    "    loss_fn = CategoricalCrossentropy()\n",
    "    \n",
    "    # Training loop with GradientTape\n",
    "    epochs = 200\n",
    "    for epoch in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            predictions, intermediate_embeddings = model([X_train, A_train_tensor])  # Unpack both outputs\n",
    "                \n",
    "            # Compute supervised loss (cross-entropy)\n",
    "            supervised_loss = loss_fn(Y_train, predictions)\n",
    "            \n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(supervised_loss, model.trainable_variables)\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "        # Print loss and accuracy for monitoring\n",
    "        if epoch % 10 == 0:\n",
    "            accuracy = CategoricalAccuracy()(Y_train, predictions)\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {supervised_loss.numpy()}, Accuracy: {accuracy.numpy()}\")\n",
    "\n",
    "    print(\"Predicting...\")\n",
    "    # Prepare the full graph for prediction\n",
    "    X_full = X  # Full node features\n",
    "    A_full = A  # Full adjacency matrix\n",
    "    \n",
    "    # Convert the full adjacency matrix to COO format\n",
    "    A_full_coo = A_full.tocoo()\n",
    "    indices_full = np.column_stack((A_full_coo.row, A_full_coo.col))\n",
    "    values_full = A_full_coo.data\n",
    "    shape_full = A_full_coo.shape\n",
    "    \n",
    "    # Create a sparse tensor for the full adjacency matrix\n",
    "    A_full_tensor = tf.sparse.SparseTensor(indices=indices_full, values=values_full, dense_shape=shape_full)\n",
    "    A_full_tensor = tf.sparse.reorder(A_full_tensor)\n",
    "    \n",
    "    # Make predictions for all nodes\n",
    "    predictions, emb = model([X_full, A_full_tensor])  # Shape: [num_nodes, n_labels]\n",
    "\n",
    "    # Convert predictions to class labels (integers)\n",
    "    predicted_labels = tf.argmax(predictions, axis=1).numpy()  # Shape: [num_nodes]\n",
    "    \n",
    "    # Extract predictions for the masked nodes\n",
    "    predicted_labels_masked = predicted_labels[labels_to_be_masked]\n",
    "\n",
    "    # True labels for the masked nodes\n",
    "    true_labels_masked = labels[labels_to_be_masked]\n",
    "    \n",
    "    # Predicted labels for the masked nodes\n",
    "    predicted_labels_masked = predicted_labels[labels_to_be_masked]\n",
    "    \n",
    "    # Evaluate the model's performance\n",
    "    results = evaluate_model(true_labels_masked, predicted_labels_masked)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Accuracy: {results['accuracy'] * 100:.2f}%\")\n",
    "    print(f\"F1-Score: {results['f1_score']:.4f}\")\n",
    "\n",
    "    results['model'] = classifier\n",
    "    results['embedding'] = embedding\n",
    "\n",
    "    # Return results and intermediate embeddings for visualization\n",
    "    return results, emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8b95ec7-e23c-4d6e-8157-a2264ef0c7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding: DEEPWALK\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 150)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n",
      "Epoch 1, Loss: 2.9073357582092285, Accuracy: 0.10947109758853912\n",
      "Epoch 11, Loss: 1.4460430145263672, Accuracy: 0.47601476311683655\n",
      "Epoch 21, Loss: 1.2604765892028809, Accuracy: 0.570725679397583\n",
      "Epoch 31, Loss: 1.1495040655136108, Accuracy: 0.6027060151100159\n",
      "Epoch 41, Loss: 1.071852207183838, Accuracy: 0.6211562156677246\n",
      "Epoch 51, Loss: 1.0147699117660522, Accuracy: 0.6359163522720337\n",
      "Epoch 61, Loss: 0.9690921306610107, Accuracy: 0.6396064162254333\n",
      "Epoch 71, Loss: 0.9310035705566406, Accuracy: 0.6531365513801575\n",
      "Epoch 81, Loss: 0.900374710559845, Accuracy: 0.6629766225814819\n",
      "Epoch 91, Loss: 0.8764164447784424, Accuracy: 0.6691266894340515\n",
      "Epoch 101, Loss: 0.8621304631233215, Accuracy: 0.6728167533874512\n",
      "Epoch 111, Loss: 0.8726982474327087, Accuracy: 0.6814268231391907\n",
      "Epoch 121, Loss: 0.855615496635437, Accuracy: 0.6851168274879456\n",
      "Epoch 131, Loss: 0.8360075950622559, Accuracy: 0.6851168274879456\n",
      "Epoch 141, Loss: 0.8203619718551636, Accuracy: 0.6974169611930847\n",
      "Epoch 151, Loss: 0.8091419339179993, Accuracy: 0.7011070251464844\n",
      "Epoch 161, Loss: 0.800973653793335, Accuracy: 0.7047970294952393\n",
      "Epoch 171, Loss: 0.7937378883361816, Accuracy: 0.7047970294952393\n",
      "Epoch 181, Loss: 0.7870029807090759, Accuracy: 0.7084870934486389\n",
      "Epoch 191, Loss: 0.7810726761817932, Accuracy: 0.7084870934486389\n",
      "Predicting...\n",
      "[[172   1   6  20  10  20  12]\n",
      " [  7 109  16  21   0   5   0]\n",
      " [  2   4 257  12   2   1   0]\n",
      " [ 35   9  27 444  59  12   6]\n",
      " [ 27   4   2  34 221   7   1]\n",
      " [  7   2   8   5   4 170   6]\n",
      " [ 15   0   0   4  12   5  92]]\n",
      "Accuracy: 77.31%\n",
      "F1-Score: 0.7682\n",
      "embedding: DEEPWALK\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 150)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.9486311674118042, Accuracy: 0.12546125054359436\n",
      "Epoch 11, Loss: 0.5940623879432678, Accuracy: 0.8081181049346924\n",
      "Epoch 21, Loss: 0.3623128831386566, Accuracy: 0.8733087182044983\n",
      "Epoch 31, Loss: 0.24603459239006042, Accuracy: 0.9175891876220703\n",
      "Epoch 41, Loss: 0.17582790553569794, Accuracy: 0.9409593939781189\n",
      "Epoch 51, Loss: 0.1286785751581192, Accuracy: 0.9446494579315186\n",
      "Epoch 61, Loss: 0.09469079971313477, Accuracy: 0.9618695974349976\n",
      "Epoch 71, Loss: 0.07153619080781937, Accuracy: 0.9753997325897217\n",
      "Epoch 81, Loss: 0.0563085600733757, Accuracy: 0.9803197979927063\n",
      "Epoch 91, Loss: 0.04633421450853348, Accuracy: 0.9852398633956909\n",
      "Epoch 101, Loss: 0.03937610611319542, Accuracy: 0.9864698648452759\n",
      "Epoch 111, Loss: 0.034515440464019775, Accuracy: 0.9876998662948608\n",
      "Epoch 121, Loss: 0.03108414262533188, Accuracy: 0.9864698648452759\n",
      "Epoch 131, Loss: 0.028477655723690987, Accuracy: 0.9864698648452759\n",
      "Epoch 141, Loss: 0.02582847699522972, Accuracy: 0.9864698648452759\n",
      "Epoch 151, Loss: 0.024285050109028816, Accuracy: 0.9864698648452759\n",
      "Epoch 161, Loss: 0.02315216325223446, Accuracy: 0.9864698648452759\n",
      "Epoch 171, Loss: 0.022349407896399498, Accuracy: 0.9876998662948608\n",
      "Epoch 181, Loss: 0.021756611764431, Accuracy: 0.9864698648452759\n",
      "Epoch 191, Loss: 0.02130105532705784, Accuracy: 0.9864698648452759\n",
      "Predicting...\n",
      "[[168   2   7  20  18  16  10]\n",
      " [  4 121  16  15   0   2   0]\n",
      " [  1   3 259  15   0   0   0]\n",
      " [ 28  13  23 475  34  13   6]\n",
      " [ 14   3   1  25 250   3   0]\n",
      " [  4   5   8   8   6 155  16]\n",
      " [ 10   0   2   6   2   9  99]]\n",
      "Accuracy: 80.58%\n",
      "F1-Score: 0.7953\n",
      "embedding: DEEPWALK\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 150)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n",
      "Epoch 1, Loss: 2.039613723754883, Accuracy: 0.1611316055059433\n",
      "Epoch 11, Loss: 1.4036000967025757, Accuracy: 0.7564575672149658\n",
      "Epoch 21, Loss: 1.3195083141326904, Accuracy: 0.8228782415390015\n",
      "Epoch 31, Loss: 1.274428367614746, Accuracy: 0.8646986484527588\n",
      "Epoch 41, Loss: 1.2461076974868774, Accuracy: 0.9003689885139465\n",
      "Epoch 51, Loss: 1.2268953323364258, Accuracy: 0.9077490568161011\n",
      "Epoch 61, Loss: 1.2126139402389526, Accuracy: 0.9212791919708252\n",
      "Epoch 71, Loss: 1.2004196643829346, Accuracy: 0.9286592602729797\n",
      "Epoch 81, Loss: 1.189555048942566, Accuracy: 0.9409593939781189\n",
      "Epoch 91, Loss: 1.179573893547058, Accuracy: 0.9483394622802734\n",
      "Epoch 101, Loss: 1.170472502708435, Accuracy: 0.955719530582428\n",
      "Epoch 111, Loss: 1.1630580425262451, Accuracy: 0.9630996584892273\n",
      "Epoch 121, Loss: 1.1558778285980225, Accuracy: 0.9729397296905518\n",
      "Epoch 131, Loss: 1.1517679691314697, Accuracy: 0.9729397296905518\n",
      "Epoch 141, Loss: 1.1458570957183838, Accuracy: 0.9766297936439514\n",
      "Epoch 151, Loss: 1.1418561935424805, Accuracy: 0.9815497994422913\n",
      "Epoch 161, Loss: 1.1390553712844849, Accuracy: 0.984009861946106\n",
      "Epoch 171, Loss: 1.1339951753616333, Accuracy: 0.9864698648452759\n",
      "Epoch 181, Loss: 1.1304354667663574, Accuracy: 0.9913899302482605\n",
      "Epoch 191, Loss: 1.1268295049667358, Accuracy: 0.9913899302482605\n",
      "Predicting...\n",
      "[[159   3   7  21  20  11  20]\n",
      " [ 13 112   9  15   5   3   1]\n",
      " [  2   4 259  10   2   1   0]\n",
      " [ 23   8  16 499  28  13   5]\n",
      " [ 15   2   1  25 247   4   2]\n",
      " [  5   2   8   6   7 157  17]\n",
      " [  4   0   1   2   3  11 107]]\n",
      "Accuracy: 81.27%\n",
      "F1-Score: 0.7956\n",
      "embedding: VGAE\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 150)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n",
      "Epoch 1, Loss: 2.2473959922790527, Accuracy: 0.13776138424873352\n",
      "Epoch 11, Loss: 1.3688595294952393, Accuracy: 0.5645756721496582\n",
      "Epoch 21, Loss: 1.1822811365127563, Accuracy: 0.6088560819625854\n",
      "Epoch 31, Loss: 1.073825716972351, Accuracy: 0.6322263479232788\n",
      "Epoch 41, Loss: 0.997455358505249, Accuracy: 0.6519064903259277\n",
      "Epoch 51, Loss: 0.9383260607719421, Accuracy: 0.6666666865348816\n",
      "Epoch 61, Loss: 0.889610230922699, Accuracy: 0.677736759185791\n",
      "Epoch 71, Loss: 0.8501335382461548, Accuracy: 0.6900368928909302\n",
      "Epoch 81, Loss: 0.818600058555603, Accuracy: 0.6974169611930847\n",
      "Epoch 91, Loss: 0.7945985198020935, Accuracy: 0.7109470963478088\n",
      "Epoch 101, Loss: 0.776993453502655, Accuracy: 0.7158671617507935\n",
      "Epoch 111, Loss: 0.7638989090919495, Accuracy: 0.7170971632003784\n",
      "Epoch 121, Loss: 0.75434410572052, Accuracy: 0.7183271646499634\n",
      "Epoch 131, Loss: 0.7471641302108765, Accuracy: 0.7183271646499634\n",
      "Epoch 141, Loss: 0.7416232228279114, Accuracy: 0.7183271646499634\n",
      "Epoch 151, Loss: 0.7372159957885742, Accuracy: 0.7207872271537781\n",
      "Epoch 161, Loss: 0.7336924076080322, Accuracy: 0.722017228603363\n",
      "Epoch 171, Loss: 0.7308396100997925, Accuracy: 0.723247230052948\n",
      "Epoch 181, Loss: 0.7285841107368469, Accuracy: 0.722017228603363\n",
      "Epoch 191, Loss: 0.7267693877220154, Accuracy: 0.724477231502533\n",
      "Predicting...\n",
      "[[148   3   9  34  11  16  20]\n",
      " [  7 118  19   8   2   4   0]\n",
      " [  7   7 243  12   3   5   1]\n",
      " [ 53  31  36 359  76  24  13]\n",
      " [ 18  14   4  48 202   5   5]\n",
      " [  8   8  14  11   4 143  14]\n",
      " [ 13   0   5   4   6   7  93]]\n",
      "Accuracy: 68.92%\n",
      "F1-Score: 0.6889\n",
      "embedding: VGAE\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 150)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n",
      "Epoch 1, Loss: 1.944360613822937, Accuracy: 0.15867158770561218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.677680492401123, Accuracy: 0.7945879697799683\n",
      "Epoch 21, Loss: 0.40751487016677856, Accuracy: 0.8720787167549133\n",
      "Epoch 31, Loss: 0.25669512152671814, Accuracy: 0.9200491905212402\n",
      "Epoch 41, Loss: 0.16978532075881958, Accuracy: 0.9495695233345032\n",
      "Epoch 51, Loss: 0.11168598383665085, Accuracy: 0.9630996584892273\n",
      "Epoch 61, Loss: 0.0767301619052887, Accuracy: 0.9766297936439514\n",
      "Epoch 71, Loss: 0.05561944842338562, Accuracy: 0.9790897965431213\n",
      "Epoch 81, Loss: 0.043246570974588394, Accuracy: 0.9852398633956909\n",
      "Epoch 91, Loss: 0.035914480686187744, Accuracy: 0.9852398633956909\n",
      "Epoch 101, Loss: 0.03120969608426094, Accuracy: 0.9864698648452759\n",
      "Epoch 111, Loss: 0.028057154268026352, Accuracy: 0.9864698648452759\n",
      "Epoch 121, Loss: 0.025902068242430687, Accuracy: 0.9864698648452759\n",
      "Epoch 131, Loss: 0.02434992976486683, Accuracy: 0.9876998662948608\n",
      "Epoch 141, Loss: 0.023176832124590874, Accuracy: 0.9876998662948608\n",
      "Epoch 151, Loss: 0.022250959649682045, Accuracy: 0.9876998662948608\n",
      "Epoch 161, Loss: 0.02129899151623249, Accuracy: 0.9876998662948608\n",
      "Epoch 171, Loss: 0.019508427008986473, Accuracy: 0.9889298677444458\n",
      "Epoch 181, Loss: 0.018739843741059303, Accuracy: 0.9889298677444458\n",
      "Epoch 191, Loss: 0.01770394667983055, Accuracy: 0.9889298677444458\n",
      "Predicting...\n",
      "[[169   4   4  18  14  25   7]\n",
      " [  3 114  17  17   5   2   0]\n",
      " [  5   9 241  11   7   5   0]\n",
      " [ 48  14  18 435  54  20   3]\n",
      " [ 15   6   3  33 221   9   9]\n",
      " [  3   4   7  18   9 157   4]\n",
      " [ 16   6   1  13   3  29  60]]\n",
      "Accuracy: 73.72%\n",
      "F1-Score: 0.7151\n",
      "embedding: VGAE\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 150)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n",
      "Epoch 1, Loss: 1.9737217426300049, Accuracy: 0.17097170650959015\n",
      "Epoch 11, Loss: 1.3834195137023926, Accuracy: 0.8019680380821228\n",
      "Epoch 21, Loss: 1.2972197532653809, Accuracy: 0.8634686470031738\n",
      "Epoch 31, Loss: 1.2544339895248413, Accuracy: 0.9028290510177612\n",
      "Epoch 41, Loss: 1.2264963388442993, Accuracy: 0.9286592602729797\n",
      "Epoch 51, Loss: 1.204674482345581, Accuracy: 0.9483394622802734\n",
      "Epoch 61, Loss: 1.187466025352478, Accuracy: 0.9594095945358276\n",
      "Epoch 71, Loss: 1.1732285022735596, Accuracy: 0.9704797267913818\n",
      "Epoch 81, Loss: 1.16206693649292, Accuracy: 0.9753997325897217\n",
      "Epoch 91, Loss: 1.1540248394012451, Accuracy: 0.9803197979927063\n",
      "Epoch 101, Loss: 1.1486485004425049, Accuracy: 0.984009861946106\n",
      "Epoch 111, Loss: 1.1432987451553345, Accuracy: 0.9864698648452759\n",
      "Epoch 121, Loss: 1.1393415927886963, Accuracy: 0.9889298677444458\n",
      "Epoch 131, Loss: 1.1354366540908813, Accuracy: 0.9901599287986755\n",
      "Epoch 141, Loss: 1.1323003768920898, Accuracy: 0.9913899302482605\n",
      "Epoch 151, Loss: 1.1302011013031006, Accuracy: 0.9901599287986755\n",
      "Epoch 161, Loss: 1.1281414031982422, Accuracy: 0.9938499331474304\n",
      "Epoch 171, Loss: 1.1270617246627808, Accuracy: 0.9938499331474304\n",
      "Epoch 181, Loss: 1.1257801055908203, Accuracy: 0.9938499331474304\n",
      "Epoch 191, Loss: 1.1247143745422363, Accuracy: 0.9938499331474304\n",
      "Predicting...\n",
      "[[154   6  12  34  15  13   7]\n",
      " [  5 104  14  20  10   4   1]\n",
      " [  3   3 226  20  12   9   5]\n",
      " [ 35  14  19 454  48  20   2]\n",
      " [ 22   1   5  47 212   8   1]\n",
      " [ 10   3   8  25   8 143   5]\n",
      " [ 17   4   3  27  13  12  52]]\n",
      "Accuracy: 70.98%\n",
      "F1-Score: 0.6844\n",
      "embedding: DGI\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 150)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n",
      "Epoch 1, Loss: 3.4470293521881104, Accuracy: 0.21279212832450867\n",
      "Epoch 11, Loss: 1.9239195585250854, Accuracy: 0.1722017228603363\n",
      "Epoch 21, Loss: 1.9002900123596191, Accuracy: 0.27798277139663696\n",
      "Epoch 31, Loss: 1.8817975521087646, Accuracy: 0.27798277139663696\n",
      "Epoch 41, Loss: 1.868064522743225, Accuracy: 0.27798277139663696\n",
      "Epoch 51, Loss: 1.8582651615142822, Accuracy: 0.27798277139663696\n",
      "Epoch 61, Loss: 1.8516106605529785, Accuracy: 0.27798277139663696\n",
      "Epoch 71, Loss: 1.8473310470581055, Accuracy: 0.27798277139663696\n",
      "Epoch 81, Loss: 1.8447028398513794, Accuracy: 0.27798277139663696\n",
      "Epoch 91, Loss: 1.843138575553894, Accuracy: 0.27798277139663696\n",
      "Epoch 101, Loss: 1.8422279357910156, Accuracy: 0.27798277139663696\n",
      "Epoch 111, Loss: 1.8417078256607056, Accuracy: 0.27798277139663696\n",
      "Epoch 121, Loss: 1.8414161205291748, Accuracy: 0.27798277139663696\n",
      "Epoch 131, Loss: 1.8412541151046753, Accuracy: 0.27798277139663696\n",
      "Epoch 141, Loss: 1.8411641120910645, Accuracy: 0.27798277139663696\n",
      "Epoch 151, Loss: 1.841113805770874, Accuracy: 0.27798277139663696\n",
      "Epoch 161, Loss: 1.8410859107971191, Accuracy: 0.27798277139663696\n",
      "Epoch 171, Loss: 1.8410701751708984, Accuracy: 0.27798277139663696\n",
      "Epoch 181, Loss: 1.8410613536834717, Accuracy: 0.27798277139663696\n",
      "Epoch 191, Loss: 1.8410563468933105, Accuracy: 0.27798277139663696\n",
      "Predicting...\n",
      "[[  0   0   0 241   0   0   0]\n",
      " [  0   0   0 158   0   0   0]\n",
      " [  0   0   0 278   0   0   0]\n",
      " [  0   0   0 592   0   0   0]\n",
      " [  0   0   0 296   0   0   0]\n",
      " [  0   0   0 202   0   0   0]\n",
      " [  0   0   0 128   0   0   0]]\n",
      "Accuracy: 31.24%\n",
      "F1-Score: 0.0680\n",
      "embedding: DGI\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 150)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n",
      "Epoch 1, Loss: 1.9559898376464844, Accuracy: 0.07257072627544403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 1.7997865676879883, Accuracy: 0.3050430417060852\n",
      "Epoch 21, Loss: 1.6739847660064697, Accuracy: 0.37392374873161316\n",
      "Epoch 31, Loss: 1.5588135719299316, Accuracy: 0.39975398778915405\n",
      "Epoch 41, Loss: 1.4893485307693481, Accuracy: 0.42189422249794006\n",
      "Epoch 51, Loss: 1.4100397825241089, Accuracy: 0.468634694814682\n",
      "Epoch 61, Loss: 1.3269370794296265, Accuracy: 0.5153751373291016\n",
      "Epoch 71, Loss: 1.2815041542053223, Accuracy: 0.5153751373291016\n",
      "Epoch 81, Loss: 1.1912226676940918, Accuracy: 0.5842558145523071\n",
      "Epoch 91, Loss: 1.1404781341552734, Accuracy: 0.6223862171173096\n",
      "Epoch 101, Loss: 1.0913622379302979, Accuracy: 0.6260762810707092\n",
      "Epoch 111, Loss: 1.041021466255188, Accuracy: 0.661746621131897\n",
      "Epoch 121, Loss: 1.0127400159835815, Accuracy: 0.659286618232727\n",
      "Epoch 131, Loss: 1.0210667848587036, Accuracy: 0.6420664191246033\n",
      "Epoch 141, Loss: 0.9624770283699036, Accuracy: 0.6814268231391907\n",
      "Epoch 151, Loss: 0.916848361492157, Accuracy: 0.6937269568443298\n",
      "Epoch 161, Loss: 0.8903835415840149, Accuracy: 0.7158671617507935\n",
      "Epoch 171, Loss: 0.8639082908630371, Accuracy: 0.7170971632003784\n",
      "Epoch 181, Loss: 0.8889397978782654, Accuracy: 0.7060270309448242\n",
      "Epoch 191, Loss: 0.9199574589729309, Accuracy: 0.6752767562866211\n",
      "Predicting...\n",
      "[[104   2  13  80   5  35   2]\n",
      " [  5  94  25  20   2  11   1]\n",
      " [  0   1 256  10   0  11   0]\n",
      " [ 12   4  34 480   9  42  11]\n",
      " [ 14   3   3 120 130  25   1]\n",
      " [  7   2  16  45   0 131   1]\n",
      " [  9   0   3  35   3  37  41]]\n",
      "Accuracy: 65.22%\n",
      "F1-Score: 0.6158\n",
      "embedding: DGI\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 150)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n",
      "Epoch 1, Loss: 1.9125137329101562, Accuracy: 0.27798277139663696\n",
      "Epoch 11, Loss: 1.8441789150238037, Accuracy: 0.27798277139663696\n",
      "Epoch 21, Loss: 1.839241862297058, Accuracy: 0.27798277139663696\n",
      "Epoch 31, Loss: 1.8297842741012573, Accuracy: 0.27798277139663696\n",
      "Epoch 41, Loss: 1.768261432647705, Accuracy: 0.3444034457206726\n",
      "Epoch 51, Loss: 1.7239800691604614, Accuracy: 0.3813038170337677\n",
      "Epoch 61, Loss: 1.6748439073562622, Accuracy: 0.4428044259548187\n",
      "Epoch 71, Loss: 1.6761478185653687, Accuracy: 0.4428044259548187\n",
      "Epoch 81, Loss: 1.6249781847000122, Accuracy: 0.507995069026947\n",
      "Epoch 91, Loss: 1.6039066314697266, Accuracy: 0.48708486557006836\n",
      "Epoch 101, Loss: 1.5769418478012085, Accuracy: 0.509225070476532\n",
      "Epoch 111, Loss: 1.565447449684143, Accuracy: 0.5596556067466736\n",
      "Epoch 121, Loss: 1.5386390686035156, Accuracy: 0.5731857419013977\n",
      "Epoch 131, Loss: 1.5381850004196167, Accuracy: 0.5670356750488281\n",
      "Epoch 141, Loss: 1.5085302591323853, Accuracy: 0.617466151714325\n",
      "Epoch 151, Loss: 1.49209725856781, Accuracy: 0.6260762810707092\n",
      "Epoch 161, Loss: 1.4770997762680054, Accuracy: 0.6580565571784973\n",
      "Epoch 171, Loss: 1.4707870483398438, Accuracy: 0.6691266894340515\n",
      "Epoch 181, Loss: 1.481980323791504, Accuracy: 0.6396064162254333\n",
      "Epoch 191, Loss: 1.5095267295837402, Accuracy: 0.6383763551712036\n",
      "Predicting...\n",
      "[[ 63   1   5 119  11  42   0]\n",
      " [  4  79  11  44   4  16   0]\n",
      " [  0   0 240  13   7  18   0]\n",
      " [  5   3   8 506   9  60   1]\n",
      " [  8   0   4 107 135  42   0]\n",
      " [  6   2   7  72   6 109   0]\n",
      " [  2   0   2  71   9  43   1]]\n",
      "Accuracy: 59.79%\n",
      "F1-Score: 0.5076\n",
      "embedding: MODULARITY\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 150)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n",
      "Epoch 1, Loss: 1.9515657424926758, Accuracy: 0.11070110648870468\n",
      "Epoch 11, Loss: 1.7158769369125366, Accuracy: 0.40467405319213867\n",
      "Epoch 21, Loss: 1.5067085027694702, Accuracy: 0.468634694814682\n",
      "Epoch 31, Loss: 1.3310389518737793, Accuracy: 0.5498154759407043\n",
      "Epoch 41, Loss: 1.188509464263916, Accuracy: 0.6457564830780029\n",
      "Epoch 51, Loss: 1.084592342376709, Accuracy: 0.659286618232727\n",
      "Epoch 61, Loss: 1.006937026977539, Accuracy: 0.676506757736206\n",
      "Epoch 71, Loss: 0.9478384852409363, Accuracy: 0.6900368928909302\n",
      "Epoch 81, Loss: 0.9027703404426575, Accuracy: 0.6998770236968994\n",
      "Epoch 91, Loss: 0.8675404191017151, Accuracy: 0.7047970294952393\n",
      "Epoch 101, Loss: 0.8395201563835144, Accuracy: 0.707257091999054\n",
      "Epoch 111, Loss: 0.8169752359390259, Accuracy: 0.7109470963478088\n",
      "Epoch 121, Loss: 0.7988801002502441, Accuracy: 0.7134071588516235\n",
      "Epoch 131, Loss: 0.7843897938728333, Accuracy: 0.7158671617507935\n",
      "Epoch 141, Loss: 0.772849440574646, Accuracy: 0.7195571660995483\n",
      "Epoch 151, Loss: 0.7636252641677856, Accuracy: 0.7207872271537781\n",
      "Epoch 161, Loss: 0.7562102675437927, Accuracy: 0.7207872271537781\n",
      "Epoch 171, Loss: 0.7502192854881287, Accuracy: 0.722017228603363\n",
      "Epoch 181, Loss: 0.7453321814537048, Accuracy: 0.7207872271537781\n",
      "Epoch 191, Loss: 0.741313636302948, Accuracy: 0.722017228603363\n",
      "Predicting...\n",
      "[[166   1   6  28  10  19  11]\n",
      " [ 12 104  24  13   2   2   1]\n",
      " [  3   5 262   5   1   2   0]\n",
      " [ 38  19  37 428  45  20   5]\n",
      " [ 25  18   5  23 219   6   0]\n",
      " [ 12   3   8   2   3 167   7]\n",
      " [ 11   1   1   1   4  12  98]]\n",
      "Accuracy: 76.20%\n",
      "F1-Score: 0.7529\n",
      "embedding: MODULARITY\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 150)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.945801854133606, Accuracy: 0.14268141984939575\n",
      "Epoch 11, Loss: 1.6649761199951172, Accuracy: 0.27798277139663696\n",
      "Epoch 21, Loss: 1.1912025213241577, Accuracy: 0.8364083766937256\n",
      "Epoch 31, Loss: 0.6224966645240784, Accuracy: 0.9212791919708252\n",
      "Epoch 41, Loss: 0.2840885519981384, Accuracy: 0.9495695233345032\n",
      "Epoch 51, Loss: 0.15674518048763275, Accuracy: 0.9569495916366577\n",
      "Epoch 61, Loss: 0.1052955612540245, Accuracy: 0.9630996584892273\n",
      "Epoch 71, Loss: 0.08005260676145554, Accuracy: 0.9729397296905518\n",
      "Epoch 81, Loss: 0.0651724636554718, Accuracy: 0.9790897965431213\n",
      "Epoch 91, Loss: 0.05567852035164833, Accuracy: 0.9790897965431213\n",
      "Epoch 101, Loss: 0.04846764728426933, Accuracy: 0.9827798008918762\n",
      "Epoch 111, Loss: 0.04246879369020462, Accuracy: 0.9864698648452759\n",
      "Epoch 121, Loss: 0.03775561600923538, Accuracy: 0.9889298677444458\n",
      "Epoch 131, Loss: 0.03434162586927414, Accuracy: 0.9889298677444458\n",
      "Epoch 141, Loss: 0.03167802095413208, Accuracy: 0.9889298677444458\n",
      "Epoch 151, Loss: 0.029462318867444992, Accuracy: 0.9901599287986755\n",
      "Epoch 161, Loss: 0.027555836364626884, Accuracy: 0.9901599287986755\n",
      "Epoch 171, Loss: 0.0259079709649086, Accuracy: 0.9901599287986755\n",
      "Epoch 181, Loss: 0.024424167349934578, Accuracy: 0.9913899302482605\n",
      "Epoch 191, Loss: 0.02313460223376751, Accuracy: 0.9913899302482605\n",
      "Predicting...\n",
      "[[169   3   4  32  21   8   4]\n",
      " [ 12 112  15  11   3   4   1]\n",
      " [  3   2 265   7   1   0   0]\n",
      " [ 33  12  29 470  30  13   5]\n",
      " [ 13   2   7  22 245   4   3]\n",
      " [ 10   5  10   7   6 157   7]\n",
      " [ 21   0   1   5   3  10  88]]\n",
      "Accuracy: 79.47%\n",
      "F1-Score: 0.7815\n",
      "embedding: MODULARITY\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 150)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n",
      "Epoch 1, Loss: 2.0124526023864746, Accuracy: 0.12915128469467163\n",
      "Epoch 11, Loss: 1.2252081632614136, Accuracy: 0.9889298677444458\n",
      "Epoch 21, Loss: 1.1441030502319336, Accuracy: 0.998769998550415\n",
      "Epoch 31, Loss: 1.1288130283355713, Accuracy: 1.0\n",
      "Epoch 41, Loss: 1.122989535331726, Accuracy: 1.0\n",
      "Epoch 51, Loss: 1.1198406219482422, Accuracy: 1.0\n",
      "Epoch 61, Loss: 1.1179970502853394, Accuracy: 1.0\n",
      "Epoch 71, Loss: 1.1167374849319458, Accuracy: 1.0\n",
      "Epoch 81, Loss: 1.1158020496368408, Accuracy: 1.0\n",
      "Epoch 91, Loss: 1.1151025295257568, Accuracy: 1.0\n",
      "Epoch 101, Loss: 1.1145625114440918, Accuracy: 1.0\n",
      "Epoch 111, Loss: 1.1141293048858643, Accuracy: 1.0\n",
      "Epoch 121, Loss: 1.1137734651565552, Accuracy: 1.0\n",
      "Epoch 131, Loss: 1.1134748458862305, Accuracy: 1.0\n",
      "Epoch 141, Loss: 1.1132200956344604, Accuracy: 1.0\n",
      "Epoch 151, Loss: 1.113001823425293, Accuracy: 1.0\n",
      "Epoch 161, Loss: 1.1128129959106445, Accuracy: 1.0\n",
      "Epoch 171, Loss: 1.112648367881775, Accuracy: 1.0\n",
      "Epoch 181, Loss: 1.1125041246414185, Accuracy: 1.0\n",
      "Epoch 191, Loss: 1.1123768091201782, Accuracy: 1.0\n",
      "Predicting...\n",
      "[[173   4   5  26  12  12   9]\n",
      " [ 13 108  17  15   2   3   0]\n",
      " [  4   2 263   9   0   0   0]\n",
      " [ 34  16  21 474  29  15   3]\n",
      " [ 19   3   5  31 230   7   1]\n",
      " [ 17   7   8   3   2 156   9]\n",
      " [ 23   0   2   1   0  12  90]]\n",
      "Accuracy: 78.84%\n",
      "F1-Score: 0.7727\n",
      "embedding: NODE2VEC\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 150)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n",
      "Epoch 1, Loss: 2.9897167682647705, Accuracy: 0.10086100548505783\n",
      "Epoch 11, Loss: 1.4242786169052124, Accuracy: 0.5596556067466736\n",
      "Epoch 21, Loss: 1.2467983961105347, Accuracy: 0.570725679397583\n",
      "Epoch 31, Loss: 1.1407084465026855, Accuracy: 0.6076260805130005\n",
      "Epoch 41, Loss: 1.0547622442245483, Accuracy: 0.6334563493728638\n",
      "Epoch 51, Loss: 0.9888125658035278, Accuracy: 0.6519064903259277\n",
      "Epoch 61, Loss: 0.9406252503395081, Accuracy: 0.6654366254806519\n",
      "Epoch 71, Loss: 0.904322624206543, Accuracy: 0.6752767562866211\n",
      "Epoch 81, Loss: 0.8778302669525146, Accuracy: 0.6838868260383606\n",
      "Epoch 91, Loss: 0.8566824793815613, Accuracy: 0.6838868260383606\n",
      "Epoch 101, Loss: 0.8391264081001282, Accuracy: 0.6863468885421753\n",
      "Epoch 111, Loss: 0.8246951103210449, Accuracy: 0.6900368928909302\n",
      "Epoch 121, Loss: 0.8306661248207092, Accuracy: 0.6974169611930847\n",
      "Epoch 131, Loss: 0.8238822817802429, Accuracy: 0.6961869597434998\n",
      "Epoch 141, Loss: 0.8127336502075195, Accuracy: 0.6961869597434998\n",
      "Epoch 151, Loss: 0.7981309294700623, Accuracy: 0.7011070251464844\n",
      "Epoch 161, Loss: 0.7903881669044495, Accuracy: 0.6998770236968994\n",
      "Epoch 171, Loss: 0.7838690280914307, Accuracy: 0.7023370265960693\n",
      "Epoch 181, Loss: 0.7786252498626709, Accuracy: 0.7060270309448242\n",
      "Epoch 191, Loss: 0.7739500999450684, Accuracy: 0.7097170948982239\n",
      "Predicting...\n",
      "[[173   4   5  21   4  23  11]\n",
      " [  4 111  17  23   0   3   0]\n",
      " [  2   1 264   8   1   1   1]\n",
      " [ 53  11  23 459  26  16   4]\n",
      " [ 29   5   0  49 209   4   0]\n",
      " [ 14   3   6  12   0 165   2]\n",
      " [ 25   0   1  13   1  12  76]]\n",
      "Accuracy: 76.89%\n",
      "F1-Score: 0.7577\n",
      "embedding: NODE2VEC\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 150)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.9383519887924194, Accuracy: 0.18696187436580658\n",
      "Epoch 11, Loss: 0.5836333632469177, Accuracy: 0.814268171787262\n",
      "Epoch 21, Loss: 0.3503478169441223, Accuracy: 0.8806887865066528\n",
      "Epoch 31, Loss: 0.24543626606464386, Accuracy: 0.9261992573738098\n",
      "Epoch 41, Loss: 0.17799623310565948, Accuracy: 0.9335793256759644\n",
      "Epoch 51, Loss: 0.13310186564922333, Accuracy: 0.9446494579315186\n",
      "Epoch 61, Loss: 0.10144802927970886, Accuracy: 0.9606395959854126\n",
      "Epoch 71, Loss: 0.07975242286920547, Accuracy: 0.9729397296905518\n",
      "Epoch 81, Loss: 0.0651208832859993, Accuracy: 0.9741697311401367\n",
      "Epoch 91, Loss: 0.054799504578113556, Accuracy: 0.9790897965431213\n",
      "Epoch 101, Loss: 0.047336023300886154, Accuracy: 0.9827798008918762\n",
      "Epoch 111, Loss: 0.041484761983156204, Accuracy: 0.9827798008918762\n",
      "Epoch 121, Loss: 0.036711741238832474, Accuracy: 0.9815497994422913\n",
      "Epoch 131, Loss: 0.03327847644686699, Accuracy: 0.9815497994422913\n",
      "Epoch 141, Loss: 0.03076031059026718, Accuracy: 0.9827798008918762\n",
      "Epoch 151, Loss: 0.028825702145695686, Accuracy: 0.9827798008918762\n",
      "Epoch 161, Loss: 0.027309253811836243, Accuracy: 0.9827798008918762\n",
      "Epoch 171, Loss: 0.026107126846909523, Accuracy: 0.9827798008918762\n",
      "Epoch 181, Loss: 0.025145109742879868, Accuracy: 0.9827798008918762\n",
      "Epoch 191, Loss: 0.024378756061196327, Accuracy: 0.9827798008918762\n",
      "Predicting...\n",
      "[[184   3   6  17   7  19   5]\n",
      " [  8 116  15  13   3   1   2]\n",
      " [  2   4 263   7   0   2   0]\n",
      " [ 41  12  18 466  39  12   4]\n",
      " [ 20   2   0  33 232   8   1]\n",
      " [  6   1   7   5   6 171   6]\n",
      " [ 17   0   2   0   0  14  95]]\n",
      "Accuracy: 80.58%\n",
      "F1-Score: 0.7986\n",
      "embedding: NODE2VEC\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 150)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n",
      "Epoch 1, Loss: 1.9932180643081665, Accuracy: 0.12177121639251709\n",
      "Epoch 11, Loss: 1.40847909450531, Accuracy: 0.7527675032615662\n",
      "Epoch 21, Loss: 1.321278691291809, Accuracy: 0.8228782415390015\n",
      "Epoch 31, Loss: 1.2757575511932373, Accuracy: 0.8634686470031738\n",
      "Epoch 41, Loss: 1.2465686798095703, Accuracy: 0.8954489827156067\n",
      "Epoch 51, Loss: 1.2261629104614258, Accuracy: 0.9089791178703308\n",
      "Epoch 61, Loss: 1.2100049257278442, Accuracy: 0.9225092530250549\n",
      "Epoch 71, Loss: 1.1953456401824951, Accuracy: 0.9323493242263794\n",
      "Epoch 81, Loss: 1.1826446056365967, Accuracy: 0.9483394622802734\n",
      "Epoch 91, Loss: 1.1717644929885864, Accuracy: 0.9569495916366577\n",
      "Epoch 101, Loss: 1.1629639863967896, Accuracy: 0.9630996584892273\n",
      "Epoch 111, Loss: 1.156082034111023, Accuracy: 0.9717097282409668\n",
      "Epoch 121, Loss: 1.1510518789291382, Accuracy: 0.9741697311401367\n",
      "Epoch 131, Loss: 1.1459238529205322, Accuracy: 0.9766297936439514\n",
      "Epoch 141, Loss: 1.1428884267807007, Accuracy: 0.9803197979927063\n",
      "Epoch 151, Loss: 1.1397138833999634, Accuracy: 0.9790897965431213\n",
      "Epoch 161, Loss: 1.139675498008728, Accuracy: 0.9790897965431213\n",
      "Epoch 171, Loss: 1.1377897262573242, Accuracy: 0.9803197979927063\n",
      "Epoch 181, Loss: 1.1350818872451782, Accuracy: 0.9815497994422913\n",
      "Epoch 191, Loss: 1.1334518194198608, Accuracy: 0.984009861946106\n",
      "Predicting...\n",
      "[[160   8   8  34   9  14   8]\n",
      " [  5 119  14  10   8   1   1]\n",
      " [  2   3 261  11   1   0   0]\n",
      " [ 16  19  15 496  30   8   8]\n",
      " [ 13   4   1  37 237   3   1]\n",
      " [  7   5   7   9   8 157   9]\n",
      " [  9   0   1   3   1  11 103]]\n",
      "Accuracy: 80.90%\n",
      "F1-Score: 0.7970\n",
      "embedding: RANDOM\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 150)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n",
      "Epoch 1, Loss: 4.015368461608887, Accuracy: 0.11439114063978195\n",
      "Epoch 11, Loss: 1.4330064058303833, Accuracy: 0.5006150007247925\n",
      "Epoch 21, Loss: 1.1920688152313232, Accuracy: 0.5781058073043823\n",
      "Epoch 31, Loss: 1.0674766302108765, Accuracy: 0.6223862171173096\n",
      "Epoch 41, Loss: 0.9783189296722412, Accuracy: 0.6506764888763428\n",
      "Epoch 51, Loss: 0.9152183532714844, Accuracy: 0.6715866923332214\n",
      "Epoch 61, Loss: 0.8677727580070496, Accuracy: 0.6924968957901001\n",
      "Epoch 71, Loss: 0.8324647545814514, Accuracy: 0.7023370265960693\n",
      "Epoch 81, Loss: 0.8072084784507751, Accuracy: 0.7097170948982239\n",
      "Epoch 91, Loss: 0.787872850894928, Accuracy: 0.7121770977973938\n",
      "Epoch 101, Loss: 0.7736334204673767, Accuracy: 0.7109470963478088\n",
      "Epoch 111, Loss: 0.7637053728103638, Accuracy: 0.7121770977973938\n",
      "Epoch 121, Loss: 0.7564833760261536, Accuracy: 0.7121770977973938\n",
      "Epoch 131, Loss: 0.7509306073188782, Accuracy: 0.7134071588516235\n",
      "Epoch 141, Loss: 0.7464406490325928, Accuracy: 0.7146371603012085\n",
      "Epoch 151, Loss: 0.7424145936965942, Accuracy: 0.7158671617507935\n",
      "Epoch 161, Loss: 0.7383912801742554, Accuracy: 0.7195571660995483\n",
      "Epoch 171, Loss: 0.7352324724197388, Accuracy: 0.7207872271537781\n",
      "Epoch 181, Loss: 0.7316054701805115, Accuracy: 0.7207872271537781\n",
      "Epoch 191, Loss: 0.7279603481292725, Accuracy: 0.722017228603363\n",
      "Predicting...\n",
      "[[ 48  12  35  56  31  46  13]\n",
      " [ 15  28  31  13  13  54   4]\n",
      " [  7   8 126  32  55  42   8]\n",
      " [ 87  44  81 180  72  98  30]\n",
      " [ 36   8  66  56  73  45  12]\n",
      " [  9   2  48  47  15  77   4]\n",
      " [ 14   0  18  22  15  31  28]]\n",
      "Accuracy: 29.55%\n",
      "F1-Score: 0.2738\n",
      "embedding: RANDOM\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 150)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n",
      "Epoch 1, Loss: 1.9490493535995483, Accuracy: 0.14268141984939575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.7111485600471497, Accuracy: 0.7958179712295532\n",
      "Epoch 21, Loss: 0.1617964655160904, Accuracy: 0.9630996584892273\n",
      "Epoch 31, Loss: 0.05152703449130058, Accuracy: 0.9815497994422913\n",
      "Epoch 41, Loss: 0.02994064800441265, Accuracy: 0.9852398633956909\n",
      "Epoch 51, Loss: 0.023864224553108215, Accuracy: 0.9864698648452759\n",
      "Epoch 61, Loss: 0.021367598325014114, Accuracy: 0.9876998662948608\n",
      "Epoch 71, Loss: 0.020811202004551888, Accuracy: 0.9864698648452759\n",
      "Epoch 81, Loss: 0.02046360820531845, Accuracy: 0.9864698648452759\n",
      "Epoch 91, Loss: 0.019534962251782417, Accuracy: 0.9864698648452759\n",
      "Epoch 101, Loss: 0.019257524982094765, Accuracy: 0.9876998662948608\n",
      "Epoch 111, Loss: 0.01895175129175186, Accuracy: 0.9901599287986755\n",
      "Epoch 121, Loss: 0.017561698332428932, Accuracy: 0.9889298677444458\n",
      "Epoch 131, Loss: 0.01716657355427742, Accuracy: 0.9901599287986755\n",
      "Epoch 141, Loss: 0.016352863982319832, Accuracy: 0.9901599287986755\n",
      "Epoch 151, Loss: 0.014760083518922329, Accuracy: 0.9901599287986755\n",
      "Epoch 161, Loss: 0.014456255361437798, Accuracy: 0.9901599287986755\n",
      "Epoch 171, Loss: 0.014231791719794273, Accuracy: 0.9901599287986755\n",
      "Epoch 181, Loss: 0.01408680435270071, Accuracy: 0.9901599287986755\n",
      "Epoch 191, Loss: 0.013997900299727917, Accuracy: 0.9901599287986755\n",
      "Predicting...\n",
      "[[ 74  16  34  68  17  27   5]\n",
      " [  7  52  21  46  15  10   7]\n",
      " [ 31  12 151  57  15  12   0]\n",
      " [ 64  16 107 306  49  37  13]\n",
      " [ 35   3  54  86  85  24   9]\n",
      " [ 37   8  39  51  15  51   1]\n",
      " [ 33   4  15  31   8  24  13]]\n",
      "Accuracy: 38.63%\n",
      "F1-Score: 0.3355\n",
      "embedding: RANDOM\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 150)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n",
      "Epoch 1, Loss: 2.021347761154175, Accuracy: 0.13407133519649506\n",
      "Epoch 11, Loss: 1.5231677293777466, Accuracy: 0.6666666865348816\n",
      "Epoch 21, Loss: 1.388831377029419, Accuracy: 0.8105781078338623\n",
      "Epoch 31, Loss: 1.3189674615859985, Accuracy: 0.8733087182044983\n",
      "Epoch 41, Loss: 1.2729960680007935, Accuracy: 0.9188191890716553\n",
      "Epoch 51, Loss: 1.2387462854385376, Accuracy: 0.9446494579315186\n",
      "Epoch 61, Loss: 1.2141214609146118, Accuracy: 0.955719530582428\n",
      "Epoch 71, Loss: 1.1972047090530396, Accuracy: 0.9667896628379822\n",
      "Epoch 81, Loss: 1.1845183372497559, Accuracy: 0.9667896628379822\n",
      "Epoch 91, Loss: 1.1758618354797363, Accuracy: 0.9704797267913818\n",
      "Epoch 101, Loss: 1.1680684089660645, Accuracy: 0.9766297936439514\n",
      "Epoch 111, Loss: 1.1639399528503418, Accuracy: 0.9778597950935364\n",
      "Epoch 121, Loss: 1.1577913761138916, Accuracy: 0.9790897965431213\n",
      "Epoch 131, Loss: 1.155537724494934, Accuracy: 0.9790897965431213\n",
      "Epoch 141, Loss: 1.1515926122665405, Accuracy: 0.9803197979927063\n",
      "Epoch 151, Loss: 1.1505833864212036, Accuracy: 0.9803197979927063\n",
      "Epoch 161, Loss: 1.1463173627853394, Accuracy: 0.984009861946106\n",
      "Epoch 171, Loss: 1.1441130638122559, Accuracy: 0.984009861946106\n",
      "Epoch 181, Loss: 1.142503023147583, Accuracy: 0.9864698648452759\n",
      "Epoch 191, Loss: 1.141822099685669, Accuracy: 0.9864698648452759\n",
      "Predicting...\n",
      "[[ 48   3  39  95  51   4   1]\n",
      " [ 23   2  17  72  35   9   0]\n",
      " [ 47   2  47 118  57   7   0]\n",
      " [ 63   2  83 306 116  20   2]\n",
      " [ 31   1  36 120  97   9   2]\n",
      " [ 36   0  34  86  32  13   1]\n",
      " [ 28   3  12  55  18  11   1]]\n",
      "Accuracy: 27.12%\n",
      "F1-Score: 0.1701\n",
      "embedding: GIVEN\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 1433)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n",
      "Epoch 1, Loss: 2.062105178833008, Accuracy: 0.09840098768472672\n",
      "Epoch 11, Loss: 1.087834119796753, Accuracy: 0.6076260805130005\n",
      "Epoch 21, Loss: 0.871857225894928, Accuracy: 0.7011070251464844\n",
      "Epoch 31, Loss: 0.7936618328094482, Accuracy: 0.7146371603012085\n",
      "Epoch 41, Loss: 0.7630178332328796, Accuracy: 0.7207872271537781\n",
      "Epoch 51, Loss: 0.7440962791442871, Accuracy: 0.724477231502533\n",
      "Epoch 61, Loss: 0.7335047125816345, Accuracy: 0.724477231502533\n",
      "Epoch 71, Loss: 0.7274293899536133, Accuracy: 0.724477231502533\n",
      "Epoch 81, Loss: 0.7231401205062866, Accuracy: 0.724477231502533\n",
      "Epoch 91, Loss: 0.7202237844467163, Accuracy: 0.724477231502533\n",
      "Epoch 101, Loss: 0.7181925177574158, Accuracy: 0.723247230052948\n",
      "Epoch 111, Loss: 0.7167399525642395, Accuracy: 0.723247230052948\n",
      "Epoch 121, Loss: 0.7156626582145691, Accuracy: 0.723247230052948\n",
      "Epoch 131, Loss: 0.7148571610450745, Accuracy: 0.723247230052948\n",
      "Epoch 141, Loss: 0.714240312576294, Accuracy: 0.723247230052948\n",
      "Epoch 151, Loss: 0.7137547135353088, Accuracy: 0.723247230052948\n",
      "Epoch 161, Loss: 0.7137163877487183, Accuracy: 0.723247230052948\n",
      "Epoch 171, Loss: 0.7134761810302734, Accuracy: 0.723247230052948\n",
      "Epoch 181, Loss: 0.714534342288971, Accuracy: 0.724477231502533\n",
      "Epoch 191, Loss: 0.7754679322242737, Accuracy: 0.7170971632003784\n",
      "Predicting...\n",
      "[[173   2  11  34  12   7   2]\n",
      " [  4  96  20  24  12   2   0]\n",
      " [  2   0 265   9   1   1   0]\n",
      " [ 39   4  16 502  24   5   2]\n",
      " [ 17   0   3  46 230   0   0]\n",
      " [ 29   1  12   7   3 147   3]\n",
      " [ 28   0   3  26   1   3  67]]\n",
      "Accuracy: 78.10%\n",
      "F1-Score: 0.7607\n",
      "embedding: GIVEN\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 1433)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.9469044208526611, Accuracy: 0.11685116589069366\n",
      "Epoch 11, Loss: 0.1977013200521469, Accuracy: 0.936039388179779\n",
      "Epoch 21, Loss: 0.06659530103206635, Accuracy: 0.9729397296905518\n",
      "Epoch 31, Loss: 0.04044291377067566, Accuracy: 0.9778597950935364\n",
      "Epoch 41, Loss: 0.030810652300715446, Accuracy: 0.984009861946106\n",
      "Epoch 51, Loss: 0.025495875626802444, Accuracy: 0.9852398633956909\n",
      "Epoch 61, Loss: 0.022625740617513657, Accuracy: 0.9852398633956909\n",
      "Epoch 71, Loss: 0.02160685509443283, Accuracy: 0.9864698648452759\n",
      "Epoch 81, Loss: 0.02071201056241989, Accuracy: 0.9864698648452759\n",
      "Epoch 91, Loss: 0.018755437806248665, Accuracy: 0.9876998662948608\n",
      "Epoch 101, Loss: 0.018266931176185608, Accuracy: 0.9876998662948608\n",
      "Epoch 111, Loss: 0.018040692433714867, Accuracy: 0.9876998662948608\n",
      "Epoch 121, Loss: 0.017873261123895645, Accuracy: 0.9876998662948608\n",
      "Epoch 131, Loss: 0.01776740700006485, Accuracy: 0.9852398633956909\n",
      "Epoch 141, Loss: 0.017682936042547226, Accuracy: 0.9876998662948608\n",
      "Epoch 151, Loss: 0.017612427473068237, Accuracy: 0.9864698648452759\n",
      "Epoch 161, Loss: 0.01755237765610218, Accuracy: 0.9889298677444458\n",
      "Epoch 171, Loss: 0.01749986782670021, Accuracy: 0.9889298677444458\n",
      "Epoch 181, Loss: 0.017454523593187332, Accuracy: 0.9864698648452759\n",
      "Epoch 191, Loss: 0.01741909235715866, Accuracy: 0.9876998662948608\n",
      "Predicting...\n",
      "[[203   3   7  13   3   9   3]\n",
      " [  8 125  11  11   3   0   0]\n",
      " [  6   0 269   2   1   0   0]\n",
      " [ 28   9  16 503  24   9   3]\n",
      " [ 15   1   0  21 256   2   1]\n",
      " [ 12   1   6   9   2 166   6]\n",
      " [ 18   0   0   2   1  11  96]]\n",
      "Accuracy: 85.38%\n",
      "F1-Score: 0.8445\n",
      "embedding: GIVEN\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (813, 1433)\n",
      "Shape of A_train_tensor: (813, 813)\n",
      "Shape of Y_train: (813, 7)\n",
      "Epoch 1, Loss: 1.949971318244934, Accuracy: 0.2066420614719391\n",
      "Epoch 11, Loss: 1.2040139436721802, Accuracy: 0.9729397296905518\n",
      "Epoch 21, Loss: 1.1485687494277954, Accuracy: 0.9938499331474304\n",
      "Epoch 31, Loss: 1.1301981210708618, Accuracy: 1.0\n",
      "Epoch 41, Loss: 1.1224563121795654, Accuracy: 1.0\n",
      "Epoch 51, Loss: 1.1186519861221313, Accuracy: 1.0\n",
      "Epoch 61, Loss: 1.1165993213653564, Accuracy: 1.0\n",
      "Epoch 71, Loss: 1.1153638362884521, Accuracy: 1.0\n",
      "Epoch 81, Loss: 1.1145356893539429, Accuracy: 1.0\n",
      "Epoch 91, Loss: 1.1139334440231323, Accuracy: 1.0\n",
      "Epoch 101, Loss: 1.1134651899337769, Accuracy: 1.0\n",
      "Epoch 111, Loss: 1.1130824089050293, Accuracy: 1.0\n",
      "Epoch 121, Loss: 1.1128020286560059, Accuracy: 1.0\n",
      "Epoch 131, Loss: 1.1125730276107788, Accuracy: 1.0\n",
      "Epoch 141, Loss: 1.112382173538208, Accuracy: 1.0\n",
      "Epoch 151, Loss: 1.1122225522994995, Accuracy: 1.0\n",
      "Epoch 161, Loss: 1.112087368965149, Accuracy: 1.0\n",
      "Epoch 171, Loss: 1.111971378326416, Accuracy: 1.0\n",
      "Epoch 181, Loss: 1.111870288848877, Accuracy: 1.0\n",
      "Epoch 191, Loss: 1.1117818355560303, Accuracy: 1.0\n",
      "Predicting...\n",
      "[[189   2  15  17  10   6   2]\n",
      " [  9 100  34  12   1   2   0]\n",
      " [  5   0 269   2   1   1   0]\n",
      " [ 31   3  31 498  22   5   2]\n",
      " [ 13   2   1  29 248   3   0]\n",
      " [ 29   0  12   9   3 146   3]\n",
      " [ 24   0   7   9   4   9  75]]\n",
      "Accuracy: 80.47%\n",
      "F1-Score: 0.7829\n"
     ]
    }
   ],
   "source": [
    "all_results=[]\n",
    "graph_embeddings_dict={}\n",
    "for emb in embedding_dict.keys():\n",
    "    for clf in classifiers:\n",
    "        results, embedding_matrix = train_and_evaluate(embedding_dict, emb, clf)\n",
    "        all_results.append(results)\n",
    "        key_string= emb + ' with ' + clf\n",
    "        graph_embeddings_dict[key_string]=embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17527c3b-ef18-4b1a-abb6-48bcea7dc4a3",
   "metadata": {},
   "source": [
    "## Saving aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa504238-b2df-4efd-b68c-90532d749d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved as ./cora_analysis_results/cora_seed46_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "# Define dataset name and seed\n",
    "dataset_name = \"cora\"\n",
    "seed_value = SEED\n",
    "\n",
    "# Save as CSV file without sorting\n",
    "filename = f\"{dataset_name}_seed{seed_value}_results.csv\"\n",
    "filename='./cora_analysis_results/'+filename\n",
    "df.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Results saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9875500-5fdf-4d56-9a05-5d5d3cbceec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings= embedding_dict | graph_embeddings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f19ef74-740a-4a9a-8ad5-bef07a3e8f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_dict(original_dict, key_order):\n",
    "    \"\"\"\n",
    "    Reorders a dictionary based on a given list of keys.\n",
    "\n",
    "    Parameters:\n",
    "    - original_dict (dict): The dictionary to reorder.\n",
    "    - key_order (list): The list specifying the desired key order.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A new dictionary with keys ordered as per key_order.\n",
    "    \"\"\"\n",
    "    return {key: original_dict[key] for key in key_order if key in original_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a0939b3-7a5a-4149-9130-86f5d6ca5141",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_order = ['random', 'random with gcn', 'random with gat', 'random with graphsage', 'deepwalk', 'deepwalk with gcn', 'deepwalk with gat', 'deepwalk with graphsage', 'node2vec','node2vec with gcn', 'node2vec with gat', 'node2vec with graphsage', 'vgae', 'vgae with gcn', 'vgae with gat', 'vgae with graphsage', 'dgi', 'dgi with gcn', 'dgi with gat', 'dgi with graphsage', 'modularity', 'modularity with gcn', 'modularity with gat', 'modularity with graphsage', 'given', 'given with gcn', 'given with gat', 'given with graphsage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "267d6703-3449-4e03-a5ed-105a5eba4eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\joblib\\_memmapping_reducer.py:603: UserWarning: Failed to delete temporary folder: C:\\Users\\user\\AppData\\Local\\Temp\\joblib_memmapping_folder_9316_e9c55aee14304499b5a58ebd0a2daa8c_4cd00a46f559483db3bce1919c1d799a\n",
      "  warnings.warn(\"Failed to delete temporary folder: {}\"\n",
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\joblib\\_memmapping_reducer.py:603: UserWarning: Failed to delete temporary folder: C:\\Users\\user\\AppData\\Local\\Temp\\joblib_memmapping_folder_9316_e9c55aee14304499b5a58ebd0a2daa8c_0d55d7813ff8480688d2e52f35f92591\n",
      "  warnings.warn(\"Failed to delete temporary folder: {}\"\n",
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\joblib\\_memmapping_reducer.py:603: UserWarning: Failed to delete temporary folder: C:\\Users\\user\\AppData\\Local\\Temp\\joblib_memmapping_folder_9316_70dd8a80d9314ff5ba1b4636ecb7cfed_1a969770f5eb4bf0b359a04fd9dd975d\n",
      "  warnings.warn(\"Failed to delete temporary folder: {}\"\n",
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\joblib\\_memmapping_reducer.py:603: UserWarning: Failed to delete temporary folder: C:\\Users\\user\\AppData\\Local\\Temp\\joblib_memmapping_folder_9316_70dd8a80d9314ff5ba1b4636ecb7cfed_96751644e7c2483882aa0b065c138fe8\n",
      "  warnings.warn(\"Failed to delete temporary folder: {}\"\n"
     ]
    }
   ],
   "source": [
    "all_embeddings = reorder_dict(all_embeddings, key_order)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0a931ea-2fce-4bd4-8bf2-cbe36f0e8381",
   "metadata": {},
   "source": [
    "visualize_all_embeddings(all_embeddings, labels, label_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbf8080-e7d6-428c-b80d-558dbc304180",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
