{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c1ef1f-2372-44c0-9703-b8ac660cce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7add991-0ec5-4243-bfd8-9707b50cf924",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time \n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import umap.umap_ as umap\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
    "from node2vec import Node2Vec\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import spektral\n",
    "from spektral.layers import GCNConv, GATConv\n",
    "from spektral.layers import GraphSageConv\n",
    "from spektral.data import Graph, Dataset, BatchLoader\n",
    "from scipy.sparse import csr_matrix\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import DeepGraphInfomax, VGAE\n",
    "from torch_geometric.utils import from_networkx\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import normalize\n",
    "from joblib import Parallel, delayed\n",
    "from torch_geometric.nn import GCNConv as PyG_GCNConv, VGAE as PyG_VGAE\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2544f48-7c06-4b94-aa50-cee5874d5b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 46\n",
    "\n",
    "# Set seed for Python's built-in random module\n",
    "random.seed(SEED)\n",
    "\n",
    "# Set seed for NumPy\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Set seed for PyTorch\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b95802d-543f-4b3e-803a-cdbdb518595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom Dataset for the graph\n",
    "class CiteSeerDataset(Dataset):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        dataset = Planetoid(root=\".\", name=\"CiteSeer\")  # Load CiteSeer dataset\n",
    "        data = dataset[0]  # Access the first graph\n",
    "        \n",
    "        # Convert Torch tensors to NumPy\n",
    "        x = data.x.numpy()\n",
    "        edge_index = data.edge_index.numpy()\n",
    "        y = data.y.numpy()\n",
    "\n",
    "        # One-hot encode labels\n",
    "        num_classes = y.max() + 1  # Number of classes\n",
    "        y_one_hot = np.eye(num_classes)[y]  # One-hot encoding\n",
    "\n",
    "        # Convert edge_index to a sparse adjacency matrix\n",
    "        num_nodes = x.shape[0]\n",
    "        adj = csr_matrix((num_nodes, num_nodes))  # Initialize sparse matrix\n",
    "        for i in range(edge_index.shape[1]):\n",
    "            src, dst = edge_index[:, i]\n",
    "            adj[src, dst] = 1\n",
    "            adj[dst, src] = 1  # Ensure undirected graph\n",
    "\n",
    "        return [Graph(x=x, a=adj, y=y_one_hot)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90c18215-d57c-47a9-957d-5f98fa330e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimensionality=150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b67b75-8102-41b3-b7d9-faac9a95ca1d",
   "metadata": {},
   "source": [
    "## Extracting modularity embedding and using it for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e46cf19-a136-404f-9c2a-a2d8404b874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian Eigenmaps Embedding\n",
    "def deepwalk_embedding(G, k=2, walk_length=10, num_walks=80, workers=4):\n",
    "    node2vec = Node2Vec(G, dimensions=k, walk_length=walk_length, num_walks=num_walks, workers=workers)\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "    return np.array([model.wv[str(node)] for node in G.nodes()])\n",
    "\n",
    "# Node2Vec Embedding\n",
    "def node2vec_embedding(G, k=2, seed=SEED):\n",
    "    node2vec = Node2Vec(G, dimensions=k, walk_length=10, num_walks=100, workers=2, seed=seed)\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "    return np.array([model.wv[str(node)] for node in G.nodes()])\n",
    "\n",
    "\n",
    "# VGAE Embedding \n",
    "class VGAEEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = PyG_GCNConv(in_channels, 2 * out_channels)  # Use PyG_GCNConv\n",
    "        self.conv_mu = PyG_GCNConv(2 * out_channels, out_channels)  # Separate layer for mu\n",
    "        self.conv_logstd = PyG_GCNConv(2 * out_channels, out_channels)  # Separate layer for logstd\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = torch.relu(self.conv1(x, edge_index))\n",
    "        mu = self.conv_mu(x, edge_index)\n",
    "        logstd = self.conv_logstd(x, edge_index)\n",
    "        return mu, logstd\n",
    "\n",
    "def vgae_embedding(data, k=128):\n",
    "    # Use one-hot encoded node IDs as features\n",
    "    num_nodes = data.num_nodes\n",
    "    x = torch.eye(num_nodes)  # One-hot encoded node features\n",
    "\n",
    "    in_channels = x.shape[1]  # Feature dimension is equal to the number of nodes\n",
    "    model = PyG_VGAE(VGAEEncoder(in_channels, k))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    for _ in tqdm(range(200)):\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(x, data.edge_index)  # Use one-hot encoded features\n",
    "        loss = model.recon_loss(z, data.edge_index) + (1 / data.num_nodes) * model.kl_loss()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model.encode(x, data.edge_index).detach().numpy()\n",
    "\n",
    "# DGI Embedding\n",
    "def dgi_embedding(data, k=128):\n",
    "    class GCNEncoder(torch.nn.Module):\n",
    "        def __init__(self, in_channels, out_channels):\n",
    "            super().__init__()\n",
    "            self.conv1 = PyG_GCNConv(in_channels, 2 * out_channels)  # Use PyG_GCNConv\n",
    "            self.conv2 = PyG_GCNConv(2 * out_channels, out_channels)  # Use PyG_GCNConv\n",
    "\n",
    "        def forward(self, x, edge_index):\n",
    "            x = torch.relu(self.conv1(x, edge_index))\n",
    "            return self.conv2(x, edge_index)\n",
    "\n",
    "    # Use one-hot encoded node IDs as features\n",
    "    num_nodes = data.num_nodes\n",
    "    x = torch.eye(num_nodes)  # One-hot encoded node features\n",
    "\n",
    "    in_channels = x.shape[1]  # Feature dimension is equal to the number of nodes\n",
    "    model = DeepGraphInfomax(\n",
    "        hidden_channels=k,\n",
    "        encoder=GCNEncoder(in_channels, k),\n",
    "        summary=lambda z, *args, **kwargs: z.mean(dim=0),  # Ensure `summary` only takes `z`\n",
    "        corruption=lambda x, edge_index: (x[torch.randperm(x.size(0))], edge_index)  # Correct corruption function\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    for _ in tqdm(range(200)):\n",
    "        optimizer.zero_grad()\n",
    "        pos_z, neg_z, summary = model(x, data.edge_index)  # Use one-hot encoded features\n",
    "        loss = model.loss(pos_z, neg_z, summary)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return pos_z.detach().numpy()\n",
    "\n",
    "\n",
    "# Unsupervised gradient ascent for modularity maximization\n",
    "def gradient_ascent_modularity_unsupervised(G, k=2, eta=0.01, iterations=1000, seed=SEED):\n",
    "    np.random.seed(seed)  # Ensure deterministic initialization\n",
    "\n",
    "    A = nx.to_numpy_array(G)\n",
    "    l = A.sum(axis=1)\n",
    "    m = np.sum(l) / 2\n",
    "    B = A - np.outer(l, l) / (2 * m)\n",
    "    n = B.shape[0]\n",
    "\n",
    "    S = np.random.randn(n, k)  # Random Initialization\n",
    "    S, _ = np.linalg.qr(S)  # Ensure initial orthonormality\n",
    "\n",
    "    for i in tqdm(range(iterations), desc=\"Gradient Ascent Progress\"):\n",
    "        grad = (1 / (2 * m)) * B @ S\n",
    "        S += eta * grad\n",
    "        S, _ = np.linalg.qr(S)  # Orthonormalize using QR decomposition\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ce87126-9fb7-4a43-b9f7-4a063b52b052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_labeled_random_walks(G, label_mask, labels, num_walks, walk_length, walk_length_labelled=3):\n",
    "    walks = {node: [] for node in G.nodes()}\n",
    "    for node in G.nodes():\n",
    "        for _ in range(num_walks):\n",
    "            walk = [node]\n",
    "            labeled_count = 0\n",
    "            for _ in range(walk_length - 1):\n",
    "                cur = walk[-1]\n",
    "                neighbors = list(G.neighbors(cur))\n",
    "                if not neighbors:\n",
    "                    break\n",
    "                labeled_neighbors = [n for n in neighbors if label_mask[n]]\n",
    "                if labeled_neighbors and labeled_count < walk_length_labelled:\n",
    "                    next_node = random.choice(labeled_neighbors)\n",
    "                    labeled_count += 1\n",
    "                else:\n",
    "                    next_node = random.choice(neighbors)\n",
    "                walk.append(next_node)\n",
    "            walks[node].extend([n for n in walk if label_mask[n]])\n",
    "    return walks\n",
    "\n",
    "def compute_attention_weights(S, labeled_nodes):\n",
    "    weights = {}\n",
    "    for node, labeled in labeled_nodes.items():\n",
    "        if labeled:\n",
    "            similarities = {n: np.dot(S[node], S[n]) for n in labeled}\n",
    "            exp_sims = {n: np.exp(sim) for n, sim in similarities.items()}\n",
    "            total = sum(exp_sims.values())\n",
    "            weights[node] = {n: exp_sims[n] / total for n in labeled}\n",
    "    return weights\n",
    "\n",
    "def semi_supervised_gradient_ascent_modularity(G, labels, label_mask, k=2, eta=0.01, lambda_supervised=1.0, \n",
    "                                                      lambda_semi=2.0, iterations=5000, initialization='random',\n",
    "                                                      num_walks=10, walk_length=5, walk_length_labelled=3):\n",
    "    # Convert graph to sparse adjacency matrix\n",
    "    A = csr_matrix(nx.to_scipy_sparse_array(G, format='csr'))\n",
    "    degrees = np.array(A.sum(axis=1)).flatten()\n",
    "    m = G.number_of_edges()\n",
    "    n = A.shape[0]\n",
    "\n",
    "    # Initialize embeddings\n",
    "    if initialization == 'random':\n",
    "        S = np.random.randn(n, k)\n",
    "    S, _ = np.linalg.qr(S)\n",
    "\n",
    "    # Compute labeled random walks and attention weights\n",
    "    labeled_walks = perform_labeled_random_walks(G, label_mask, labels, num_walks, walk_length, walk_length_labelled)\n",
    "    attention_weights = compute_attention_weights(S, labeled_walks)\n",
    "\n",
    "    for _ in tqdm(range(iterations), desc=\"Gradient Ascent with Linear Modularity\"):\n",
    "        # Compute modularity gradient using linear approximation\n",
    "        neighbor_agg = A @ S  # Efficient aggregation of neighbor embeddings\n",
    "        global_correction = (degrees[:, None] / (2 * m)) * S.sum(axis=0)\n",
    "        grad_modularity = (1 / (2 * m)) * (neighbor_agg - global_correction)\n",
    "\n",
    "        # Compute supervised gradient\n",
    "        grad_supervised = np.zeros_like(S)\n",
    "        unique_labels = np.unique(labels[label_mask])\n",
    "        for label in unique_labels:\n",
    "            mask = (labels == label) & label_mask\n",
    "            mean_embedding = np.mean(S[mask], axis=0, keepdims=True)\n",
    "            grad_supervised[mask] = S[mask] - mean_embedding\n",
    "\n",
    "        # Compute semi-supervised gradient using adaptive attention\n",
    "        grad_semi_supervised = np.zeros_like(S)\n",
    "        for i in range(n):\n",
    "            if not label_mask[i] and i in attention_weights:\n",
    "                weighted_embedding = sum(weight * S[n] for n, weight in attention_weights[i].items())\n",
    "                grad_semi_supervised[i] = S[i] - weighted_embedding\n",
    "\n",
    "        # Update embeddings\n",
    "        grad_total = grad_modularity - lambda_supervised * grad_supervised - lambda_semi * grad_semi_supervised\n",
    "        S += eta * grad_total\n",
    "        S, _ = np.linalg.qr(S)\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d1fa1ef-526c-4ecb-a4e5-6c344f0412c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_networkx(A):\n",
    "    return nx.from_scipy_sparse_array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7fbba5b-3f7c-4821-9af5-d9d6e982b9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\scipy\\sparse\\_index.py:108: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  self._set_intXint(row, col, x.flat[0])\n"
     ]
    }
   ],
   "source": [
    "dataset = CiteSeerDataset()\n",
    "ground_truth_labels = dataset[0].y\n",
    "labels=np.argmax(ground_truth_labels,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c92de7a7-bab8-4ee8-9601-e4f95f0386e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_be_masked=np.random.choice(np.arange(len(labels)),int(len(labels)*.7),replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0cf50e3-56e5-4187-b4ef-9f05cd3bc76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_labels=[]\n",
    "for i in np.arange(len(labels)):\n",
    "    if i in labels_to_be_masked:\n",
    "        masked_labels.append(-1)\n",
    "    else:\n",
    "        masked_labels.append(labels[i])\n",
    "masked_labels=np.array(masked_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77562c2a-8c15-4b37-a4d3-674776a0edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask = masked_labels != -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "517544ea-62e6-495c-bce9-6733a551c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[0].x\n",
    "A = dataset[0].a\n",
    "G = convert_to_networkx(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75465021-453d-486d-9723-b74392ca9e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency Matrix Shape: (3327, 3327)\n",
      "Graph Nodes: 3327\n",
      "Graph Edges: 4552\n"
     ]
    }
   ],
   "source": [
    "print(\"Adjacency Matrix Shape:\", A.shape)\n",
    "print(\"Graph Nodes:\", G.number_of_nodes())\n",
    "print(\"Graph Edges:\", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2208e44-0f6e-4264-9dd3-472cbb7d14f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert your preprocessed data into a PyTorch Geometric Data object\n",
    "X_py = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float),  # Node features\n",
    "    edge_index=torch.tensor(np.array(A.nonzero()), dtype=torch.long),  # Edge indices\n",
    "    y=torch.tensor(labels, dtype=torch.long)  # Labels\n",
    ")\n",
    "\n",
    "# Ensure edge_index is in the correct shape (2, num_edges)\n",
    "X_py.edge_index = X_py.edge_index.to(torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e5d6c2-f4f6-469d-a965-39236e120c9f",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f4fa5a7-948d-4ef1-9c6d-e952e01aa530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing DeepWalk embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 3327/3327 [00:00<00:00, 7837.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepWalk embedding computed in 131.02 seconds.\n",
      "Computing VGAE embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:18<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGAE embedding computed in 18.64 seconds.\n",
      "Computing DGI embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:30<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGI embedding computed in 30.85 seconds.\n",
      "Computing Modularity embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gradient Ascent with Linear Modularity: 100%|██████████| 200/200 [00:28<00:00,  7.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modularity embedding computed in 28.94 seconds.\n",
      "Computing Node2Vec embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 3327/3327 [00:00<00:00, 10411.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node2Vec embedding computed in 167.55 seconds.\n",
      "Generating Random embedding...\n",
      "Random embedding generated in 0.00 seconds.\n",
      "All embeddings computed and stored in the dictionary successfully.\n",
      "\n",
      "Execution times saved to 'embedding_execution_times.csv'.\n",
      "        Model  Time (seconds)\n",
      "0    DeepWalk      131.022651\n",
      "1        VGAE       18.639882\n",
      "2         DGI       30.845219\n",
      "3  Modularity       28.940452\n",
      "4    Node2Vec      167.550165\n",
      "5      Random        0.000000\n"
     ]
    }
   ],
   "source": [
    "# Dictionary for embeddings\n",
    "embedding_dict = {}\n",
    "execution_times = []  # List to store execution times\n",
    "\n",
    "# Compute embeddings and store them with time tracking\n",
    "def record_time(model_name, func, *args, **kwargs):\n",
    "    print(f\"Computing {model_name} embedding...\")\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    execution_times.append((model_name, elapsed_time))\n",
    "    print(f\"{model_name} embedding computed in {elapsed_time:.2f} seconds.\")\n",
    "    return result\n",
    "\n",
    "X_deepwalk = record_time(\"DeepWalk\", deepwalk_embedding, G, k=embedding_dimensionality)\n",
    "X_deepwalk = tf.convert_to_tensor(X_deepwalk, dtype=tf.float32)\n",
    "embedding_dict['deepwalk'] = X_deepwalk\n",
    "\n",
    "X_vgae = record_time(\"VGAE\", vgae_embedding, X_py, k=embedding_dimensionality)\n",
    "embedding_dict['vgae'] = X_vgae\n",
    "\n",
    "X_dgi = record_time(\"DGI\", dgi_embedding, X_py, k=embedding_dimensionality)\n",
    "embedding_dict['dgi'] = X_dgi\n",
    "\n",
    "X_modularity = record_time(\"Modularity\", semi_supervised_gradient_ascent_modularity,\n",
    "                           G, labels, label_mask, k=embedding_dimensionality,\n",
    "                           eta=0.05, lambda_supervised=1.0, lambda_semi=2.0, iterations=200, initialization='random')\n",
    "embedding_dict['modularity'] = X_modularity\n",
    "\n",
    "X_node2vec = record_time(\"Node2Vec\", node2vec_embedding, G, k=embedding_dimensionality)\n",
    "X_node2vec = tf.convert_to_tensor(X_node2vec, dtype=tf.float32)\n",
    "embedding_dict['node2vec'] = X_node2vec\n",
    "\n",
    "# Generate random embedding\n",
    "print(\"Generating Random embedding...\")\n",
    "start_time = time.time()\n",
    "shape = (len(ground_truth_labels), embedding_dimensionality)\n",
    "X_random = np.random.randn(*shape)\n",
    "X_random = tf.convert_to_tensor(X_random, dtype=tf.float32)\n",
    "end_time = time.time()\n",
    "execution_times.append((\"Random\", end_time - start_time))\n",
    "print(f\"Random embedding generated in {end_time - start_time:.2f} seconds.\")\n",
    "embedding_dict['random'] = X_random\n",
    "\n",
    "# Use original node features as 'given' embedding\n",
    "embedding_dict['given'] = X\n",
    "\n",
    "print(\"All embeddings computed and stored in the dictionary successfully.\")\n",
    "\n",
    "# Store execution times in a DataFrame and save\n",
    "execution_df = pd.DataFrame(execution_times, columns=[\"Model\", \"Time (seconds)\"])\n",
    "execution_df.to_csv(\"./citeseer_analysis_results/embedding_execution_times_citeseer_\"+str(SEED)+\".csv\", index=False)\n",
    "\n",
    "print(\"\\nExecution times saved to 'embedding_execution_times.csv'.\")\n",
    "print(execution_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f1c742-27ef-4688-9641-4f4c07b4b262",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7297774-e5c4-4b87-9cc9-cab07deb7978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_all_embeddings(all_embeddings, labels, label_mask):\n",
    "    \"\"\"\n",
    "    Visualize all embeddings in a grid with 4 columns per row using UMAP.\n",
    "\n",
    "    Parameters:\n",
    "    - all_embeddings: Dictionary where keys are embedding methods, and values are embeddings.\n",
    "    - labels: Labels (numpy array of shape [n_nodes]).\n",
    "    - label_mask: Boolean array indicating known labels (True for known, False for unknown).\n",
    "    \"\"\"\n",
    "    num_embeddings = len(all_embeddings)\n",
    "    num_rows = (num_embeddings + 3) // 4  # Ensure enough rows for all embeddings\n",
    "    fig, axes = plt.subplots(num_rows, 4, figsize=(8.27, 11.69))  # A4 size\n",
    "\n",
    "    for i, (embedding_type, embedding) in tqdm(enumerate(all_embeddings.items()), \n",
    "                                               total=num_embeddings, desc=\"Visualizing embeddings\"):\n",
    "        row, col = divmod(i, 4)\n",
    "        ax = axes[row, col] if num_rows > 1 else axes[col]  # Adjust for single-row case\n",
    "\n",
    "        # Ensure embedding is a NumPy array\n",
    "        if isinstance(embedding, tf.Tensor):\n",
    "            embedding = embedding.numpy()\n",
    "\n",
    "        # Reduce dimensionality using UMAP\n",
    "        reducer = umap.UMAP(n_components=2)\n",
    "        embedding_2d = reducer.fit_transform(embedding)\n",
    "\n",
    "        # Known labels\n",
    "        ax.scatter(embedding_2d[label_mask, 0], embedding_2d[label_mask, 1], \n",
    "                   c=labels[label_mask], cmap=\"Set1\", s=3, alpha=0.7, label=\"Known Labels\",\n",
    "                   edgecolors='none')\n",
    "\n",
    "        # Unknown labels\n",
    "        ax.scatter(embedding_2d[~label_mask, 0], embedding_2d[~label_mask, 1], \n",
    "                   c=labels[~label_mask], cmap=\"Set1\", s=5, alpha=0.7, \n",
    "                   label=\"Unknown Labels\", edgecolors='black', linewidths=0.2)\n",
    "\n",
    "        # Title with smaller font size\n",
    "        ax.set_title(embedding_type.upper(), fontsize=8, pad=2)\n",
    "\n",
    "        # Remove axis labels, ticks, and frames\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "    # Remove empty subplots if num_embeddings is not a multiple of 4\n",
    "    for j in range(i + 1, num_rows * 4):\n",
    "        row, col = divmod(j, 4)\n",
    "        fig.delaxes(axes[row, col])\n",
    "\n",
    "    plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05, wspace=0.2, hspace=0.2)  # Adjust margins\n",
    "    save_path = \"./citeseer_analysis_results/embedding_grid_plot_citeseer.png\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Visualization saved to {save_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73add6f8-ad97-49f5-8f66-88df3b717390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance using accuracy, F1-score, and confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.array): Ground truth labels (integers).\n",
    "        predicted_labels (np.array): Predicted labels (integers).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing accuracy, F1-score, and confusion matrix.\n",
    "    \"\"\"\n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    \n",
    "    # Compute F1-score (macro-averaged)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    #\n",
    "    print(cm)\n",
    "    \n",
    "    # Return results as a dictionary\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad91add-83d2-4b32-a97b-a7b48487c7fe",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2c1c719-f501-4cc5-b805-a99b6ccd647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(tf.keras.Model):\n",
    "    def __init__(self, n_labels, seed=42):  # Use an explicit seed\n",
    "        super().__init__()\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=seed)  # Define initializer\n",
    "        \n",
    "        self.conv1 = GCNConv(16, activation='relu', kernel_initializer=initializer)\n",
    "        self.conv2 = GCNConv(n_labels, activation='softmax', kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        intermediate_embeddings = self.conv1([x, a])  # Store intermediate embeddings\n",
    "        x = self.conv2([intermediate_embeddings, a])\n",
    "        return x, intermediate_embeddings  # Return both final output and intermediate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8b69dfc-2d79-41ae-a12b-2310457f551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GAT model\n",
    "class GAT(tf.keras.Model):\n",
    "    def __init__(self, n_labels, num_heads=8, seed=42):\n",
    "        super().__init__()\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=seed)\n",
    "\n",
    "        self.conv1 = GATConv(16, attn_heads=num_heads, concat_heads=True, activation='elu', kernel_initializer=initializer)\n",
    "        self.conv2 = GATConv(n_labels, attn_heads=1, concat_heads=False, activation='softmax', kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        intermediate_embeddings = self.conv1([x, a])  # Store intermediate embeddings\n",
    "        x = self.conv2([intermediate_embeddings, a])\n",
    "        return x, intermediate_embeddings  # Return both final output and intermediate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59ee2d78-d89d-438a-ba6c-d1fa432882d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphSAGE model\n",
    "class GraphSAGE(tf.keras.Model):\n",
    "    def __init__(self, n_labels, hidden_dim=16, aggregator='mean', seed=42):\n",
    "        super().__init__()\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=seed)\n",
    "\n",
    "        self.conv1 = GraphSageConv(hidden_dim, activation='relu', aggregator=aggregator, kernel_initializer=initializer)\n",
    "        self.conv2 = GraphSageConv(n_labels, activation='softmax', aggregator=aggregator, kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        intermediate_embeddings = self.conv1([x, a])  # Store intermediate embeddings\n",
    "        x = self.conv2([intermediate_embeddings, a])\n",
    "        return x, intermediate_embeddings  # Return both final output and intermediate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ebfcaa9-6146-4785-affc-4a5634d7f2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers=['gcn','gat','graphsage']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c2a60c-9db4-4163-8672-af46eecf074b",
   "metadata": {},
   "source": [
    "## Classification using different node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf56a4ec-ec42-489a-bf1e-13e5773c7a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(embedding_dict, embedding, classifier, ground_truth_labels=ground_truth_labels, masked_labels=masked_labels):\n",
    "    \"the labels have to be one hot encoded\"\n",
    "    \"model take values: gcn, gat, graphsage\"\n",
    "    print('embedding: ' + embedding.upper())\n",
    "    print('model: ' + classifier.upper())\n",
    "\n",
    "    X = embedding_dict[embedding]\n",
    "\n",
    "    print(\"Processing...\")\n",
    "    # Create boolean mask for training\n",
    "    train_mask = masked_labels != -1\n",
    "\n",
    "    # Split the data into training and prediction sets\n",
    "    X_train = X[train_mask]  # Training node features\n",
    "    Y_train = ground_truth_labels[train_mask]  # Training labels (one-hot encoded)\n",
    "    Y_train = tf.cast(Y_train, dtype='int32')\n",
    "    \n",
    "    # Reduce the adjacency matrix to only include training nodes\n",
    "    A_train = A[train_mask, :][:, train_mask]  # Correctly reduce the adjacency matrix\n",
    "    \n",
    "    # Convert sparse adjacency matrix to COO format\n",
    "    A_coo = A_train.tocoo()\n",
    "    indices = np.column_stack((A_coo.row, A_coo.col))  # Corrected indices format\n",
    "    values = A_coo.data\n",
    "    shape = A_coo.shape  # Shape: (num_nodes, num_nodes)\n",
    "    \n",
    "    # Create a sparse tensor for the adjacency matrix\n",
    "    A_train_tensor = tf.sparse.SparseTensor(indices=indices, values=values, dense_shape=shape)\n",
    "    \n",
    "    # Ensure the sparse tensor is ordered correctly\n",
    "    A_train_tensor = tf.sparse.reorder(A_train_tensor)\n",
    "\n",
    "    print(\"Training...\")\n",
    "    # Initialize the model\n",
    "    if classifier == 'gcn':\n",
    "        n_labels = ground_truth_labels.shape[1]  # Number of classes\n",
    "        model = GCN(n_labels)\n",
    "    elif classifier == 'gat':\n",
    "        n_labels = ground_truth_labels.shape[1]  # Number of classes\n",
    "        model = GAT(n_labels)\n",
    "    elif classifier == 'graphsage':\n",
    "        n_labels = ground_truth_labels.shape[1]  # Number of classes\n",
    "        model = GraphSAGE(n_labels)\n",
    "    \n",
    "    # Compile the model (not strictly necessary when using GradientTape, but useful for metrics)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.01),\n",
    "        loss=CategoricalCrossentropy(),\n",
    "        metrics=[CategoricalAccuracy()]\n",
    "    )\n",
    "    \n",
    "    # Print shapes for debugging\n",
    "    print(f\"Shape of X_train: {X_train.shape}\")\n",
    "    print(f\"Shape of A_train_tensor: {A_train_tensor.shape}\")\n",
    "    print(f\"Shape of Y_train: {Y_train.shape}\")\n",
    "    \n",
    "    # Define the optimizer and loss function\n",
    "    optimizer = Adam(learning_rate=0.01)\n",
    "    loss_fn = CategoricalCrossentropy()\n",
    "    \n",
    "    # Training loop with GradientTape\n",
    "    epochs = 200\n",
    "    for epoch in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            predictions, intermediate_embeddings = model([X_train, A_train_tensor])  # Unpack both outputs\n",
    "                \n",
    "            # Compute supervised loss (cross-entropy)\n",
    "            supervised_loss = loss_fn(Y_train, predictions)\n",
    "            \n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(supervised_loss, model.trainable_variables)\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "        # Print loss and accuracy for monitoring\n",
    "        if epoch % 10 == 0:\n",
    "            accuracy = CategoricalAccuracy()(Y_train, predictions)\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {supervised_loss.numpy()}, Accuracy: {accuracy.numpy()}\")\n",
    "\n",
    "    print(\"Predicting...\")\n",
    "    # Prepare the full graph for prediction\n",
    "    X_full = X  # Full node features\n",
    "    A_full = A  # Full adjacency matrix\n",
    "    \n",
    "    # Convert the full adjacency matrix to COO format\n",
    "    A_full_coo = A_full.tocoo()\n",
    "    indices_full = np.column_stack((A_full_coo.row, A_full_coo.col))\n",
    "    values_full = A_full_coo.data\n",
    "    shape_full = A_full_coo.shape\n",
    "    \n",
    "    # Create a sparse tensor for the full adjacency matrix\n",
    "    A_full_tensor = tf.sparse.SparseTensor(indices=indices_full, values=values_full, dense_shape=shape_full)\n",
    "    A_full_tensor = tf.sparse.reorder(A_full_tensor)\n",
    "    \n",
    "    # Make predictions for all nodes\n",
    "    predictions, emb = model([X_full, A_full_tensor])  # Shape: [num_nodes, n_labels]\n",
    "\n",
    "    # Convert predictions to class labels (integers)\n",
    "    predicted_labels = tf.argmax(predictions, axis=1).numpy()  # Shape: [num_nodes]\n",
    "    \n",
    "    # Extract predictions for the masked nodes\n",
    "    predicted_labels_masked = predicted_labels[labels_to_be_masked]\n",
    "\n",
    "    # True labels for the masked nodes\n",
    "    true_labels_masked = labels[labels_to_be_masked]\n",
    "    \n",
    "    # Predicted labels for the masked nodes\n",
    "    predicted_labels_masked = predicted_labels[labels_to_be_masked]\n",
    "    \n",
    "    # Evaluate the model's performance\n",
    "    results = evaluate_model(true_labels_masked, predicted_labels_masked)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Accuracy: {results['accuracy'] * 100:.2f}%\")\n",
    "    print(f\"F1-Score: {results['f1_score']:.4f}\")\n",
    "\n",
    "    results['model'] = classifier\n",
    "    results['embedding'] = embedding\n",
    "\n",
    "    # Return results and intermediate embeddings for visualization\n",
    "    return results, emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "129a6385-cd57-4d97-9da2-721b43c7d42f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding: DEEPWALK\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 150)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n",
      "Epoch 1, Loss: 2.1869518756866455, Accuracy: 0.0810810774564743\n",
      "Epoch 11, Loss: 1.4918746948242188, Accuracy: 0.36836835741996765\n",
      "Epoch 21, Loss: 1.4004707336425781, Accuracy: 0.41941940784454346\n",
      "Epoch 31, Loss: 1.342458724975586, Accuracy: 0.4374374449253082\n",
      "Epoch 41, Loss: 1.2903934717178345, Accuracy: 0.45145145058631897\n",
      "Epoch 51, Loss: 1.2446377277374268, Accuracy: 0.46146145462989807\n",
      "Epoch 61, Loss: 1.2046377658843994, Accuracy: 0.48048049211502075\n",
      "Epoch 71, Loss: 1.1684335470199585, Accuracy: 0.49149149656295776\n",
      "Epoch 81, Loss: 1.1366139650344849, Accuracy: 0.5075075030326843\n",
      "Epoch 91, Loss: 1.1092063188552856, Accuracy: 0.5175175070762634\n",
      "Epoch 101, Loss: 1.0861293077468872, Accuracy: 0.5195195078849792\n",
      "Epoch 111, Loss: 1.0664793252944946, Accuracy: 0.5285285115242004\n",
      "Epoch 121, Loss: 1.050792932510376, Accuracy: 0.5345345139503479\n",
      "Epoch 131, Loss: 1.038114070892334, Accuracy: 0.5365365147590637\n",
      "Epoch 141, Loss: 1.0284368991851807, Accuracy: 0.5375375151634216\n",
      "Epoch 151, Loss: 1.01904296875, Accuracy: 0.5425425171852112\n",
      "Epoch 161, Loss: 1.010300874710083, Accuracy: 0.5455455183982849\n",
      "Epoch 171, Loss: 1.0032970905303955, Accuracy: 0.5455455183982849\n",
      "Epoch 181, Loss: 0.9983753561973572, Accuracy: 0.5505505800247192\n",
      "Epoch 191, Loss: 0.9915279150009155, Accuracy: 0.5485485196113586\n",
      "Predicting...\n",
      "[[ 31  33  37  51  22  11]\n",
      " [ 63 136  96  61  25  22]\n",
      " [ 28  45 294  56  11  17]\n",
      " [ 77  38 140 209  42  10]\n",
      " [ 35  20  36  30 267  18]\n",
      " [ 41  54  50  39  41 142]]\n",
      "Accuracy: 46.35%\n",
      "F1-Score: 0.4358\n",
      "embedding: DEEPWALK\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 150)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.8003129959106445, Accuracy: 0.12312312424182892\n",
      "Epoch 11, Loss: 1.0328199863433838, Accuracy: 0.6446446180343628\n",
      "Epoch 21, Loss: 0.7999384999275208, Accuracy: 0.7187187075614929\n",
      "Epoch 31, Loss: 0.670311689376831, Accuracy: 0.7547547817230225\n",
      "Epoch 41, Loss: 0.563237726688385, Accuracy: 0.792792797088623\n",
      "Epoch 51, Loss: 0.4480130672454834, Accuracy: 0.8328328132629395\n",
      "Epoch 61, Loss: 0.3395926356315613, Accuracy: 0.8668668866157532\n",
      "Epoch 71, Loss: 0.25264424085617065, Accuracy: 0.90190190076828\n",
      "Epoch 81, Loss: 0.2048087865114212, Accuracy: 0.9079079031944275\n",
      "Epoch 91, Loss: 0.177895650267601, Accuracy: 0.913913905620575\n",
      "Epoch 101, Loss: 0.16116918623447418, Accuracy: 0.9219219088554382\n",
      "Epoch 111, Loss: 0.1493750810623169, Accuracy: 0.9209209084510803\n",
      "Epoch 121, Loss: 0.14123834669589996, Accuracy: 0.9259259104728699\n",
      "Epoch 131, Loss: 0.13529320061206818, Accuracy: 0.9269269108772278\n",
      "Epoch 141, Loss: 0.13335135579109192, Accuracy: 0.9269269108772278\n",
      "Epoch 151, Loss: 0.1276792287826538, Accuracy: 0.9289289116859436\n",
      "Epoch 161, Loss: 0.12404248863458633, Accuracy: 0.9289289116859436\n",
      "Epoch 171, Loss: 0.12203870713710785, Accuracy: 0.9299299120903015\n",
      "Epoch 181, Loss: 0.12066081166267395, Accuracy: 0.9299299120903015\n",
      "Epoch 191, Loss: 0.11914562433958054, Accuracy: 0.9299299120903015\n",
      "Predicting...\n",
      "[[ 51  36  16  39  35   8]\n",
      " [ 46 202  56  29  31  39]\n",
      " [ 25  48 293  44  20  21]\n",
      " [ 39  23  61 339  30  24]\n",
      " [ 38  23  16  18 297  14]\n",
      " [ 24  12  34  34  35 228]]\n",
      "Accuracy: 60.57%\n",
      "F1-Score: 0.5724\n",
      "embedding: DEEPWALK\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 150)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n",
      "Epoch 1, Loss: 1.8980573415756226, Accuracy: 0.12412412464618683\n",
      "Epoch 11, Loss: 1.4130010604858398, Accuracy: 0.5955955982208252\n",
      "Epoch 21, Loss: 1.308497428894043, Accuracy: 0.695695698261261\n",
      "Epoch 31, Loss: 1.2527490854263306, Accuracy: 0.7437437176704407\n",
      "Epoch 41, Loss: 1.2127869129180908, Accuracy: 0.7837837934494019\n",
      "Epoch 51, Loss: 1.184942603111267, Accuracy: 0.8148148059844971\n",
      "Epoch 61, Loss: 1.1668802499771118, Accuracy: 0.8368368148803711\n",
      "Epoch 71, Loss: 1.146881103515625, Accuracy: 0.8478478193283081\n",
      "Epoch 81, Loss: 1.131352424621582, Accuracy: 0.857857882976532\n",
      "Epoch 91, Loss: 1.1257065534591675, Accuracy: 0.8618618845939636\n",
      "Epoch 101, Loss: 1.1134601831436157, Accuracy: 0.8758758902549744\n",
      "Epoch 111, Loss: 1.1148648262023926, Accuracy: 0.8788788914680481\n",
      "Epoch 121, Loss: 1.1040472984313965, Accuracy: 0.8918918967247009\n",
      "Epoch 131, Loss: 1.0971423387527466, Accuracy: 0.8978978991508484\n",
      "Epoch 141, Loss: 1.0913630723953247, Accuracy: 0.9099099040031433\n",
      "Epoch 151, Loss: 1.0879271030426025, Accuracy: 0.9099099040031433\n",
      "Epoch 161, Loss: 1.0841110944747925, Accuracy: 0.913913905620575\n",
      "Epoch 171, Loss: 1.0795997381210327, Accuracy: 0.9159159064292908\n",
      "Epoch 181, Loss: 1.075541615486145, Accuracy: 0.923923909664154\n",
      "Epoch 191, Loss: 1.0729845762252808, Accuracy: 0.9269269108772278\n",
      "Predicting...\n",
      "[[ 29  41  12  59  23  21]\n",
      " [ 24 212  63  37  38  29]\n",
      " [  7  44 309  51  20  20]\n",
      " [ 22  31  62 346  20  35]\n",
      " [ 17  25  13  35 289  27]\n",
      " [  6  29  29  22  38 243]]\n",
      "Accuracy: 61.34%\n",
      "F1-Score: 0.5659\n",
      "embedding: VGAE\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 150)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n",
      "Epoch 1, Loss: 1.982161045074463, Accuracy: 0.091091088950634\n",
      "Epoch 11, Loss: 1.5123984813690186, Accuracy: 0.3723723590373993\n",
      "Epoch 21, Loss: 1.3964738845825195, Accuracy: 0.42042040824890137\n",
      "Epoch 31, Loss: 1.311505675315857, Accuracy: 0.45045045018196106\n",
      "Epoch 41, Loss: 1.2348343133926392, Accuracy: 0.4764764904975891\n",
      "Epoch 51, Loss: 1.1688438653945923, Accuracy: 0.5035035014152527\n",
      "Epoch 61, Loss: 1.112242579460144, Accuracy: 0.5275275111198425\n",
      "Epoch 71, Loss: 1.0647478103637695, Accuracy: 0.5455455183982849\n",
      "Epoch 81, Loss: 1.0266313552856445, Accuracy: 0.5625625848770142\n",
      "Epoch 91, Loss: 0.9973621964454651, Accuracy: 0.5715715885162354\n",
      "Epoch 101, Loss: 0.9748789072036743, Accuracy: 0.5785785913467407\n",
      "Epoch 111, Loss: 0.9578569531440735, Accuracy: 0.5795795917510986\n",
      "Epoch 121, Loss: 0.9449031949043274, Accuracy: 0.5815815925598145\n",
      "Epoch 131, Loss: 0.9343994855880737, Accuracy: 0.5845845937728882\n",
      "Epoch 141, Loss: 0.9262655973434448, Accuracy: 0.586586594581604\n",
      "Epoch 151, Loss: 0.9204365611076355, Accuracy: 0.5895895957946777\n",
      "Epoch 161, Loss: 0.915643572807312, Accuracy: 0.5895895957946777\n",
      "Epoch 171, Loss: 0.9120563268661499, Accuracy: 0.5895895957946777\n",
      "Epoch 181, Loss: 0.9091787934303284, Accuracy: 0.5895895957946777\n",
      "Epoch 191, Loss: 0.9066997170448303, Accuracy: 0.5895895957946777\n",
      "Predicting...\n",
      "[[ 40  42  29  43  22   9]\n",
      " [ 53 148  76  36  46  44]\n",
      " [ 28  65 235  71  22  30]\n",
      " [ 62  86  85 208  41  34]\n",
      " [ 58  46  31  19 232  20]\n",
      " [ 34  63  55  37  44 134]]\n",
      "Accuracy: 42.83%\n",
      "F1-Score: 0.4079\n",
      "embedding: VGAE\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 150)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n",
      "Epoch 1, Loss: 1.7940202951431274, Accuracy: 0.15515515208244324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 1.1433528661727905, Accuracy: 0.5735735893249512\n",
      "Epoch 21, Loss: 0.9332072734832764, Accuracy: 0.6906906962394714\n",
      "Epoch 31, Loss: 0.802937388420105, Accuracy: 0.7187187075614929\n",
      "Epoch 41, Loss: 0.6652925610542297, Accuracy: 0.7757757902145386\n",
      "Epoch 51, Loss: 0.4727577567100525, Accuracy: 0.8598598837852478\n",
      "Epoch 61, Loss: 0.2605704963207245, Accuracy: 0.924924910068512\n",
      "Epoch 71, Loss: 0.1451098471879959, Accuracy: 0.9329329133033752\n",
      "Epoch 81, Loss: 0.10853597521781921, Accuracy: 0.9409409165382385\n",
      "Epoch 91, Loss: 0.09562074393033981, Accuracy: 0.9439439177513123\n",
      "Epoch 101, Loss: 0.08868984878063202, Accuracy: 0.946946918964386\n",
      "Epoch 111, Loss: 0.08402939885854721, Accuracy: 0.9479479193687439\n",
      "Epoch 121, Loss: 0.0803171843290329, Accuracy: 0.9499499201774597\n",
      "Epoch 131, Loss: 0.07789738476276398, Accuracy: 0.9519519805908203\n",
      "Epoch 141, Loss: 0.07585285604000092, Accuracy: 0.9519519805908203\n",
      "Epoch 151, Loss: 0.07416900247335434, Accuracy: 0.9529529809951782\n",
      "Epoch 161, Loss: 0.07251762598752975, Accuracy: 0.9539539813995361\n",
      "Epoch 171, Loss: 0.07154741883277893, Accuracy: 0.9529529809951782\n",
      "Epoch 181, Loss: 0.07071294635534286, Accuracy: 0.9539539813995361\n",
      "Epoch 191, Loss: 0.0700245052576065, Accuracy: 0.9539539813995361\n",
      "Predicting...\n",
      "[[ 21  32  29  31  50  22]\n",
      " [ 27 152  72  42  56  54]\n",
      " [ 12  59 281  45  28  26]\n",
      " [ 38  58  76 249  48  47]\n",
      " [ 12  29  35  24 266  40]\n",
      " [  8  31  45  23  68 192]]\n",
      "Accuracy: 49.87%\n",
      "F1-Score: 0.4551\n",
      "embedding: VGAE\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 150)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n",
      "Epoch 1, Loss: 1.9078567028045654, Accuracy: 0.1211211234331131\n",
      "Epoch 11, Loss: 1.3842952251434326, Accuracy: 0.6436436176300049\n",
      "Epoch 21, Loss: 1.2730931043624878, Accuracy: 0.7697697877883911\n",
      "Epoch 31, Loss: 1.2089462280273438, Accuracy: 0.8428428173065186\n",
      "Epoch 41, Loss: 1.166203260421753, Accuracy: 0.8768768906593323\n",
      "Epoch 51, Loss: 1.136333703994751, Accuracy: 0.9069069027900696\n",
      "Epoch 61, Loss: 1.1148778200149536, Accuracy: 0.9159159064292908\n",
      "Epoch 71, Loss: 1.0966405868530273, Accuracy: 0.9289289116859436\n",
      "Epoch 81, Loss: 1.0816534757614136, Accuracy: 0.9379379153251648\n",
      "Epoch 91, Loss: 1.072052001953125, Accuracy: 0.9439439177513123\n",
      "Epoch 101, Loss: 1.0636001825332642, Accuracy: 0.9499499201774597\n",
      "Epoch 111, Loss: 1.0559157133102417, Accuracy: 0.955955982208252\n",
      "Epoch 121, Loss: 1.0505229234695435, Accuracy: 0.9609609842300415\n",
      "Epoch 131, Loss: 1.0454745292663574, Accuracy: 0.9639639854431152\n",
      "Epoch 141, Loss: 1.0412720441818237, Accuracy: 0.965965986251831\n",
      "Epoch 151, Loss: 1.0373058319091797, Accuracy: 0.9689689874649048\n",
      "Epoch 161, Loss: 1.0356757640838623, Accuracy: 0.9739739894866943\n",
      "Epoch 171, Loss: 1.0308008193969727, Accuracy: 0.9759759902954102\n",
      "Epoch 181, Loss: 1.0276288986206055, Accuracy: 0.9759759902954102\n",
      "Epoch 191, Loss: 1.0253525972366333, Accuracy: 0.977977991104126\n",
      "Predicting...\n",
      "[[  4  48  25  38  47  23]\n",
      " [  9 173  74  67  41  39]\n",
      " [  2  59 271  58  28  33]\n",
      " [ 13  82  62 250  67  42]\n",
      " [  6  59  37  42 239  23]\n",
      " [  5  97  47  51  52 115]]\n",
      "Accuracy: 45.19%\n",
      "F1-Score: 0.3938\n",
      "embedding: DGI\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 150)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n",
      "Epoch 1, Loss: 1.9266494512557983, Accuracy: 0.07907907664775848\n",
      "Epoch 11, Loss: 1.704514741897583, Accuracy: 0.23823824524879456\n",
      "Epoch 21, Loss: 1.6769667863845825, Accuracy: 0.2512512505054474\n",
      "Epoch 31, Loss: 1.654510259628296, Accuracy: 0.2532532513141632\n",
      "Epoch 41, Loss: 1.639854907989502, Accuracy: 0.28928929567337036\n",
      "Epoch 51, Loss: 1.6229368448257446, Accuracy: 0.30730730295181274\n",
      "Epoch 61, Loss: 1.6065781116485596, Accuracy: 0.31631630659103394\n",
      "Epoch 71, Loss: 1.588560938835144, Accuracy: 0.33033034205436707\n",
      "Epoch 81, Loss: 1.5702110528945923, Accuracy: 0.3453453481197357\n",
      "Epoch 91, Loss: 1.5525420904159546, Accuracy: 0.35035035014152527\n",
      "Epoch 101, Loss: 1.535919427871704, Accuracy: 0.3513513505458832\n",
      "Epoch 111, Loss: 1.5204864740371704, Accuracy: 0.353353351354599\n",
      "Epoch 121, Loss: 1.5061911344528198, Accuracy: 0.36036035418510437\n",
      "Epoch 131, Loss: 1.4928193092346191, Accuracy: 0.36736735701560974\n",
      "Epoch 141, Loss: 1.4800677299499512, Accuracy: 0.3743743598461151\n",
      "Epoch 151, Loss: 1.4674402475357056, Accuracy: 0.37937939167022705\n",
      "Epoch 161, Loss: 1.4555299282073975, Accuracy: 0.37837839126586914\n",
      "Epoch 171, Loss: 1.4451199769973755, Accuracy: 0.3843843936920166\n",
      "Epoch 181, Loss: 1.4339103698730469, Accuracy: 0.3853853940963745\n",
      "Epoch 191, Loss: 1.423105001449585, Accuracy: 0.38938939571380615\n",
      "Predicting...\n",
      "[[  0  63  17  45  37  23]\n",
      " [  3 151  80  81  44  44]\n",
      " [  0  50 277  60  30  34]\n",
      " [  0 129  84 131  90  82]\n",
      " [  0  40  65  59 204  38]\n",
      " [  0  73  47  42  42 163]]\n",
      "Accuracy: 39.78%\n",
      "F1-Score: 0.3446\n",
      "embedding: DGI\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 150)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n",
      "Epoch 1, Loss: 1.7924904823303223, Accuracy: 0.1911911964416504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 1.668418288230896, Accuracy: 0.3033033013343811\n",
      "Epoch 21, Loss: 1.5815640687942505, Accuracy: 0.36636635661125183\n",
      "Epoch 31, Loss: 1.4888790845870972, Accuracy: 0.4264264404773712\n",
      "Epoch 41, Loss: 1.4053030014038086, Accuracy: 0.473473459482193\n",
      "Epoch 51, Loss: 1.340527892112732, Accuracy: 0.49049049615859985\n",
      "Epoch 61, Loss: 1.2995831966400146, Accuracy: 0.5185185074806213\n",
      "Epoch 71, Loss: 1.2657450437545776, Accuracy: 0.5275275111198425\n",
      "Epoch 81, Loss: 1.2153985500335693, Accuracy: 0.5655655860900879\n",
      "Epoch 91, Loss: 1.1767123937606812, Accuracy: 0.586586594581604\n",
      "Epoch 101, Loss: 1.1435835361480713, Accuracy: 0.5885885953903198\n",
      "Epoch 111, Loss: 1.1182241439819336, Accuracy: 0.6026026010513306\n",
      "Epoch 121, Loss: 1.0874989032745361, Accuracy: 0.6166166067123413\n",
      "Epoch 131, Loss: 1.0562204122543335, Accuracy: 0.6366366147994995\n",
      "Epoch 141, Loss: 1.026378870010376, Accuracy: 0.6526526808738708\n",
      "Epoch 151, Loss: 1.0186139345169067, Accuracy: 0.6526526808738708\n",
      "Epoch 161, Loss: 0.9914034605026245, Accuracy: 0.6656656861305237\n",
      "Epoch 171, Loss: 0.9605759382247925, Accuracy: 0.6746746897697449\n",
      "Epoch 181, Loss: 0.9789051413536072, Accuracy: 0.6666666865348816\n",
      "Epoch 191, Loss: 1.0337550640106201, Accuracy: 0.6176176071166992\n",
      "Predicting...\n",
      "[[  3  34  34  16  35  63]\n",
      " [  7 108 119  27  45  97]\n",
      " [  6  21 327  25  18  54]\n",
      " [  8  48  91 186  67 116]\n",
      " [  2  30  27  29 244  74]\n",
      " [  2  34  41  19  41 230]]\n",
      "Accuracy: 47.16%\n",
      "F1-Score: 0.4052\n",
      "embedding: DGI\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 150)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n",
      "Epoch 1, Loss: 1.8574199676513672, Accuracy: 0.21721722185611725\n",
      "Epoch 11, Loss: 1.6978604793548584, Accuracy: 0.29929929971694946\n",
      "Epoch 21, Loss: 1.652321696281433, Accuracy: 0.3443443477153778\n",
      "Epoch 31, Loss: 1.6188576221466064, Accuracy: 0.36936935782432556\n",
      "Epoch 41, Loss: 1.5682264566421509, Accuracy: 0.4354354441165924\n",
      "Epoch 51, Loss: 1.513515591621399, Accuracy: 0.49149149656295776\n",
      "Epoch 61, Loss: 1.480625867843628, Accuracy: 0.5235235095024109\n",
      "Epoch 71, Loss: 1.4663447141647339, Accuracy: 0.5415415167808533\n",
      "Epoch 81, Loss: 1.4525880813598633, Accuracy: 0.5505505800247192\n",
      "Epoch 91, Loss: 1.4262278079986572, Accuracy: 0.5625625848770142\n",
      "Epoch 101, Loss: 1.407520055770874, Accuracy: 0.5935935974121094\n",
      "Epoch 111, Loss: 1.3982347249984741, Accuracy: 0.6006006002426147\n",
      "Epoch 121, Loss: 1.387002944946289, Accuracy: 0.6166166067123413\n",
      "Epoch 131, Loss: 1.3865476846694946, Accuracy: 0.619619607925415\n",
      "Epoch 141, Loss: 1.378286361694336, Accuracy: 0.6256256103515625\n",
      "Epoch 151, Loss: 1.382826566696167, Accuracy: 0.6236236095428467\n",
      "Epoch 161, Loss: 1.380379557609558, Accuracy: 0.6146146059036255\n",
      "Epoch 171, Loss: 1.3574374914169312, Accuracy: 0.650650680065155\n",
      "Epoch 181, Loss: 1.3599400520324707, Accuracy: 0.650650680065155\n",
      "Epoch 191, Loss: 1.3563909530639648, Accuracy: 0.6526526808738708\n",
      "Predicting...\n",
      "[[ 12  45  20  51  43  14]\n",
      " [ 22 120  81  77  75  28]\n",
      " [  5  41 284  62  37  22]\n",
      " [ 17  79  57 223 105  35]\n",
      " [ 15  22  18  50 288  13]\n",
      " [ 15  44  44  42 100 122]]\n",
      "Accuracy: 45.06%\n",
      "F1-Score: 0.3985\n",
      "embedding: MODULARITY\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 150)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n",
      "Epoch 1, Loss: 1.7951313257217407, Accuracy: 0.07907907664775848\n",
      "Epoch 11, Loss: 1.707343578338623, Accuracy: 0.30730730295181274\n",
      "Epoch 21, Loss: 1.610396146774292, Accuracy: 0.4264264404773712\n",
      "Epoch 31, Loss: 1.5134694576263428, Accuracy: 0.4974974989891052\n",
      "Epoch 41, Loss: 1.4223873615264893, Accuracy: 0.522522509098053\n",
      "Epoch 51, Loss: 1.3387818336486816, Accuracy: 0.5455455183982849\n",
      "Epoch 61, Loss: 1.265272617340088, Accuracy: 0.5555555820465088\n",
      "Epoch 71, Loss: 1.2020819187164307, Accuracy: 0.5765765905380249\n",
      "Epoch 81, Loss: 1.1495565176010132, Accuracy: 0.5775775909423828\n",
      "Epoch 91, Loss: 1.107491374015808, Accuracy: 0.5795795917510986\n",
      "Epoch 101, Loss: 1.074985384941101, Accuracy: 0.5805805921554565\n",
      "Epoch 111, Loss: 1.050249457359314, Accuracy: 0.5815815925598145\n",
      "Epoch 121, Loss: 1.0314205884933472, Accuracy: 0.5815815925598145\n",
      "Epoch 131, Loss: 1.0168099403381348, Accuracy: 0.5825825929641724\n",
      "Epoch 141, Loss: 1.0051189661026, Accuracy: 0.5825825929641724\n",
      "Epoch 151, Loss: 0.9960136413574219, Accuracy: 0.5835835933685303\n",
      "Epoch 161, Loss: 0.9885092377662659, Accuracy: 0.5825825929641724\n",
      "Epoch 171, Loss: 0.9808710813522339, Accuracy: 0.5825825929641724\n",
      "Epoch 181, Loss: 0.9750218987464905, Accuracy: 0.5825825929641724\n",
      "Epoch 191, Loss: 0.9698364734649658, Accuracy: 0.5825825929641724\n",
      "Predicting...\n",
      "[[ 41  41  16  39  35  13]\n",
      " [ 41 206  65  35  30  26]\n",
      " [ 16  23 336  31  27  18]\n",
      " [ 28  34  74 332  33  15]\n",
      " [ 19  23  12  22 315  15]\n",
      " [ 10  24  38  24  37 234]]\n",
      "Accuracy: 62.89%\n",
      "F1-Score: 0.5872\n",
      "embedding: MODULARITY\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 150)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.792133092880249, Accuracy: 0.07707707583904266\n",
      "Epoch 11, Loss: 1.5998426675796509, Accuracy: 0.6706706881523132\n",
      "Epoch 21, Loss: 1.1777383089065552, Accuracy: 0.9199199080467224\n",
      "Epoch 31, Loss: 0.6070935726165771, Accuracy: 0.9189189076423645\n",
      "Epoch 41, Loss: 0.261653333902359, Accuracy: 0.9209209084510803\n",
      "Epoch 51, Loss: 0.1681051254272461, Accuracy: 0.9269269108772278\n",
      "Epoch 61, Loss: 0.14620691537857056, Accuracy: 0.9279279112815857\n",
      "Epoch 71, Loss: 0.1380033791065216, Accuracy: 0.9279279112815857\n",
      "Epoch 81, Loss: 0.1330478936433792, Accuracy: 0.9269269108772278\n",
      "Epoch 91, Loss: 0.12941698729991913, Accuracy: 0.9299299120903015\n",
      "Epoch 101, Loss: 0.12644821405410767, Accuracy: 0.9309309124946594\n",
      "Epoch 111, Loss: 0.12352302670478821, Accuracy: 0.9309309124946594\n",
      "Epoch 121, Loss: 0.12077997624874115, Accuracy: 0.9309309124946594\n",
      "Epoch 131, Loss: 0.11691496521234512, Accuracy: 0.9329329133033752\n",
      "Epoch 141, Loss: 0.11363297700881958, Accuracy: 0.9349349141120911\n",
      "Epoch 151, Loss: 0.10687746107578278, Accuracy: 0.9429429173469543\n",
      "Epoch 161, Loss: 0.10277266055345535, Accuracy: 0.9429429173469543\n",
      "Epoch 171, Loss: 0.09989653527736664, Accuracy: 0.9449449181556702\n",
      "Epoch 181, Loss: 0.0974796786904335, Accuracy: 0.946946918964386\n",
      "Epoch 191, Loss: 0.09537072479724884, Accuracy: 0.9479479193687439\n",
      "Predicting...\n",
      "[[ 39  46  25  28  36  11]\n",
      " [ 31 212  89  20  32  19]\n",
      " [ 19  17 345  33  23  14]\n",
      " [ 29  51  75 313  31  17]\n",
      " [ 16  19  13  17 324  17]\n",
      " [ 14  22  46  17  33 235]]\n",
      "Accuracy: 63.06%\n",
      "F1-Score: 0.5887\n",
      "embedding: MODULARITY\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 150)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n",
      "Epoch 1, Loss: 2.1615970134735107, Accuracy: 0.07807807624340057\n",
      "Epoch 11, Loss: 1.2358195781707764, Accuracy: 0.9699699878692627\n",
      "Epoch 21, Loss: 1.1238102912902832, Accuracy: 0.988988995552063\n",
      "Epoch 31, Loss: 1.0611106157302856, Accuracy: 0.988988995552063\n",
      "Epoch 41, Loss: 1.024475336074829, Accuracy: 0.9949949979782104\n",
      "Epoch 51, Loss: 1.0068453550338745, Accuracy: 0.9969969987869263\n",
      "Epoch 61, Loss: 1.0006015300750732, Accuracy: 0.9979979991912842\n",
      "Epoch 71, Loss: 0.9979546666145325, Accuracy: 0.9989989995956421\n",
      "Epoch 81, Loss: 0.9959815740585327, Accuracy: 1.0\n",
      "Epoch 91, Loss: 0.9945876598358154, Accuracy: 1.0\n",
      "Epoch 101, Loss: 0.9932782053947449, Accuracy: 1.0\n",
      "Epoch 111, Loss: 0.9921176433563232, Accuracy: 1.0\n",
      "Epoch 121, Loss: 0.9910578727722168, Accuracy: 1.0\n",
      "Epoch 131, Loss: 0.9900758266448975, Accuracy: 1.0\n",
      "Epoch 141, Loss: 0.9891771674156189, Accuracy: 1.0\n",
      "Epoch 151, Loss: 0.9883575439453125, Accuracy: 1.0\n",
      "Epoch 161, Loss: 0.9876173734664917, Accuracy: 1.0\n",
      "Epoch 171, Loss: 0.9869593381881714, Accuracy: 1.0\n",
      "Epoch 181, Loss: 0.9863746762275696, Accuracy: 1.0\n",
      "Epoch 191, Loss: 0.9858554601669312, Accuracy: 1.0\n",
      "Predicting...\n",
      "[[ 44  37  19  31  33  21]\n",
      " [ 40 199  72  18  41  33]\n",
      " [ 15  25 327  33  34  17]\n",
      " [ 32  36  72 311  42  23]\n",
      " [ 22  19  18  19 309  19]\n",
      " [ 16  16  42  14  41 238]]\n",
      "Accuracy: 61.34%\n",
      "F1-Score: 0.5748\n",
      "embedding: NODE2VEC\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 150)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n",
      "Epoch 1, Loss: 2.0408213138580322, Accuracy: 0.11011011153459549\n",
      "Epoch 11, Loss: 1.4594383239746094, Accuracy: 0.37737739086151123\n",
      "Epoch 21, Loss: 1.3549933433532715, Accuracy: 0.4344344437122345\n",
      "Epoch 31, Loss: 1.2765074968338013, Accuracy: 0.462462455034256\n",
      "Epoch 41, Loss: 1.2070730924606323, Accuracy: 0.4844844937324524\n",
      "Epoch 51, Loss: 1.1506223678588867, Accuracy: 0.5105105042457581\n",
      "Epoch 61, Loss: 1.1066181659698486, Accuracy: 0.5195195078849792\n",
      "Epoch 71, Loss: 1.076224446296692, Accuracy: 0.5245245099067688\n",
      "Epoch 81, Loss: 1.052599549293518, Accuracy: 0.5295295119285583\n",
      "Epoch 91, Loss: 1.0333799123764038, Accuracy: 0.53353351354599\n",
      "Epoch 101, Loss: 1.0202962160110474, Accuracy: 0.5415415167808533\n",
      "Epoch 111, Loss: 1.009355902671814, Accuracy: 0.5485485196113586\n",
      "Epoch 121, Loss: 1.0012003183364868, Accuracy: 0.5435435175895691\n",
      "Epoch 131, Loss: 0.9931515455245972, Accuracy: 0.5545545816421509\n",
      "Epoch 141, Loss: 0.9872124195098877, Accuracy: 0.5545545816421509\n",
      "Epoch 151, Loss: 0.9827367067337036, Accuracy: 0.5575575828552246\n",
      "Epoch 161, Loss: 0.9778894782066345, Accuracy: 0.5615615844726562\n",
      "Epoch 171, Loss: 0.9732391834259033, Accuracy: 0.5635635852813721\n",
      "Epoch 181, Loss: 0.9697535634040833, Accuracy: 0.5695695877075195\n",
      "Epoch 191, Loss: 0.9676228761672974, Accuracy: 0.5665665864944458\n",
      "Predicting...\n",
      "[[ 26  31  33  59  19  17]\n",
      " [ 60 136  77  69  31  30]\n",
      " [ 21  41 302  57  17  13]\n",
      " [ 45  62 106 243  38  22]\n",
      " [ 32  19  19  60 266  10]\n",
      " [ 48  32  55  48  47 137]]\n",
      "Accuracy: 47.68%\n",
      "F1-Score: 0.4411\n",
      "embedding: NODE2VEC\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 150)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.7960402965545654, Accuracy: 0.13713712990283966\n",
      "Epoch 11, Loss: 1.0167691707611084, Accuracy: 0.6496496200561523\n",
      "Epoch 21, Loss: 0.7866694927215576, Accuracy: 0.7477477192878723\n",
      "Epoch 31, Loss: 0.6579179167747498, Accuracy: 0.7797797918319702\n",
      "Epoch 41, Loss: 0.5515264272689819, Accuracy: 0.8058058023452759\n",
      "Epoch 51, Loss: 0.45395368337631226, Accuracy: 0.8468468189239502\n",
      "Epoch 61, Loss: 0.34283408522605896, Accuracy: 0.8828828930854797\n",
      "Epoch 71, Loss: 0.2533355951309204, Accuracy: 0.9049049019813538\n",
      "Epoch 81, Loss: 0.20096611976623535, Accuracy: 0.9149149060249329\n",
      "Epoch 91, Loss: 0.1721351593732834, Accuracy: 0.9169169068336487\n",
      "Epoch 101, Loss: 0.15580280125141144, Accuracy: 0.9219219088554382\n",
      "Epoch 111, Loss: 0.14568829536437988, Accuracy: 0.923923909664154\n",
      "Epoch 121, Loss: 0.13873229920864105, Accuracy: 0.9269269108772278\n",
      "Epoch 131, Loss: 0.13532496988773346, Accuracy: 0.9289289116859436\n",
      "Epoch 141, Loss: 0.12957584857940674, Accuracy: 0.9289289116859436\n",
      "Epoch 151, Loss: 0.126447856426239, Accuracy: 0.9289289116859436\n",
      "Epoch 161, Loss: 0.12403145432472229, Accuracy: 0.9289289116859436\n",
      "Epoch 171, Loss: 0.12166521698236465, Accuracy: 0.9309309124946594\n",
      "Epoch 181, Loss: 0.12037131935358047, Accuracy: 0.9319319128990173\n",
      "Epoch 191, Loss: 0.11934378743171692, Accuracy: 0.9279279112815857\n",
      "Predicting...\n",
      "[[ 34  34  29  42  36  10]\n",
      " [ 33 206  61  32  35  36]\n",
      " [ 11  29 321  33  27  30]\n",
      " [ 23  41  62 338  29  23]\n",
      " [ 23  24  19  29 271  40]\n",
      " [  9  28  40  23  38 229]]\n",
      "Accuracy: 60.09%\n",
      "F1-Score: 0.5566\n",
      "embedding: NODE2VEC\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 150)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n",
      "Epoch 1, Loss: 1.8704376220703125, Accuracy: 0.13413412868976593\n",
      "Epoch 11, Loss: 1.3857510089874268, Accuracy: 0.6146146059036255\n",
      "Epoch 21, Loss: 1.2948555946350098, Accuracy: 0.7017017006874084\n",
      "Epoch 31, Loss: 1.249266505241394, Accuracy: 0.7567567825317383\n",
      "Epoch 41, Loss: 1.2147921323776245, Accuracy: 0.7987987995147705\n",
      "Epoch 51, Loss: 1.187843680381775, Accuracy: 0.8248248100280762\n",
      "Epoch 61, Loss: 1.1679078340530396, Accuracy: 0.8338338136672974\n",
      "Epoch 71, Loss: 1.1509729623794556, Accuracy: 0.8498498201370239\n",
      "Epoch 81, Loss: 1.1398941278457642, Accuracy: 0.8608608841896057\n",
      "Epoch 91, Loss: 1.1295274496078491, Accuracy: 0.868868887424469\n",
      "Epoch 101, Loss: 1.121771216392517, Accuracy: 0.8728728890419006\n",
      "Epoch 111, Loss: 1.1177791357040405, Accuracy: 0.8828828930854797\n",
      "Epoch 121, Loss: 1.113059639930725, Accuracy: 0.890890896320343\n",
      "Epoch 131, Loss: 1.1024523973464966, Accuracy: 0.8948948979377747\n",
      "Epoch 141, Loss: 1.0964545011520386, Accuracy: 0.9009009003639221\n",
      "Epoch 151, Loss: 1.0914703607559204, Accuracy: 0.8998998999595642\n",
      "Epoch 161, Loss: 1.0919010639190674, Accuracy: 0.90190190076828\n",
      "Epoch 171, Loss: 1.0834060907363892, Accuracy: 0.9149149060249329\n",
      "Epoch 181, Loss: 1.092182993888855, Accuracy: 0.9059059023857117\n",
      "Epoch 191, Loss: 1.0793429613113403, Accuracy: 0.9159159064292908\n",
      "Predicting...\n",
      "[[ 40  30  17  31  46  21]\n",
      " [ 32 199  71  35  37  29]\n",
      " [ 13  33 335  38  19  13]\n",
      " [ 26  40  67 336  28  19]\n",
      " [ 22  22  16  27 304  15]\n",
      " [ 16  29  47  31  41 203]]\n",
      "Accuracy: 60.87%\n",
      "F1-Score: 0.5658\n",
      "embedding: RANDOM\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 150)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n",
      "Epoch 1, Loss: 2.668814182281494, Accuracy: 0.10810811072587967\n",
      "Epoch 11, Loss: 1.4128549098968506, Accuracy: 0.3943943977355957\n",
      "Epoch 21, Loss: 1.2502731084823608, Accuracy: 0.4744744598865509\n",
      "Epoch 31, Loss: 1.139374017715454, Accuracy: 0.5255255103111267\n",
      "Epoch 41, Loss: 1.061035394668579, Accuracy: 0.553553581237793\n",
      "Epoch 51, Loss: 1.0075746774673462, Accuracy: 0.5685685873031616\n",
      "Epoch 61, Loss: 0.9724202752113342, Accuracy: 0.575575590133667\n",
      "Epoch 71, Loss: 0.949202835559845, Accuracy: 0.5815815925598145\n",
      "Epoch 81, Loss: 0.9337880611419678, Accuracy: 0.5855855941772461\n",
      "Epoch 91, Loss: 0.9236841201782227, Accuracy: 0.5875875949859619\n",
      "Epoch 101, Loss: 0.9167916774749756, Accuracy: 0.5885885953903198\n",
      "Epoch 111, Loss: 0.9119037985801697, Accuracy: 0.5885885953903198\n",
      "Epoch 121, Loss: 0.908405601978302, Accuracy: 0.5885885953903198\n",
      "Epoch 131, Loss: 0.9058557748794556, Accuracy: 0.5895895957946777\n",
      "Epoch 141, Loss: 0.9039932489395142, Accuracy: 0.5895895957946777\n",
      "Epoch 151, Loss: 0.9024627804756165, Accuracy: 0.5895895957946777\n",
      "Epoch 161, Loss: 0.901236891746521, Accuracy: 0.5895895957946777\n",
      "Epoch 171, Loss: 0.9002265930175781, Accuracy: 0.5895895957946777\n",
      "Epoch 181, Loss: 0.8996621370315552, Accuracy: 0.5895895957946777\n",
      "Epoch 191, Loss: 0.8987335562705994, Accuracy: 0.5905905961990356\n",
      "Predicting...\n",
      "[[ 18  45  34  38  44   6]\n",
      " [ 37 125  96  50  55  40]\n",
      " [ 25  61 203  60  65  37]\n",
      " [ 57  97 102 127 107  26]\n",
      " [ 59  56  94  50 115  32]\n",
      " [ 48  66  87  57  67  42]]\n",
      "Accuracy: 27.06%\n",
      "F1-Score: 0.2435\n",
      "embedding: RANDOM\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 150)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.8004229068756104, Accuracy: 0.16716717183589935\n",
      "Epoch 11, Loss: 0.9381479024887085, Accuracy: 0.6676676869392395\n",
      "Epoch 21, Loss: 0.26613864302635193, Accuracy: 0.9259259104728699\n",
      "Epoch 31, Loss: 0.09135778993368149, Accuracy: 0.9459459185600281\n",
      "Epoch 41, Loss: 0.07612477988004684, Accuracy: 0.9529529809951782\n",
      "Epoch 51, Loss: 0.0708220973610878, Accuracy: 0.9539539813995361\n",
      "Epoch 61, Loss: 0.0693359449505806, Accuracy: 0.9529529809951782\n",
      "Epoch 71, Loss: 0.06712371855974197, Accuracy: 0.954954981803894\n",
      "Epoch 81, Loss: 0.06628608703613281, Accuracy: 0.954954981803894\n",
      "Epoch 91, Loss: 0.0658077523112297, Accuracy: 0.954954981803894\n",
      "Epoch 101, Loss: 0.06547375023365021, Accuracy: 0.954954981803894\n",
      "Epoch 111, Loss: 0.06521196663379669, Accuracy: 0.9539539813995361\n",
      "Epoch 121, Loss: 0.06580360978841782, Accuracy: 0.954954981803894\n",
      "Epoch 131, Loss: 0.06452811509370804, Accuracy: 0.955955982208252\n",
      "Epoch 141, Loss: 0.06404764950275421, Accuracy: 0.954954981803894\n",
      "Epoch 151, Loss: 0.06387922167778015, Accuracy: 0.955955982208252\n",
      "Epoch 161, Loss: 0.06944528222084045, Accuracy: 0.954954981803894\n",
      "Epoch 171, Loss: 0.06741420179605484, Accuracy: 0.9539539813995361\n",
      "Epoch 181, Loss: 0.08541614562273026, Accuracy: 0.9509509801864624\n",
      "Epoch 191, Loss: 0.07261840999126434, Accuracy: 0.9539539813995361\n",
      "Predicting...\n",
      "[[ 17  40  45  25  35  23]\n",
      " [ 21 108 132  50  59  33]\n",
      " [ 20  46 277  41  36  31]\n",
      " [ 29  92 171 111  63  50]\n",
      " [ 14  54 142  54  97  45]\n",
      " [ 15  48 102  29  58 115]]\n",
      "Accuracy: 31.14%\n",
      "F1-Score: 0.2797\n",
      "embedding: RANDOM\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 150)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n",
      "Epoch 1, Loss: 1.8703821897506714, Accuracy: 0.1411411464214325\n",
      "Epoch 11, Loss: 1.4217585325241089, Accuracy: 0.608608603477478\n",
      "Epoch 21, Loss: 1.2864797115325928, Accuracy: 0.7687687873840332\n",
      "Epoch 31, Loss: 1.2065117359161377, Accuracy: 0.8738738894462585\n",
      "Epoch 41, Loss: 1.1551129817962646, Accuracy: 0.9099099040031433\n",
      "Epoch 51, Loss: 1.1205906867980957, Accuracy: 0.9349349141120911\n",
      "Epoch 61, Loss: 1.0963666439056396, Accuracy: 0.9519519805908203\n",
      "Epoch 71, Loss: 1.0793988704681396, Accuracy: 0.955955982208252\n",
      "Epoch 81, Loss: 1.0663081407546997, Accuracy: 0.9639639854431152\n",
      "Epoch 91, Loss: 1.0569686889648438, Accuracy: 0.9649649858474731\n",
      "Epoch 101, Loss: 1.0475631952285767, Accuracy: 0.9689689874649048\n",
      "Epoch 111, Loss: 1.0423229932785034, Accuracy: 0.9729729890823364\n",
      "Epoch 121, Loss: 1.0363738536834717, Accuracy: 0.9739739894866943\n",
      "Epoch 131, Loss: 1.0308165550231934, Accuracy: 0.9749749898910522\n",
      "Epoch 141, Loss: 1.0273011922836304, Accuracy: 0.977977991104126\n",
      "Epoch 151, Loss: 1.0238324403762817, Accuracy: 0.9799799919128418\n",
      "Epoch 161, Loss: 1.0213053226470947, Accuracy: 0.9819819927215576\n",
      "Epoch 171, Loss: 1.0189288854599, Accuracy: 0.9829829931259155\n",
      "Epoch 181, Loss: 1.017915964126587, Accuracy: 0.9839839935302734\n",
      "Epoch 191, Loss: 1.0156848430633545, Accuracy: 0.9849849939346313\n",
      "Predicting...\n",
      "[[  3  39  26  71  40   6]\n",
      " [  5  94  84  99 108  13]\n",
      " [  7  91 105 107 121  20]\n",
      " [  6  93 116 154 127  20]\n",
      " [  4  72  81 107 132  10]\n",
      " [  3  74  87  97  85  21]]\n",
      "Accuracy: 21.86%\n",
      "F1-Score: 0.1808\n",
      "embedding: GIVEN\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 3703)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n",
      "Epoch 1, Loss: 1.8183159828186035, Accuracy: 0.10710711032152176\n",
      "Epoch 11, Loss: 1.0484635829925537, Accuracy: 0.5595595836639404\n",
      "Epoch 21, Loss: 0.9274643659591675, Accuracy: 0.5875875949859619\n",
      "Epoch 31, Loss: 0.9080040454864502, Accuracy: 0.5875875949859619\n",
      "Epoch 41, Loss: 0.9028612375259399, Accuracy: 0.5875875949859619\n",
      "Epoch 51, Loss: 0.9005852341651917, Accuracy: 0.5875875949859619\n",
      "Epoch 61, Loss: 0.8994768857955933, Accuracy: 0.5875875949859619\n",
      "Epoch 71, Loss: 0.8987751603126526, Accuracy: 0.5875875949859619\n",
      "Epoch 81, Loss: 0.8984630107879639, Accuracy: 0.5875875949859619\n",
      "Epoch 91, Loss: 0.8978582620620728, Accuracy: 0.5875875949859619\n",
      "Epoch 101, Loss: 0.8975996971130371, Accuracy: 0.5875875949859619\n",
      "Epoch 111, Loss: 0.8969108462333679, Accuracy: 0.5885885953903198\n",
      "Epoch 121, Loss: 0.896541178226471, Accuracy: 0.5905905961990356\n",
      "Epoch 131, Loss: 0.8961899876594543, Accuracy: 0.5905905961990356\n",
      "Epoch 141, Loss: 0.8957930207252502, Accuracy: 0.5905905961990356\n",
      "Epoch 151, Loss: 0.8954219222068787, Accuracy: 0.5905905961990356\n",
      "Epoch 161, Loss: 0.8951326012611389, Accuracy: 0.5905905961990356\n",
      "Epoch 171, Loss: 0.8948593139648438, Accuracy: 0.5905905961990356\n",
      "Epoch 181, Loss: 0.8946126103401184, Accuracy: 0.5905905961990356\n",
      "Epoch 191, Loss: 0.8943825364112854, Accuracy: 0.5905905961990356\n",
      "Predicting...\n",
      "[[ 49  55  12  28  34   7]\n",
      " [ 48 258  61   9  20   7]\n",
      " [ 12  50 333  28  16  12]\n",
      " [ 25  59  84 306  40   2]\n",
      " [ 18  31  13  12 327   5]\n",
      " [ 53  30  27  12  45 200]]\n",
      "Accuracy: 63.27%\n",
      "F1-Score: 0.5979\n",
      "embedding: GIVEN\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 3703)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.790566086769104, Accuracy: 0.19719719886779785\n",
      "Epoch 11, Loss: 0.14630603790283203, Accuracy: 0.9219219088554382\n",
      "Epoch 21, Loss: 0.1044120118021965, Accuracy: 0.9399399161338806\n",
      "Epoch 31, Loss: 0.09035292267799377, Accuracy: 0.9459459185600281\n",
      "Epoch 41, Loss: 0.08279518038034439, Accuracy: 0.9479479193687439\n",
      "Epoch 51, Loss: 0.07794938236474991, Accuracy: 0.9479479193687439\n",
      "Epoch 61, Loss: 0.07498271018266678, Accuracy: 0.9489489197731018\n",
      "Epoch 71, Loss: 0.0733448714017868, Accuracy: 0.9509509801864624\n",
      "Epoch 81, Loss: 0.07225412875413895, Accuracy: 0.9519519805908203\n",
      "Epoch 91, Loss: 0.07146193087100983, Accuracy: 0.9529529809951782\n",
      "Epoch 101, Loss: 0.06964485347270966, Accuracy: 0.9529529809951782\n",
      "Epoch 111, Loss: 0.06888776272535324, Accuracy: 0.9539539813995361\n",
      "Epoch 121, Loss: 0.06819772720336914, Accuracy: 0.9539539813995361\n",
      "Epoch 131, Loss: 0.06942838430404663, Accuracy: 0.9539539813995361\n",
      "Epoch 141, Loss: 0.06804989278316498, Accuracy: 0.9539539813995361\n",
      "Epoch 151, Loss: 0.06730513274669647, Accuracy: 0.9539539813995361\n",
      "Epoch 161, Loss: 0.066904716193676, Accuracy: 0.9539539813995361\n",
      "Epoch 171, Loss: 0.06670030951499939, Accuracy: 0.9539539813995361\n",
      "Epoch 181, Loss: 0.0672977864742279, Accuracy: 0.9539539813995361\n",
      "Epoch 191, Loss: 0.06967002898454666, Accuracy: 0.9529529809951782\n",
      "Predicting...\n",
      "[[ 75  49  12  24  18   7]\n",
      " [ 40 289  48   9  12   5]\n",
      " [ 17  31 334  41   9  19]\n",
      " [ 30  33  61 373  11   8]\n",
      " [ 14  27  10  16 330   9]\n",
      " [ 20  22  22  15  36 252]]\n",
      "Accuracy: 71.01%\n",
      "F1-Score: 0.6820\n",
      "embedding: GIVEN\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (999, 3703)\n",
      "Shape of A_train_tensor: (999, 999)\n",
      "Shape of Y_train: (999, 6)\n",
      "Epoch 1, Loss: 1.8969969749450684, Accuracy: 0.13413412868976593\n",
      "Epoch 11, Loss: 1.073607087135315, Accuracy: 0.9529529809951782\n",
      "Epoch 21, Loss: 1.0277929306030273, Accuracy: 0.9769769906997681\n",
      "Epoch 31, Loss: 1.0110334157943726, Accuracy: 0.9899899959564209\n",
      "Epoch 41, Loss: 1.0023695230484009, Accuracy: 0.9939939975738525\n",
      "Epoch 51, Loss: 0.9975003004074097, Accuracy: 0.9979979991912842\n",
      "Epoch 61, Loss: 0.9939737319946289, Accuracy: 0.9979979991912842\n",
      "Epoch 71, Loss: 0.9914681315422058, Accuracy: 1.0\n",
      "Epoch 81, Loss: 0.9895358085632324, Accuracy: 1.0\n",
      "Epoch 91, Loss: 0.9881827235221863, Accuracy: 1.0\n",
      "Epoch 101, Loss: 0.9871540069580078, Accuracy: 1.0\n",
      "Epoch 111, Loss: 0.9863536357879639, Accuracy: 1.0\n",
      "Epoch 121, Loss: 0.9857485294342041, Accuracy: 1.0\n",
      "Epoch 131, Loss: 0.9852745532989502, Accuracy: 1.0\n",
      "Epoch 141, Loss: 0.9849393963813782, Accuracy: 1.0\n",
      "Epoch 151, Loss: 0.9846603870391846, Accuracy: 1.0\n",
      "Epoch 161, Loss: 0.9844525456428528, Accuracy: 1.0\n",
      "Epoch 171, Loss: 0.9842652082443237, Accuracy: 1.0\n",
      "Epoch 181, Loss: 0.9841346740722656, Accuracy: 1.0\n",
      "Epoch 191, Loss: 0.9840072989463806, Accuracy: 1.0\n",
      "Predicting...\n",
      "[[ 29  74  20  30  14  18]\n",
      " [ 14 295  66   9   7  12]\n",
      " [  5  29 352  30   8  27]\n",
      " [ 12  28  73 370  12  21]\n",
      " [  5  49  16  21 282  33]\n",
      " [  2  15  37   7  16 290]]\n",
      "Accuracy: 69.50%\n",
      "F1-Score: 0.6416\n"
     ]
    }
   ],
   "source": [
    "all_results=[]\n",
    "graph_embeddings_dict={}\n",
    "for emb in embedding_dict.keys():\n",
    "    for clf in classifiers:\n",
    "        results, embedding_matrix = train_and_evaluate(embedding_dict, emb, clf)\n",
    "        all_results.append(results)\n",
    "        key_string= emb + ' with ' + clf\n",
    "        graph_embeddings_dict[key_string]=embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94621965-573c-49ef-8872-505b520d24c2",
   "metadata": {},
   "source": [
    "## Saving aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e330947-4dfc-4604-95fc-eaba95077274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved as ./citeseer_analysis_results/citeseer_seed46_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "# Define dataset name and seed\n",
    "dataset_name = \"citeseer\"\n",
    "seed_value = SEED\n",
    "\n",
    "# Save as CSV file without sorting\n",
    "filename = f\"{dataset_name}_seed{seed_value}_results.csv\"\n",
    "filename='./citeseer_analysis_results/'+filename\n",
    "df.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Results saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2bfb60c-ff32-47f1-898c-70d9c6079799",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings= embedding_dict | graph_embeddings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c6baa74-0524-4a8d-8057-9191b9862bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_dict(original_dict, key_order):\n",
    "    \"\"\"\n",
    "    Reorders a dictionary based on a given list of keys.\n",
    "\n",
    "    Parameters:\n",
    "    - original_dict (dict): The dictionary to reorder.\n",
    "    - key_order (list): The list specifying the desired key order.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A new dictionary with keys ordered as per key_order.\n",
    "    \"\"\"\n",
    "    return {key: original_dict[key] for key in key_order if key in original_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3071f76b-a8b1-4e32-8524-2a162f10e347",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_order = ['random', 'random with gcn', 'random with gat', 'random with graphsage', 'deepwalk', 'deepwalk with gcn', 'deepwalk with gat', 'deepwalk with graphsage', 'node2vec','node2vec with gcn', 'node2vec with gat', 'node2vec with graphsage', 'vgae', 'vgae with gcn', 'vgae with gat', 'vgae with graphsage', 'dgi', 'dgi with gcn', 'dgi with gat', 'dgi with graphsage', 'modularity', 'modularity with gcn', 'modularity with gat', 'modularity with graphsage', 'given', 'given with gcn', 'given with gat', 'given with graphsage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc06e782-3bc1-4b2a-a939-06675e13c44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\joblib\\_memmapping_reducer.py:603: UserWarning: Failed to delete temporary folder: C:\\Users\\user\\AppData\\Local\\Temp\\joblib_memmapping_folder_8012_635dd5cc1a614943991f5adb09edb720_9e68aad3c6724ab59b4cbd36e76781c9\n",
      "  warnings.warn(\"Failed to delete temporary folder: {}\"\n",
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\joblib\\_memmapping_reducer.py:603: UserWarning: Failed to delete temporary folder: C:\\Users\\user\\AppData\\Local\\Temp\\joblib_memmapping_folder_8012_635dd5cc1a614943991f5adb09edb720_4e2bb516ecbf4ba997a95d2c79a1a121\n",
      "  warnings.warn(\"Failed to delete temporary folder: {}\"\n",
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\joblib\\_memmapping_reducer.py:603: UserWarning: Failed to delete temporary folder: C:\\Users\\user\\AppData\\Local\\Temp\\joblib_memmapping_folder_8012_5f729750220d4ddbaf9d9030b2f7850c_1bae81e0a0c64c71a8c52680de593fcb\n",
      "  warnings.warn(\"Failed to delete temporary folder: {}\"\n",
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\joblib\\_memmapping_reducer.py:603: UserWarning: Failed to delete temporary folder: C:\\Users\\user\\AppData\\Local\\Temp\\joblib_memmapping_folder_8012_5f729750220d4ddbaf9d9030b2f7850c_a6f6054903084871927676a1a5bd83fe\n",
      "  warnings.warn(\"Failed to delete temporary folder: {}\"\n"
     ]
    }
   ],
   "source": [
    "all_embeddings = reorder_dict(all_embeddings, key_order)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ad533c0-f510-4e25-b8a1-462996cccc6e",
   "metadata": {},
   "source": [
    "visualize_all_embeddings(all_embeddings, labels, label_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0a6c1-272c-4e2e-a4c3-54f78bf6eed5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
