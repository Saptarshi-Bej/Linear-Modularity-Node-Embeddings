{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c1ef1f-2372-44c0-9703-b8ac660cce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "351a952e-ca8c-4804-ad18-e8f49dea9f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time \n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import umap.umap_ as umap\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
    "from node2vec import Node2Vec\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import spektral\n",
    "from spektral.layers import GCNConv, GATConv\n",
    "from spektral.layers import GraphSageConv\n",
    "from spektral.data import Graph, Dataset, BatchLoader\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from torch_geometric.datasets import Amazon\n",
    "from torch_geometric.nn import DeepGraphInfomax, VGAE\n",
    "from torch_geometric.utils import from_networkx\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import normalize\n",
    "from joblib import Parallel, delayed\n",
    "from torch_geometric.nn import GCNConv as PyG_GCNConv, VGAE as PyG_VGAE\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9044d178-5de4-4fab-8b82-ca674598128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 46\n",
    "\n",
    "# Set seed for Python's built-in random module\n",
    "random.seed(SEED)\n",
    "\n",
    "# Set seed for NumPy\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Set seed for PyTorch\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b95802d-543f-4b3e-803a-cdbdb518595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom Dataset for DBLP\n",
    "class AmazonPhotosDataset(Dataset):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        dataset = Amazon(\".\", name=\"photo\")  # Load Amazon Computers dataset\n",
    "        data = dataset[0]\n",
    "\n",
    "        x = data.x.numpy()\n",
    "        edge_index = data.edge_index.numpy()\n",
    "        y = data.y.numpy()\n",
    "\n",
    "        # One-hot encode labels\n",
    "        num_classes = y.max() + 1\n",
    "        y_one_hot = np.eye(num_classes)[y]\n",
    "\n",
    "        # Convert edge_index to adjacency matrix\n",
    "        num_nodes = x.shape[0]\n",
    "        adj = lil_matrix((num_nodes, num_nodes), dtype=np.float32)\n",
    "        for i in range(edge_index.shape[1]):\n",
    "            src, dst = edge_index[:, i]\n",
    "            adj[src, dst] = 1\n",
    "            adj[dst, src] = 1  \n",
    "\n",
    "        return [Graph(x=x, a=adj, y=y_one_hot)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90c18215-d57c-47a9-957d-5f98fa330e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimensionality=150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b67b75-8102-41b3-b7d9-faac9a95ca1d",
   "metadata": {},
   "source": [
    "## Extracting modularity embedding and using it for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd20588d-2ca8-457e-ab49-a8f42f9cef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian Eigenmaps Embedding\n",
    "def deepwalk_embedding(G, k=2, walk_length=10, num_walks=80, workers=4):\n",
    "    node2vec = Node2Vec(G, dimensions=k, walk_length=walk_length, num_walks=num_walks, workers=workers)\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "    return np.array([model.wv[str(node)] for node in G.nodes()])\n",
    "\n",
    "# Node2Vec Embedding\n",
    "def node2vec_embedding(G, k=2, seed=SEED):\n",
    "    node2vec = Node2Vec(G, dimensions=k, walk_length=10, num_walks=100, workers=2, seed=seed)\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "    return np.array([model.wv[str(node)] for node in G.nodes()])\n",
    "\n",
    "\n",
    "# VGAE Embedding \n",
    "class VGAEEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = PyG_GCNConv(in_channels, 2 * out_channels)  # Use PyG_GCNConv\n",
    "        self.conv_mu = PyG_GCNConv(2 * out_channels, out_channels)  # Separate layer for mu\n",
    "        self.conv_logstd = PyG_GCNConv(2 * out_channels, out_channels)  # Separate layer for logstd\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = torch.relu(self.conv1(x, edge_index))\n",
    "        mu = self.conv_mu(x, edge_index)\n",
    "        logstd = self.conv_logstd(x, edge_index)\n",
    "        return mu, logstd\n",
    "\n",
    "def vgae_embedding(data, k=128):\n",
    "    # Use one-hot encoded node IDs as features\n",
    "    num_nodes = data.num_nodes\n",
    "    x = torch.eye(num_nodes)  # One-hot encoded node features\n",
    "\n",
    "    in_channels = x.shape[1]  # Feature dimension is equal to the number of nodes\n",
    "    model = PyG_VGAE(VGAEEncoder(in_channels, k))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    for _ in tqdm(range(200)):\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(x, data.edge_index)  # Use one-hot encoded features\n",
    "        loss = model.recon_loss(z, data.edge_index) + (1 / data.num_nodes) * model.kl_loss()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model.encode(x, data.edge_index).detach().numpy()\n",
    "\n",
    "# DGI Embedding\n",
    "def dgi_embedding(data, k=128):\n",
    "    class GCNEncoder(torch.nn.Module):\n",
    "        def __init__(self, in_channels, out_channels):\n",
    "            super().__init__()\n",
    "            self.conv1 = PyG_GCNConv(in_channels, 2 * out_channels)  # Use PyG_GCNConv\n",
    "            self.conv2 = PyG_GCNConv(2 * out_channels, out_channels)  # Use PyG_GCNConv\n",
    "\n",
    "        def forward(self, x, edge_index):\n",
    "            x = torch.relu(self.conv1(x, edge_index))\n",
    "            return self.conv2(x, edge_index)\n",
    "\n",
    "    # Use one-hot encoded node IDs as features\n",
    "    num_nodes = data.num_nodes\n",
    "    x = torch.eye(num_nodes)  # One-hot encoded node features\n",
    "\n",
    "    in_channels = x.shape[1]  # Feature dimension is equal to the number of nodes\n",
    "    model = DeepGraphInfomax(\n",
    "        hidden_channels=k,\n",
    "        encoder=GCNEncoder(in_channels, k),\n",
    "        summary=lambda z, *args, **kwargs: z.mean(dim=0),  # Ensure `summary` only takes `z`\n",
    "        corruption=lambda x, edge_index: (x[torch.randperm(x.size(0))], edge_index)  # Correct corruption function\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    for _ in tqdm(range(200)):\n",
    "        optimizer.zero_grad()\n",
    "        pos_z, neg_z, summary = model(x, data.edge_index)  # Use one-hot encoded features\n",
    "        loss = model.loss(pos_z, neg_z, summary)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return pos_z.detach().numpy()\n",
    "\n",
    "\n",
    "# Unsupervised gradient ascent for modularity maximization\n",
    "def gradient_ascent_modularity_unsupervised(G, k=2, eta=0.01, iterations=1000, seed=SEED):\n",
    "    np.random.seed(seed)  # Ensure deterministic initialization\n",
    "\n",
    "    A = nx.to_numpy_array(G)\n",
    "    l = A.sum(axis=1)\n",
    "    m = np.sum(l) / 2\n",
    "    B = A - np.outer(l, l) / (2 * m)\n",
    "    n = B.shape[0]\n",
    "\n",
    "    S = np.random.randn(n, k)  # Random Initialization\n",
    "    S, _ = np.linalg.qr(S)  # Ensure initial orthonormality\n",
    "\n",
    "    for i in tqdm(range(iterations), desc=\"Gradient Ascent Progress\"):\n",
    "        grad = (1 / (2 * m)) * B @ S\n",
    "        S += eta * grad\n",
    "        S, _ = np.linalg.qr(S)  # Orthonormalize using QR decomposition\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c468b5ec-43c2-4852-949b-521beda25e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_labeled_random_walks(G, label_mask, labels, num_walks, walk_length, walk_length_labelled=3):\n",
    "    walks = {node: [] for node in G.nodes()}\n",
    "    for node in G.nodes():\n",
    "        for _ in range(num_walks):\n",
    "            walk = [node]\n",
    "            labeled_count = 0\n",
    "            for _ in range(walk_length - 1):\n",
    "                cur = walk[-1]\n",
    "                neighbors = list(G.neighbors(cur))\n",
    "                if not neighbors:\n",
    "                    break\n",
    "                labeled_neighbors = [n for n in neighbors if label_mask[n]]\n",
    "                if labeled_neighbors and labeled_count < walk_length_labelled:\n",
    "                    next_node = random.choice(labeled_neighbors)\n",
    "                    labeled_count += 1\n",
    "                else:\n",
    "                    next_node = random.choice(neighbors)\n",
    "                walk.append(next_node)\n",
    "            walks[node].extend([n for n in walk if label_mask[n]])\n",
    "    return walks\n",
    "\n",
    "def compute_attention_weights(S, labeled_nodes):\n",
    "    weights = {}\n",
    "    for node, labeled in labeled_nodes.items():\n",
    "        if labeled:\n",
    "            similarities = {n: np.dot(S[node], S[n]) for n in labeled}\n",
    "            exp_sims = {n: np.exp(sim) for n, sim in similarities.items()}\n",
    "            total = sum(exp_sims.values())\n",
    "            weights[node] = {n: exp_sims[n] / total for n in labeled}\n",
    "    return weights\n",
    "\n",
    "def semi_supervised_gradient_ascent_modularity(G, labels, label_mask, k=2, eta=0.01, lambda_supervised=1.0, \n",
    "                                                      lambda_semi=2.0, iterations=5000, initialization='random',\n",
    "                                                      num_walks=10, walk_length=5, walk_length_labelled=3):\n",
    "    # Convert graph to sparse adjacency matrix\n",
    "    A = csr_matrix(nx.to_scipy_sparse_array(G, format='csr'))\n",
    "    degrees = np.array(A.sum(axis=1)).flatten()\n",
    "    m = G.number_of_edges()\n",
    "    n = A.shape[0]\n",
    "\n",
    "    # Initialize embeddings\n",
    "    if initialization == 'random':\n",
    "        S = np.random.randn(n, k)\n",
    "    S, _ = np.linalg.qr(S)\n",
    "\n",
    "    # Compute labeled random walks and attention weights\n",
    "    labeled_walks = perform_labeled_random_walks(G, label_mask, labels, num_walks, walk_length, walk_length_labelled)\n",
    "    attention_weights = compute_attention_weights(S, labeled_walks)\n",
    "\n",
    "    for _ in tqdm(range(iterations), desc=\"Gradient Ascent with Linear Modularity\"):\n",
    "        # Compute modularity gradient using linear approximation\n",
    "        neighbor_agg = A @ S  # Efficient aggregation of neighbor embeddings\n",
    "        global_correction = (degrees[:, None] / (2 * m)) * S.sum(axis=0)\n",
    "        grad_modularity = (1 / (2 * m)) * (neighbor_agg - global_correction)\n",
    "\n",
    "        # Compute supervised gradient\n",
    "        grad_supervised = np.zeros_like(S)\n",
    "        unique_labels = np.unique(labels[label_mask])\n",
    "        for label in unique_labels:\n",
    "            mask = (labels == label) & label_mask\n",
    "            mean_embedding = np.mean(S[mask], axis=0, keepdims=True)\n",
    "            grad_supervised[mask] = S[mask] - mean_embedding\n",
    "\n",
    "        # Compute semi-supervised gradient using adaptive attention\n",
    "        grad_semi_supervised = np.zeros_like(S)\n",
    "        for i in range(n):\n",
    "            if not label_mask[i] and i in attention_weights:\n",
    "                weighted_embedding = sum(weight * S[n] for n, weight in attention_weights[i].items())\n",
    "                grad_semi_supervised[i] = S[i] - weighted_embedding\n",
    "\n",
    "        # Update embeddings\n",
    "        grad_total = grad_modularity - lambda_supervised * grad_supervised - lambda_semi * grad_semi_supervised\n",
    "        S += eta * grad_total\n",
    "        S, _ = np.linalg.qr(S)\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d1fa1ef-526c-4ecb-a4e5-6c344f0412c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_networkx(A):\n",
    "    return nx.from_scipy_sparse_array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7fbba5b-3f7c-4821-9af5-d9d6e982b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AmazonPhotosDataset()\n",
    "ground_truth_labels = dataset[0].y\n",
    "labels=np.argmax(ground_truth_labels,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c92de7a7-bab8-4ee8-9601-e4f95f0386e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_be_masked=np.random.choice(np.arange(len(labels)),int(len(labels)*.7),replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0cf50e3-56e5-4187-b4ef-9f05cd3bc76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_labels=[]\n",
    "for i in np.arange(len(labels)):\n",
    "    if i in labels_to_be_masked:\n",
    "        masked_labels.append(-1)\n",
    "    else:\n",
    "        masked_labels.append(labels[i])\n",
    "masked_labels=np.array(masked_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77562c2a-8c15-4b37-a4d3-674776a0edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask = masked_labels != -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "517544ea-62e6-495c-bce9-6733a551c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[0].x\n",
    "A = dataset[0].a\n",
    "G = convert_to_networkx(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42c8983a-9d5d-4f7a-9a1b-891e79fee2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency Matrix Shape: (7650, 7650)\n",
      "Graph Nodes: 7650\n",
      "Graph Edges: 119081\n"
     ]
    }
   ],
   "source": [
    "print(\"Adjacency Matrix Shape:\", A.shape)\n",
    "print(\"Graph Nodes:\", G.number_of_nodes())\n",
    "print(\"Graph Edges:\", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68111ede-a54c-4fe0-8f8a-eefa5bc7b302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert your preprocessed data into a PyTorch Geometric Data object\n",
    "X_py = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float),  # Node features\n",
    "    edge_index=torch.tensor(np.array(A.nonzero()), dtype=torch.long),  # Edge indices\n",
    "    y=torch.tensor(labels, dtype=torch.long)  # Labels\n",
    ")\n",
    "\n",
    "# Ensure edge_index is in the correct shape (2, num_edges)\n",
    "X_py.edge_index = X_py.edge_index.to(torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a08195-165a-4046-9e86-03cc40619353",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a78c9e8b-638e-464f-a7b0-a472835bf284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing DeepWalk embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 7650/7650 [02:34<00:00, 49.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepWalk embedding computed in 480.52 seconds.\n",
      "Computing VGAE embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:53<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGAE embedding computed in 174.10 seconds.\n",
      "Computing DGI embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:53<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGI embedding computed in 173.57 seconds.\n",
      "Computing Modularity embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gradient Ascent with Linear Modularity: 100%|██████████| 200/200 [03:56<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modularity embedding computed in 243.26 seconds.\n",
      "Computing Node2Vec embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 7650/7650 [03:33<00:00, 35.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node2Vec embedding computed in 1169.81 seconds.\n",
      "Generating Random embedding...\n",
      "Random embedding generated in 0.03 seconds.\n",
      "All embeddings computed and stored in the dictionary successfully.\n",
      "\n",
      "Execution times saved to 'embedding_execution_times.csv'.\n",
      "        Model  Time (seconds)\n",
      "0    DeepWalk      480.520978\n",
      "1        VGAE      174.098534\n",
      "2         DGI      173.570651\n",
      "3  Modularity      243.257231\n",
      "4    Node2Vec     1169.812063\n",
      "5      Random        0.030629\n"
     ]
    }
   ],
   "source": [
    "# Dictionary for embeddings\n",
    "embedding_dict = {}\n",
    "execution_times = []  # List to store execution times\n",
    "\n",
    "# Compute embeddings and store them with time tracking\n",
    "def record_time(model_name, func, *args, **kwargs):\n",
    "    print(f\"Computing {model_name} embedding...\")\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    execution_times.append((model_name, elapsed_time))\n",
    "    print(f\"{model_name} embedding computed in {elapsed_time:.2f} seconds.\")\n",
    "    return result\n",
    "\n",
    "X_deepwalk = record_time(\"DeepWalk\", deepwalk_embedding, G, k=embedding_dimensionality)\n",
    "X_deepwalk = tf.convert_to_tensor(X_deepwalk, dtype=tf.float32)\n",
    "embedding_dict['deepwalk'] = X_deepwalk\n",
    "\n",
    "X_vgae = record_time(\"VGAE\", vgae_embedding, X_py, k=embedding_dimensionality)\n",
    "embedding_dict['vgae'] = X_vgae\n",
    "\n",
    "X_dgi = record_time(\"DGI\", dgi_embedding, X_py, k=embedding_dimensionality)\n",
    "embedding_dict['dgi'] = X_dgi\n",
    "\n",
    "X_modularity = record_time(\"Modularity\", semi_supervised_gradient_ascent_modularity,\n",
    "                           G, labels, label_mask, k=embedding_dimensionality,\n",
    "                           eta=0.05, lambda_supervised=1.0, lambda_semi=2.0, iterations=200, initialization='random')\n",
    "embedding_dict['modularity'] = X_modularity\n",
    "\n",
    "X_node2vec = record_time(\"Node2Vec\", node2vec_embedding, G, k=embedding_dimensionality)\n",
    "X_node2vec = tf.convert_to_tensor(X_node2vec, dtype=tf.float32)\n",
    "embedding_dict['node2vec'] = X_node2vec\n",
    "\n",
    "# Generate random embedding\n",
    "print(\"Generating Random embedding...\")\n",
    "start_time = time.time()\n",
    "shape = (len(ground_truth_labels), embedding_dimensionality)\n",
    "X_random = np.random.randn(*shape)\n",
    "X_random = tf.convert_to_tensor(X_random, dtype=tf.float32)\n",
    "end_time = time.time()\n",
    "execution_times.append((\"Random\", end_time - start_time))\n",
    "print(f\"Random embedding generated in {end_time - start_time:.2f} seconds.\")\n",
    "embedding_dict['random'] = X_random\n",
    "\n",
    "# Use original node features as 'given' embedding\n",
    "embedding_dict['given'] = X\n",
    "\n",
    "print(\"All embeddings computed and stored in the dictionary successfully.\")\n",
    "\n",
    "# Store execution times in a DataFrame and save\n",
    "execution_df = pd.DataFrame(execution_times, columns=[\"Model\", \"Time (seconds)\"])\n",
    "execution_df.to_csv(\"./photo_analysis_results/embedding_execution_times_photo_\"+str(SEED)+\".csv\", index=False)\n",
    "\n",
    "print(\"\\nExecution times saved to 'embedding_execution_times.csv'.\")\n",
    "print(execution_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ead0a51-7df6-4ee5-812d-70f222d3bd48",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0828590d-7226-4229-9aa2-7c833bfa9377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_all_embeddings(all_embeddings, labels, label_mask):\n",
    "    \"\"\"\n",
    "    Visualize all embeddings in a grid with 4 columns per row using UMAP.\n",
    "\n",
    "    Parameters:\n",
    "    - all_embeddings: Dictionary where keys are embedding methods, and values are embeddings.\n",
    "    - labels: Labels (numpy array of shape [n_nodes]).\n",
    "    - label_mask: Boolean array indicating known labels (True for known, False for unknown).\n",
    "    \"\"\"\n",
    "    num_embeddings = len(all_embeddings)\n",
    "    num_rows = (num_embeddings + 3) // 4  # Ensure enough rows for all embeddings\n",
    "    fig, axes = plt.subplots(num_rows, 4, figsize=(8.27, 11.69))  # A4 size\n",
    "\n",
    "    for i, (embedding_type, embedding) in tqdm(enumerate(all_embeddings.items()), \n",
    "                                               total=num_embeddings, desc=\"Visualizing embeddings\"):\n",
    "        row, col = divmod(i, 4)\n",
    "        ax = axes[row, col] if num_rows > 1 else axes[col]  # Adjust for single-row case\n",
    "\n",
    "        # Ensure embedding is a NumPy array\n",
    "        if isinstance(embedding, tf.Tensor):\n",
    "            embedding = embedding.numpy()\n",
    "\n",
    "        # Reduce dimensionality using UMAP\n",
    "        reducer = umap.UMAP(n_components=2)\n",
    "        embedding_2d = reducer.fit_transform(embedding)\n",
    "\n",
    "        # Known labels\n",
    "        ax.scatter(embedding_2d[label_mask, 0], embedding_2d[label_mask, 1], \n",
    "                   c=labels[label_mask], cmap=\"Set1\", s=3, alpha=0.7, label=\"Known Labels\",\n",
    "                   edgecolors='none')\n",
    "\n",
    "        # Unknown labels\n",
    "        ax.scatter(embedding_2d[~label_mask, 0], embedding_2d[~label_mask, 1], \n",
    "                   c=labels[~label_mask], cmap=\"Set1\", s=5, alpha=0.7, \n",
    "                   label=\"Unknown Labels\", edgecolors='black', linewidths=0.2)\n",
    "\n",
    "        # Title with smaller font size\n",
    "        ax.set_title(embedding_type.upper(), fontsize=8, pad=2)\n",
    "\n",
    "        # Remove axis labels, ticks, and frames\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "    # Remove empty subplots if num_embeddings is not a multiple of 4\n",
    "    for j in range(i + 1, num_rows * 4):\n",
    "        row, col = divmod(j, 4)\n",
    "        fig.delaxes(axes[row, col])\n",
    "\n",
    "    plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05, wspace=0.2, hspace=0.2)  # Adjust margins\n",
    "    save_path = \"./photo_analysis_results/embedding_grid_plot_photo.png\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Visualization saved to {save_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ad48116-fc9e-4306-aba2-631509e64002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance using accuracy, F1-score, and confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.array): Ground truth labels (integers).\n",
    "        predicted_labels (np.array): Predicted labels (integers).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing accuracy, F1-score, and confusion matrix.\n",
    "    \"\"\"\n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    \n",
    "    # Compute F1-score (macro-averaged)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    #\n",
    "    print(cm)\n",
    "    \n",
    "    # Return results as a dictionary\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e519f7-b02e-444f-aff3-4de14d282200",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88669d87-afc7-4d8d-9471-40892a9d485a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(tf.keras.Model):\n",
    "    def __init__(self, n_labels, seed=42):  # Use an explicit seed\n",
    "        super().__init__()\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=seed)  # Define initializer\n",
    "        \n",
    "        self.conv1 = GCNConv(16, activation='relu', kernel_initializer=initializer)\n",
    "        self.conv2 = GCNConv(n_labels, activation='softmax', kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        intermediate_embeddings = self.conv1([x, a])  # Store intermediate embeddings\n",
    "        x = self.conv2([intermediate_embeddings, a])\n",
    "        return x, intermediate_embeddings  # Return both final output and intermediate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32add8f8-6c31-4c37-b0cb-0d5ebcdccf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GAT model\n",
    "class GAT(tf.keras.Model):\n",
    "    def __init__(self, n_labels, num_heads=8, seed=42):\n",
    "        super().__init__()\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=seed)\n",
    "\n",
    "        self.conv1 = GATConv(16, attn_heads=num_heads, concat_heads=True, activation='elu', kernel_initializer=initializer)\n",
    "        self.conv2 = GATConv(n_labels, attn_heads=1, concat_heads=False, activation='softmax', kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        intermediate_embeddings = self.conv1([x, a])  # Store intermediate embeddings\n",
    "        x = self.conv2([intermediate_embeddings, a])\n",
    "        return x, intermediate_embeddings  # Return both final output and intermediate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "989b705e-9c9f-4cc7-b5d2-9753d476aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphSAGE model\n",
    "class GraphSAGE(tf.keras.Model):\n",
    "    def __init__(self, n_labels, hidden_dim=16, aggregator='mean', seed=42):\n",
    "        super().__init__()\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=seed)\n",
    "\n",
    "        self.conv1 = GraphSageConv(hidden_dim, activation='relu', aggregator=aggregator, kernel_initializer=initializer)\n",
    "        self.conv2 = GraphSageConv(n_labels, activation='softmax', aggregator=aggregator, kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        intermediate_embeddings = self.conv1([x, a])  # Store intermediate embeddings\n",
    "        x = self.conv2([intermediate_embeddings, a])\n",
    "        return x, intermediate_embeddings  # Return both final output and intermediate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74b396b7-d6f4-439a-993a-f35e27f2806a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers=['gcn','gat','graphsage']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb576ec-8e6a-4320-8f0c-a37ee1e4f534",
   "metadata": {},
   "source": [
    "## Classification using different node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7296b83-eb11-44de-962b-d405da4e59fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(embedding_dict, embedding, classifier, ground_truth_labels=ground_truth_labels, masked_labels=masked_labels):\n",
    "    \"the labels have to be one hot encoded\"\n",
    "    \"model take values: gcn, gat, graphsage\"\n",
    "    print('embedding: ' + embedding.upper())\n",
    "    print('model: ' + classifier.upper())\n",
    "\n",
    "    X = embedding_dict[embedding]\n",
    "\n",
    "    print(\"Processing...\")\n",
    "    # Create boolean mask for training\n",
    "    train_mask = masked_labels != -1\n",
    "\n",
    "    # Split the data into training and prediction sets\n",
    "    X_train = X[train_mask]  # Training node features\n",
    "    Y_train = ground_truth_labels[train_mask]  # Training labels (one-hot encoded)\n",
    "    Y_train = tf.cast(Y_train, dtype='int32')\n",
    "    \n",
    "    # Reduce the adjacency matrix to only include training nodes\n",
    "    A_train = A[train_mask, :][:, train_mask]  # Correctly reduce the adjacency matrix\n",
    "    \n",
    "    # Convert sparse adjacency matrix to COO format\n",
    "    A_coo = A_train.tocoo()\n",
    "    indices = np.column_stack((A_coo.row, A_coo.col))  # Corrected indices format\n",
    "    values = A_coo.data\n",
    "    shape = A_coo.shape  # Shape: (num_nodes, num_nodes)\n",
    "    \n",
    "    # Create a sparse tensor for the adjacency matrix\n",
    "    A_train_tensor = tf.sparse.SparseTensor(indices=indices, values=values, dense_shape=shape)\n",
    "    \n",
    "    # Ensure the sparse tensor is ordered correctly\n",
    "    A_train_tensor = tf.sparse.reorder(A_train_tensor)\n",
    "\n",
    "    print(\"Training...\")\n",
    "    # Initialize the model\n",
    "    if classifier == 'gcn':\n",
    "        n_labels = ground_truth_labels.shape[1]  # Number of classes\n",
    "        model = GCN(n_labels)\n",
    "    elif classifier == 'gat':\n",
    "        n_labels = ground_truth_labels.shape[1]  # Number of classes\n",
    "        model = GAT(n_labels)\n",
    "    elif classifier == 'graphsage':\n",
    "        n_labels = ground_truth_labels.shape[1]  # Number of classes\n",
    "        model = GraphSAGE(n_labels)\n",
    "    \n",
    "    # Compile the model (not strictly necessary when using GradientTape, but useful for metrics)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.01),\n",
    "        loss=CategoricalCrossentropy(),\n",
    "        metrics=[CategoricalAccuracy()]\n",
    "    )\n",
    "    \n",
    "    # Print shapes for debugging\n",
    "    print(f\"Shape of X_train: {X_train.shape}\")\n",
    "    print(f\"Shape of A_train_tensor: {A_train_tensor.shape}\")\n",
    "    print(f\"Shape of Y_train: {Y_train.shape}\")\n",
    "    \n",
    "    # Define the optimizer and loss function\n",
    "    optimizer = Adam(learning_rate=0.01)\n",
    "    loss_fn = CategoricalCrossentropy()\n",
    "    \n",
    "    # Training loop with GradientTape\n",
    "    epochs = 200\n",
    "    for epoch in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            predictions, intermediate_embeddings = model([X_train, A_train_tensor])  # Unpack both outputs\n",
    "                \n",
    "            # Compute supervised loss (cross-entropy)\n",
    "            supervised_loss = loss_fn(Y_train, predictions)\n",
    "            \n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(supervised_loss, model.trainable_variables)\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "        # Print loss and accuracy for monitoring\n",
    "        if epoch % 10 == 0:\n",
    "            accuracy = CategoricalAccuracy()(Y_train, predictions)\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {supervised_loss.numpy()}, Accuracy: {accuracy.numpy()}\")\n",
    "\n",
    "    print(\"Predicting...\")\n",
    "    # Prepare the full graph for prediction\n",
    "    X_full = X  # Full node features\n",
    "    A_full = A  # Full adjacency matrix\n",
    "    \n",
    "    # Convert the full adjacency matrix to COO format\n",
    "    A_full_coo = A_full.tocoo()\n",
    "    indices_full = np.column_stack((A_full_coo.row, A_full_coo.col))\n",
    "    values_full = A_full_coo.data\n",
    "    shape_full = A_full_coo.shape\n",
    "    \n",
    "    # Create a sparse tensor for the full adjacency matrix\n",
    "    A_full_tensor = tf.sparse.SparseTensor(indices=indices_full, values=values_full, dense_shape=shape_full)\n",
    "    A_full_tensor = tf.sparse.reorder(A_full_tensor)\n",
    "    \n",
    "    # Make predictions for all nodes\n",
    "    predictions, emb = model([X_full, A_full_tensor])  # Shape: [num_nodes, n_labels]\n",
    "\n",
    "    # Convert predictions to class labels (integers)\n",
    "    predicted_labels = tf.argmax(predictions, axis=1).numpy()  # Shape: [num_nodes]\n",
    "    \n",
    "    # Extract predictions for the masked nodes\n",
    "    predicted_labels_masked = predicted_labels[labels_to_be_masked]\n",
    "\n",
    "    # True labels for the masked nodes\n",
    "    true_labels_masked = labels[labels_to_be_masked]\n",
    "    \n",
    "    # Predicted labels for the masked nodes\n",
    "    predicted_labels_masked = predicted_labels[labels_to_be_masked]\n",
    "    \n",
    "    # Evaluate the model's performance\n",
    "    results = evaluate_model(true_labels_masked, predicted_labels_masked)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Accuracy: {results['accuracy'] * 100:.2f}%\")\n",
    "    print(f\"F1-Score: {results['f1_score']:.4f}\")\n",
    "\n",
    "    results['model'] = classifier\n",
    "    results['embedding'] = embedding\n",
    "\n",
    "    # Return results and intermediate embeddings for visualization\n",
    "    return results, emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfd6c5ee-d55d-497e-ac2d-67bd98813c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding: DEEPWALK\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 150)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 80.59327697753906, Accuracy: 0.15032680332660675\n",
      "Epoch 11, Loss: 14.102044105529785, Accuracy: 0.4919390082359314\n",
      "Epoch 21, Loss: 4.502809047698975, Accuracy: 0.47145968675613403\n",
      "Epoch 31, Loss: 1.4875774383544922, Accuracy: 0.5381263494491577\n",
      "Epoch 41, Loss: 1.4364583492279053, Accuracy: 0.43834424018859863\n",
      "Epoch 51, Loss: 1.2657424211502075, Accuracy: 0.615686297416687\n",
      "Epoch 61, Loss: 1.0556358098983765, Accuracy: 0.6823529601097107\n",
      "Epoch 71, Loss: 1.0012435913085938, Accuracy: 0.7163398861885071\n",
      "Epoch 81, Loss: 0.9449745416641235, Accuracy: 0.7119825482368469\n",
      "Epoch 91, Loss: 0.9138507843017578, Accuracy: 0.7289760112762451\n",
      "Epoch 101, Loss: 0.8825042247772217, Accuracy: 0.7272331118583679\n",
      "Epoch 111, Loss: 0.8615908622741699, Accuracy: 0.7337690591812134\n",
      "Epoch 121, Loss: 0.8467381596565247, Accuracy: 0.7359477281570435\n",
      "Epoch 131, Loss: 0.8365573883056641, Accuracy: 0.7363834381103516\n",
      "Epoch 141, Loss: 0.8264889121055603, Accuracy: 0.7350762486457825\n",
      "Epoch 151, Loss: 0.8166418075561523, Accuracy: 0.7342047691345215\n",
      "Epoch 161, Loss: 0.807044506072998, Accuracy: 0.7315903902053833\n",
      "Epoch 171, Loss: 0.7980301380157471, Accuracy: 0.7342047691345215\n",
      "Epoch 181, Loss: 0.7895582318305969, Accuracy: 0.7355119585990906\n",
      "Epoch 191, Loss: 0.781249463558197, Accuracy: 0.7350762486457825\n",
      "Predicting...\n",
      "[[ 164   15    2   73    1    1    3    0]\n",
      " [   1  927    6  144   79   13   12    0]\n",
      " [   1    5  468    4   14    4    0    1]\n",
      " [   4   45    1  536   40    1    5    3]\n",
      " [   1   42   27  142  298    3   96    4]\n",
      " [   0    4    0    1   19  560    0    0]\n",
      " [  14   10    7   28   74    1 1193   31]\n",
      " [   2   11    1   65   16    1   38   93]]\n",
      "Accuracy: 79.16%\n",
      "F1-Score: 0.7531\n",
      "embedding: DEEPWALK\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 150)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.0882253646850586, Accuracy: 0.051851850003004074\n",
      "Epoch 11, Loss: 0.4419538974761963, Accuracy: 0.8596950173377991\n",
      "Epoch 21, Loss: 0.35105979442596436, Accuracy: 0.9045751690864563\n",
      "Epoch 31, Loss: 0.2798238694667816, Accuracy: 0.9241830110549927\n",
      "Epoch 41, Loss: 0.22318072617053986, Accuracy: 0.9320261478424072\n",
      "Epoch 51, Loss: 0.1884259283542633, Accuracy: 0.9403049945831299\n",
      "Epoch 61, Loss: 0.16226136684417725, Accuracy: 0.9459695219993591\n",
      "Epoch 71, Loss: 0.1393304467201233, Accuracy: 0.9529411792755127\n",
      "Epoch 81, Loss: 0.11889629811048508, Accuracy: 0.9594771265983582\n",
      "Epoch 91, Loss: 0.09927824139595032, Accuracy: 0.9681917428970337\n",
      "Epoch 101, Loss: 0.0809531956911087, Accuracy: 0.9764705896377563\n",
      "Epoch 111, Loss: 0.0643705278635025, Accuracy: 0.9790849685668945\n",
      "Epoch 121, Loss: 0.052403468638658524, Accuracy: 0.9821350574493408\n",
      "Epoch 131, Loss: 0.04501965641975403, Accuracy: 0.984749436378479\n",
      "Epoch 141, Loss: 0.04034382849931717, Accuracy: 0.984749436378479\n",
      "Epoch 151, Loss: 0.036521315574645996, Accuracy: 0.9860566258430481\n",
      "Epoch 161, Loss: 0.03353377804160118, Accuracy: 0.9877995848655701\n",
      "Epoch 171, Loss: 0.03179311007261276, Accuracy: 0.9877995848655701\n",
      "Epoch 181, Loss: 0.030615875497460365, Accuracy: 0.9877995848655701\n",
      "Epoch 191, Loss: 0.0296478234231472, Accuracy: 0.9873638153076172\n",
      "Predicting...\n",
      "[[ 237   10    0    2    0    0    9    1]\n",
      " [   2 1065    2   53    4   12   39    5]\n",
      " [   1    4  473    3    3    1   10    2]\n",
      " [   1   90    2  509    3    1   18   11]\n",
      " [   0   19    5    7  547    2   30    3]\n",
      " [   0    5    3    4    1  559   11    1]\n",
      " [  15   12    7    9   15    4 1265   31]\n",
      " [   2   19    1    8    3    0   34  160]]\n",
      "Accuracy: 89.92%\n",
      "F1-Score: 0.8880\n",
      "embedding: DEEPWALK\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 150)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 2.182734727859497, Accuracy: 0.10370370000600815\n",
      "Epoch 11, Loss: 1.462781310081482, Accuracy: 0.8396514058113098\n",
      "Epoch 21, Loss: 1.3723819255828857, Accuracy: 0.8662309646606445\n",
      "Epoch 31, Loss: 1.343220591545105, Accuracy: 0.9084967374801636\n",
      "Epoch 41, Loss: 1.3268077373504639, Accuracy: 0.9185185432434082\n",
      "Epoch 51, Loss: 1.3144322633743286, Accuracy: 0.9246187210083008\n",
      "Epoch 61, Loss: 1.30581533908844, Accuracy: 0.9324618577957153\n",
      "Epoch 71, Loss: 1.2994548082351685, Accuracy: 0.9359477162361145\n",
      "Epoch 81, Loss: 1.2944114208221436, Accuracy: 0.9407407641410828\n",
      "Epoch 91, Loss: 1.2901307344436646, Accuracy: 0.94466233253479\n",
      "Epoch 101, Loss: 1.2862666845321655, Accuracy: 0.9468409419059753\n",
      "Epoch 111, Loss: 1.2824589014053345, Accuracy: 0.9529411792755127\n",
      "Epoch 121, Loss: 1.2787846326828003, Accuracy: 0.955991268157959\n",
      "Epoch 131, Loss: 1.275265097618103, Accuracy: 0.9607843160629272\n",
      "Epoch 141, Loss: 1.2720692157745361, Accuracy: 0.9651415944099426\n",
      "Epoch 151, Loss: 1.2690401077270508, Accuracy: 0.9677559733390808\n",
      "Epoch 161, Loss: 1.2661259174346924, Accuracy: 0.9694989323616028\n",
      "Epoch 171, Loss: 1.2631301879882812, Accuracy: 0.972113311290741\n",
      "Epoch 181, Loss: 1.2602548599243164, Accuracy: 0.9738562107086182\n",
      "Epoch 191, Loss: 1.2577983140945435, Accuracy: 0.9773420691490173\n",
      "Predicting...\n",
      "[[ 247    8    2    1    0    0    1    0]\n",
      " [   4 1047    0   80    7   13   31    0]\n",
      " [   1    4  473    6    1    1   11    0]\n",
      " [   0   49    1  551    8    0   14   12]\n",
      " [   0    8    4    5  568    5   20    3]\n",
      " [   0    6    4    0    2  561   10    1]\n",
      " [  10   14    8   17   20    6 1266   17]\n",
      " [   2   11    0   18    3    0   29  164]]\n",
      "Accuracy: 91.07%\n",
      "F1-Score: 0.9032\n",
      "embedding: VGAE\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 150)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 133.74746704101562, Accuracy: 0.0631808266043663\n",
      "Epoch 11, Loss: 14.32374382019043, Accuracy: 0.5755991339683533\n",
      "Epoch 21, Loss: 6.42582368850708, Accuracy: 0.6949890851974487\n",
      "Epoch 31, Loss: 2.369858980178833, Accuracy: 0.7241830229759216\n",
      "Epoch 41, Loss: 1.4643303155899048, Accuracy: 0.756426990032196\n",
      "Epoch 51, Loss: 0.9293773174285889, Accuracy: 0.7912853956222534\n",
      "Epoch 61, Loss: 0.7400206327438354, Accuracy: 0.8008714318275452\n",
      "Epoch 71, Loss: 0.6813215613365173, Accuracy: 0.8052287697792053\n",
      "Epoch 81, Loss: 0.6438295245170593, Accuracy: 0.8117647171020508\n",
      "Epoch 91, Loss: 0.6156588196754456, Accuracy: 0.813507616519928\n",
      "Epoch 101, Loss: 0.5920401215553284, Accuracy: 0.8217864632606506\n",
      "Epoch 111, Loss: 0.5719324946403503, Accuracy: 0.8239651322364807\n",
      "Epoch 121, Loss: 0.5551789999008179, Accuracy: 0.827015221118927\n",
      "Epoch 131, Loss: 0.5411060452461243, Accuracy: 0.827015221118927\n",
      "Epoch 141, Loss: 0.5296499133110046, Accuracy: 0.8309367895126343\n",
      "Epoch 151, Loss: 0.5204383730888367, Accuracy: 0.8318082690238953\n",
      "Epoch 161, Loss: 0.5123451948165894, Accuracy: 0.8348584175109863\n",
      "Epoch 171, Loss: 0.5050138831138611, Accuracy: 0.8361656069755554\n",
      "Epoch 181, Loss: 0.4979209303855896, Accuracy: 0.8379085063934326\n",
      "Epoch 191, Loss: 0.491144597530365, Accuracy: 0.8392156958580017\n",
      "Predicting...\n",
      "[[ 247    4    2    3    0    0    3    0]\n",
      " [   7  999    0  134   10    8    8   16]\n",
      " [   1   18  466    3    5    1    1    2]\n",
      " [   6   54    1  487   17    1   14   55]\n",
      " [   0   20    3    5  566    0   19    0]\n",
      " [   0   23    0    0    1  557    2    1]\n",
      " [  16   51   11    7   55    3 1194   21]\n",
      " [   3    8    0   14    6    0   48  148]]\n",
      "Accuracy: 87.10%\n",
      "F1-Score: 0.8572\n",
      "embedding: VGAE\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 150)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 2.0698742866516113, Accuracy: 0.27407407760620117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.5036377310752869, Accuracy: 0.8470588326454163\n",
      "Epoch 21, Loss: 0.3781101107597351, Accuracy: 0.8810457587242126\n",
      "Epoch 31, Loss: 0.3068903386592865, Accuracy: 0.9058823585510254\n",
      "Epoch 41, Loss: 0.2633686363697052, Accuracy: 0.9189542531967163\n",
      "Epoch 51, Loss: 0.23371148109436035, Accuracy: 0.9285402894020081\n",
      "Epoch 61, Loss: 0.21073397994041443, Accuracy: 0.9363834261894226\n",
      "Epoch 71, Loss: 0.19086569547653198, Accuracy: 0.94466233253479\n",
      "Epoch 81, Loss: 0.17239412665367126, Accuracy: 0.9477124214172363\n",
      "Epoch 91, Loss: 0.15454117953777313, Accuracy: 0.9546840786933899\n",
      "Epoch 101, Loss: 0.13699974119663239, Accuracy: 0.9599128365516663\n",
      "Epoch 111, Loss: 0.12024929374456406, Accuracy: 0.9651415944099426\n",
      "Epoch 121, Loss: 0.10452726483345032, Accuracy: 0.9694989323616028\n",
      "Epoch 131, Loss: 0.08856122940778732, Accuracy: 0.9734205007553101\n",
      "Epoch 141, Loss: 0.07418165355920792, Accuracy: 0.9769062995910645\n",
      "Epoch 151, Loss: 0.06089424341917038, Accuracy: 0.9821350574493408\n",
      "Epoch 161, Loss: 0.04917735978960991, Accuracy: 0.984749436378479\n",
      "Epoch 171, Loss: 0.039183832705020905, Accuracy: 0.9886710047721863\n",
      "Epoch 181, Loss: 0.03102242760360241, Accuracy: 0.9912853837013245\n",
      "Epoch 191, Loss: 0.02460288256406784, Accuracy: 0.9934640526771545\n",
      "Predicting...\n",
      "[[ 237    4    1    1    0   14    1    1]\n",
      " [   3 1066    2   58    9   10   21   13]\n",
      " [   3   12  466    4    2    5    3    2]\n",
      " [   2  104    4  468    8    2   18   29]\n",
      " [   1   10    7    5  559    2   27    2]\n",
      " [   1   15    1    2    2  560    2    1]\n",
      " [  16   31   17   25   11    7 1225   26]\n",
      " [   1    7    1    6    1    1   25  185]]\n",
      "Accuracy: 89.00%\n",
      "F1-Score: 0.8806\n",
      "embedding: VGAE\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 150)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 2.1453123092651367, Accuracy: 0.13681916892528534\n",
      "Epoch 11, Loss: 1.4326304197311401, Accuracy: 0.8535947799682617\n",
      "Epoch 21, Loss: 1.3669679164886475, Accuracy: 0.8884531855583191\n",
      "Epoch 31, Loss: 1.3398724794387817, Accuracy: 0.9054466485977173\n",
      "Epoch 41, Loss: 1.323736310005188, Accuracy: 0.9154683947563171\n",
      "Epoch 51, Loss: 1.3133697509765625, Accuracy: 0.9250544905662537\n",
      "Epoch 61, Loss: 1.30497145652771, Accuracy: 0.9355120062828064\n",
      "Epoch 71, Loss: 1.2978830337524414, Accuracy: 0.9420479536056519\n",
      "Epoch 81, Loss: 1.2916535139083862, Accuracy: 0.9494553208351135\n",
      "Epoch 91, Loss: 1.2864047288894653, Accuracy: 0.9533768892288208\n",
      "Epoch 101, Loss: 1.2816414833068848, Accuracy: 0.9572984576225281\n",
      "Epoch 111, Loss: 1.2772753238677979, Accuracy: 0.9620915055274963\n",
      "Epoch 121, Loss: 1.2733359336853027, Accuracy: 0.9647058844566345\n",
      "Epoch 131, Loss: 1.2696088552474976, Accuracy: 0.9664487838745117\n",
      "Epoch 141, Loss: 1.2661244869232178, Accuracy: 0.9690631628036499\n",
      "Epoch 151, Loss: 1.2630131244659424, Accuracy: 0.9734205007553101\n",
      "Epoch 161, Loss: 1.2601276636123657, Accuracy: 0.9751634001731873\n",
      "Epoch 171, Loss: 1.2573835849761963, Accuracy: 0.9773420691490173\n",
      "Epoch 181, Loss: 1.2548906803131104, Accuracy: 0.9790849685668945\n",
      "Epoch 191, Loss: 1.2526862621307373, Accuracy: 0.9803921580314636\n",
      "Predicting...\n",
      "[[ 237    8    2    5    0    1    3    3]\n",
      " [   3 1031    8   71   12   16   27   14]\n",
      " [   2    9  473    5    4    2    2    0]\n",
      " [   1   87    5  487   14    1   24   16]\n",
      " [   1   19    4    6  555    0   25    3]\n",
      " [   0    8    1    0    2  567    3    3]\n",
      " [   8   23   17   23   30    9 1214   34]\n",
      " [   2   13    1   15    2    0   34  160]]\n",
      "Accuracy: 88.22%\n",
      "F1-Score: 0.8713\n",
      "embedding: DGI\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 150)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 225.65675354003906, Accuracy: 0.0470588244497776\n",
      "Epoch 11, Loss: 8.126142501831055, Accuracy: 0.2718954384326935\n",
      "Epoch 21, Loss: 2.082487106323242, Accuracy: 0.21960784494876862\n",
      "Epoch 31, Loss: 2.0640878677368164, Accuracy: 0.21960784494876862\n",
      "Epoch 41, Loss: 2.042874813079834, Accuracy: 0.21960784494876862\n",
      "Epoch 51, Loss: 2.022798776626587, Accuracy: 0.21960784494876862\n",
      "Epoch 61, Loss: 2.0051376819610596, Accuracy: 0.21960784494876862\n",
      "Epoch 71, Loss: 1.9901288747787476, Accuracy: 0.21960784494876862\n",
      "Epoch 81, Loss: 1.9775981903076172, Accuracy: 0.21960784494876862\n",
      "Epoch 91, Loss: 1.9672374725341797, Accuracy: 0.21960784494876862\n",
      "Epoch 101, Loss: 1.9587279558181763, Accuracy: 0.21960784494876862\n",
      "Epoch 111, Loss: 1.951786756515503, Accuracy: 0.21960784494876862\n",
      "Epoch 121, Loss: 1.9461722373962402, Accuracy: 0.21960784494876862\n",
      "Epoch 131, Loss: 1.9416790008544922, Accuracy: 0.21960784494876862\n",
      "Epoch 141, Loss: 1.938125729560852, Accuracy: 0.21960784494876862\n",
      "Epoch 151, Loss: 1.9353516101837158, Accuracy: 0.21960784494876862\n",
      "Epoch 161, Loss: 1.9332118034362793, Accuracy: 0.2540304958820343\n",
      "Epoch 171, Loss: 1.9315801858901978, Accuracy: 0.2540304958820343\n",
      "Epoch 181, Loss: 1.9303470849990845, Accuracy: 0.2540304958820343\n",
      "Epoch 191, Loss: 1.9294228553771973, Accuracy: 0.2540304958820343\n",
      "Predicting...\n",
      "[[   0    0    0    0    0    0  259    0]\n",
      " [   0    0    0    0    0    0 1182    0]\n",
      " [   0    0    0    0    0    0  497    0]\n",
      " [   0    0    0    0    0    0  635    0]\n",
      " [   0    0    0    0    0    0  613    0]\n",
      " [   0    0    0    0    0    0  584    0]\n",
      " [   0    0    0    0    0    0 1358    0]\n",
      " [   0    0    0    0    0    0  227    0]]\n",
      "Accuracy: 25.36%\n",
      "F1-Score: 0.0506\n",
      "embedding: DGI\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 150)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 2.0827796459198, Accuracy: 0.10413943231105804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 1.711827278137207, Accuracy: 0.399564266204834\n",
      "Epoch 21, Loss: 1.3537522554397583, Accuracy: 0.4910675287246704\n",
      "Epoch 31, Loss: 1.0830405950546265, Accuracy: 0.6082788705825806\n",
      "Epoch 41, Loss: 0.9349703788757324, Accuracy: 0.7198256850242615\n",
      "Epoch 51, Loss: 0.823497474193573, Accuracy: 0.7529411911964417\n",
      "Epoch 61, Loss: 0.7289060354232788, Accuracy: 0.7668845057487488\n",
      "Epoch 71, Loss: 0.6714534163475037, Accuracy: 0.7808278799057007\n",
      "Epoch 81, Loss: 0.6229240298271179, Accuracy: 0.7943354845046997\n",
      "Epoch 91, Loss: 0.5915417671203613, Accuracy: 0.8017429113388062\n",
      "Epoch 101, Loss: 0.5672233700752258, Accuracy: 0.8082788586616516\n",
      "Epoch 111, Loss: 0.5478813648223877, Accuracy: 0.813507616519928\n",
      "Epoch 121, Loss: 0.5294991135597229, Accuracy: 0.827015221118927\n",
      "Epoch 131, Loss: 0.5098995566368103, Accuracy: 0.8322439789772034\n",
      "Epoch 141, Loss: 0.4965786337852478, Accuracy: 0.842265784740448\n",
      "Epoch 151, Loss: 0.4823084771633148, Accuracy: 0.8444444537162781\n",
      "Epoch 161, Loss: 0.4703095853328705, Accuracy: 0.8470588326454163\n",
      "Epoch 171, Loss: 0.4613863229751587, Accuracy: 0.8522875905036926\n",
      "Epoch 181, Loss: 0.450029194355011, Accuracy: 0.8522875905036926\n",
      "Epoch 191, Loss: 0.4412710964679718, Accuracy: 0.8605664372444153\n",
      "Predicting...\n",
      "[[ 240   13    2    4    0    0    0    0]\n",
      " [  11 1055    0   67    2   12   19   16]\n",
      " [   1    8  471    1    1    4   10    1]\n",
      " [   1  142    2  424    4    0   11   51]\n",
      " [   0   25   11    7  536    0   29    5]\n",
      " [   3    5    3    2    1  564    6    0]\n",
      " [  22   58   11   20    7    5 1203   32]\n",
      " [   2   25    1   23    3    0   77   96]]\n",
      "Accuracy: 85.70%\n",
      "F1-Score: 0.8262\n",
      "embedding: DGI\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 150)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 2.1547906398773193, Accuracy: 0.08976034820079803\n",
      "Epoch 11, Loss: 1.9470300674438477, Accuracy: 0.2540304958820343\n",
      "Epoch 21, Loss: 1.9389445781707764, Accuracy: 0.2535947859287262\n",
      "Epoch 31, Loss: 1.9301491975784302, Accuracy: 0.2540304958820343\n",
      "Epoch 41, Loss: 1.9005844593048096, Accuracy: 0.3677559792995453\n",
      "Epoch 51, Loss: 1.7796038389205933, Accuracy: 0.442701518535614\n",
      "Epoch 61, Loss: 1.6834653615951538, Accuracy: 0.5638344287872314\n",
      "Epoch 71, Loss: 1.6315784454345703, Accuracy: 0.5930283069610596\n",
      "Epoch 81, Loss: 1.592158317565918, Accuracy: 0.615686297416687\n",
      "Epoch 91, Loss: 1.5414925813674927, Accuracy: 0.684531569480896\n",
      "Epoch 101, Loss: 1.5136610269546509, Accuracy: 0.7246187329292297\n",
      "Epoch 111, Loss: 1.4950486421585083, Accuracy: 0.7385621070861816\n",
      "Epoch 121, Loss: 1.465917706489563, Accuracy: 0.7755991220474243\n",
      "Epoch 131, Loss: 1.4521466493606567, Accuracy: 0.7830065488815308\n",
      "Epoch 141, Loss: 1.438247799873352, Accuracy: 0.8004357218742371\n",
      "Epoch 151, Loss: 1.430819034576416, Accuracy: 0.8239651322364807\n",
      "Epoch 161, Loss: 1.4361687898635864, Accuracy: 0.8056644797325134\n",
      "Epoch 171, Loss: 1.4221307039260864, Accuracy: 0.8113289475440979\n",
      "Epoch 181, Loss: 1.4485324621200562, Accuracy: 0.8248366117477417\n",
      "Epoch 191, Loss: 1.4251025915145874, Accuracy: 0.8052287697792053\n",
      "Predicting...\n",
      "[[ 231   26    0    1    0    0    1    0]\n",
      " [  22 1049    4   71   10   12   14    0]\n",
      " [   7    8  469    3    3    4    3    0]\n",
      " [   5  133    4  440   44    0    9    0]\n",
      " [   1   22    8   12  535    0   35    0]\n",
      " [  10    3    4    3    1  562    1    0]\n",
      " [  54   88   12   25   21    3 1155    0]\n",
      " [   3   18    0   95    5    0  106    0]]\n",
      "Accuracy: 82.93%\n",
      "F1-Score: 0.7412\n",
      "embedding: MODULARITY\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 150)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 2.2489686012268066, Accuracy: 0.2052287608385086\n",
      "Epoch 11, Loss: 1.1538017988204956, Accuracy: 0.7834422588348389\n",
      "Epoch 21, Loss: 0.8017113208770752, Accuracy: 0.7816993594169617\n",
      "Epoch 31, Loss: 0.6684567332267761, Accuracy: 0.827886700630188\n",
      "Epoch 41, Loss: 0.5989212393760681, Accuracy: 0.8501089215278625\n",
      "Epoch 51, Loss: 0.5566487908363342, Accuracy: 0.8562091588973999\n",
      "Epoch 61, Loss: 0.5252065658569336, Accuracy: 0.856644868850708\n",
      "Epoch 71, Loss: 0.5001844763755798, Accuracy: 0.8601307272911072\n",
      "Epoch 81, Loss: 0.4795008599758148, Accuracy: 0.8596950173377991\n",
      "Epoch 91, Loss: 0.4617680013179779, Accuracy: 0.8640522956848145\n",
      "Epoch 101, Loss: 0.4463069438934326, Accuracy: 0.8684095740318298\n",
      "Epoch 111, Loss: 0.43258416652679443, Accuracy: 0.8732026219367981\n",
      "Epoch 121, Loss: 0.42033708095550537, Accuracy: 0.8740741014480591\n",
      "Epoch 131, Loss: 0.4092024564743042, Accuracy: 0.8788670897483826\n",
      "Epoch 141, Loss: 0.39888834953308105, Accuracy: 0.8819172382354736\n",
      "Epoch 151, Loss: 0.38917043805122375, Accuracy: 0.8840958476066589\n",
      "Epoch 161, Loss: 0.3799721300601959, Accuracy: 0.8867102265357971\n",
      "Epoch 171, Loss: 0.3711544871330261, Accuracy: 0.8875817060470581\n",
      "Epoch 181, Loss: 0.3626513183116913, Accuracy: 0.8884531855583191\n",
      "Epoch 191, Loss: 0.35435745120048523, Accuracy: 0.8897603750228882\n",
      "Predicting...\n",
      "[[ 167    8    2    2    0    1   78    1]\n",
      " [   3 1134    0   21    6   13    5    0]\n",
      " [   0   14  472    0    2    5    4    0]\n",
      " [   0  320    1  276   15    0   21    2]\n",
      " [   0   28    3    2  567    0   11    2]\n",
      " [   0   17    0    1    3  563    0    0]\n",
      " [   0  335  133    1   90    3  594  202]\n",
      " [   0   84    8    9    7    0   18  101]]\n",
      "Accuracy: 72.34%\n",
      "F1-Score: 0.7142\n",
      "embedding: MODULARITY\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 150)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 2.0795226097106934, Accuracy: 0.0322440080344677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 1.8640697002410889, Accuracy: 0.2540304958820343\n",
      "Epoch 21, Loss: 1.6470447778701782, Accuracy: 0.5202614665031433\n",
      "Epoch 31, Loss: 1.2332122325897217, Accuracy: 0.7385621070861816\n",
      "Epoch 41, Loss: 0.7295100688934326, Accuracy: 0.9176470637321472\n",
      "Epoch 51, Loss: 0.3875207304954529, Accuracy: 0.9450980424880981\n",
      "Epoch 61, Loss: 0.2296510636806488, Accuracy: 0.9529411792755127\n",
      "Epoch 71, Loss: 0.1703900545835495, Accuracy: 0.9555555582046509\n",
      "Epoch 81, Loss: 0.14451254904270172, Accuracy: 0.9603486061096191\n",
      "Epoch 91, Loss: 0.12919367849826813, Accuracy: 0.9603486061096191\n",
      "Epoch 101, Loss: 0.11708693206310272, Accuracy: 0.9616557955741882\n",
      "Epoch 111, Loss: 0.1040523499250412, Accuracy: 0.9668845534324646\n",
      "Epoch 121, Loss: 0.09504732489585876, Accuracy: 0.9725490212440491\n",
      "Epoch 131, Loss: 0.08489483594894409, Accuracy: 0.9734205007553101\n",
      "Epoch 141, Loss: 0.07635311037302017, Accuracy: 0.9769062995910645\n",
      "Epoch 151, Loss: 0.06998712569475174, Accuracy: 0.9786492586135864\n",
      "Epoch 161, Loss: 0.06391480565071106, Accuracy: 0.9803921580314636\n",
      "Epoch 171, Loss: 0.05720135197043419, Accuracy: 0.9825708270072937\n",
      "Epoch 181, Loss: 0.05207931250333786, Accuracy: 0.9830065369606018\n",
      "Epoch 191, Loss: 0.04770604521036148, Accuracy: 0.9838780164718628\n",
      "Predicting...\n",
      "[[ 246    5    3    3    0    2    0    0]\n",
      " [  10 1032    5   86   10   17   22    0]\n",
      " [   4    6  477    3    0    1    5    1]\n",
      " [   0   51    2  546   14    3   16    3]\n",
      " [   0   12    6    6  556    0   33    0]\n",
      " [   0    7    1    2    3  564    7    0]\n",
      " [  10    7   12   11   29    8 1279    2]\n",
      " [   1   11    1   25    5    1   51  132]]\n",
      "Accuracy: 90.23%\n",
      "F1-Score: 0.8883\n",
      "embedding: MODULARITY\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 150)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 2.215533971786499, Accuracy: 0.04008714482188225\n",
      "Epoch 11, Loss: 1.4883571863174438, Accuracy: 0.8614379167556763\n",
      "Epoch 21, Loss: 1.3537484407424927, Accuracy: 0.9904139637947083\n",
      "Epoch 31, Loss: 1.2885723114013672, Accuracy: 0.9938997626304626\n",
      "Epoch 41, Loss: 1.2486989498138428, Accuracy: 0.9978213310241699\n",
      "Epoch 51, Loss: 1.237169861793518, Accuracy: 0.999128520488739\n",
      "Epoch 61, Loss: 1.2337547540664673, Accuracy: 0.999128520488739\n",
      "Epoch 71, Loss: 1.2319841384887695, Accuracy: 0.9995642900466919\n",
      "Epoch 81, Loss: 1.23067307472229, Accuracy: 0.9995642900466919\n",
      "Epoch 91, Loss: 1.2298945188522339, Accuracy: 0.9995642900466919\n",
      "Epoch 101, Loss: 1.2292667627334595, Accuracy: 0.9995642900466919\n",
      "Epoch 111, Loss: 1.2287565469741821, Accuracy: 0.9995642900466919\n",
      "Epoch 121, Loss: 1.2283231019973755, Accuracy: 0.9995642900466919\n",
      "Epoch 131, Loss: 1.227954626083374, Accuracy: 0.9995642900466919\n",
      "Epoch 141, Loss: 1.2276403903961182, Accuracy: 0.9995642900466919\n",
      "Epoch 151, Loss: 1.2273684740066528, Accuracy: 0.9995642900466919\n",
      "Epoch 161, Loss: 1.2271307706832886, Accuracy: 0.9995642900466919\n",
      "Epoch 171, Loss: 1.2269209623336792, Accuracy: 0.9995642900466919\n",
      "Epoch 181, Loss: 1.2267355918884277, Accuracy: 0.9995642900466919\n",
      "Epoch 191, Loss: 1.226570963859558, Accuracy: 0.9995642900466919\n",
      "Predicting...\n",
      "[[ 245    7    2    5    0    0    0    0]\n",
      " [   8  958   10  155   15   15   13    8]\n",
      " [   1    3  475    7    4    2    4    1]\n",
      " [   2   39    2  561   11    0   15    5]\n",
      " [   0    8    7   44  522    1   30    1]\n",
      " [   2    2    1    2    3  564    5    5]\n",
      " [  15    9   12   21   21    5 1269    6]\n",
      " [   3    9    1   41    2    0   55  116]]\n",
      "Accuracy: 87.96%\n",
      "F1-Score: 0.8598\n",
      "embedding: NODE2VEC\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 150)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 108.04830169677734, Accuracy: 0.11633986979722977\n",
      "Epoch 11, Loss: 17.433509826660156, Accuracy: 0.557298481464386\n",
      "Epoch 21, Loss: 3.1353914737701416, Accuracy: 0.6714596748352051\n",
      "Epoch 31, Loss: 1.235599398612976, Accuracy: 0.5790849924087524\n",
      "Epoch 41, Loss: 1.1675167083740234, Accuracy: 0.6344226598739624\n",
      "Epoch 51, Loss: 1.0845369100570679, Accuracy: 0.671023964881897\n",
      "Epoch 61, Loss: 1.036367654800415, Accuracy: 0.6928104758262634\n",
      "Epoch 71, Loss: 0.991235613822937, Accuracy: 0.6893246173858643\n",
      "Epoch 81, Loss: 0.9611087441444397, Accuracy: 0.6936818957328796\n",
      "Epoch 91, Loss: 0.9422340989112854, Accuracy: 0.6906318068504333\n",
      "Epoch 101, Loss: 0.9253681898117065, Accuracy: 0.6936818957328796\n",
      "Epoch 111, Loss: 0.9104940295219421, Accuracy: 0.6945533752441406\n",
      "Epoch 121, Loss: 0.8969368934631348, Accuracy: 0.6928104758262634\n",
      "Epoch 131, Loss: 0.8844167590141296, Accuracy: 0.6958605647087097\n",
      "Epoch 141, Loss: 0.8716766238212585, Accuracy: 0.699782133102417\n",
      "Epoch 151, Loss: 0.8581686615943909, Accuracy: 0.7015250325202942\n",
      "Epoch 161, Loss: 0.84527987241745, Accuracy: 0.7063180804252625\n",
      "Epoch 171, Loss: 0.8328506946563721, Accuracy: 0.7076252698898315\n",
      "Epoch 181, Loss: 0.819614827632904, Accuracy: 0.7119825482368469\n",
      "Epoch 191, Loss: 0.7995216250419617, Accuracy: 0.7206971645355225\n",
      "Predicting...\n",
      "[[ 246    7    2    3    0    1    0    0]\n",
      " [  12  921    6  202   21   12    8    0]\n",
      " [   1    1  466   17    7    1    4    0]\n",
      " [  16   75    3  422   68    2   49    0]\n",
      " [   1   12    4   65  490    4   37    0]\n",
      " [   2    1    0   14    6  559    2    0]\n",
      " [  18    7   10   97   70    7 1149    0]\n",
      " [   5   15    3  123   21    1   59    0]]\n",
      "Accuracy: 79.42%\n",
      "F1-Score: 0.7195\n",
      "embedding: NODE2VEC\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 150)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 2.0764217376708984, Accuracy: 0.13769063353538513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.4419606626033783, Accuracy: 0.8527233004570007\n",
      "Epoch 21, Loss: 0.34532174468040466, Accuracy: 0.9058823585510254\n",
      "Epoch 31, Loss: 0.27543315291404724, Accuracy: 0.9224401116371155\n",
      "Epoch 41, Loss: 0.22975513339042664, Accuracy: 0.929411768913269\n",
      "Epoch 51, Loss: 0.2002449780702591, Accuracy: 0.9328976273536682\n",
      "Epoch 61, Loss: 0.1755405217409134, Accuracy: 0.9394335746765137\n",
      "Epoch 71, Loss: 0.15477000176906586, Accuracy: 0.9485839009284973\n",
      "Epoch 81, Loss: 0.13439002633094788, Accuracy: 0.9546840786933899\n",
      "Epoch 91, Loss: 0.11530130356550217, Accuracy: 0.9599128365516663\n",
      "Epoch 101, Loss: 0.09767153114080429, Accuracy: 0.9660130739212036\n",
      "Epoch 111, Loss: 0.08121698349714279, Accuracy: 0.972113311290741\n",
      "Epoch 121, Loss: 0.0667680874466896, Accuracy: 0.9799564480781555\n",
      "Epoch 131, Loss: 0.05616503581404686, Accuracy: 0.9821350574493408\n",
      "Epoch 141, Loss: 0.048189662396907806, Accuracy: 0.984749436378479\n",
      "Epoch 151, Loss: 0.04205676540732384, Accuracy: 0.9869281053543091\n",
      "Epoch 161, Loss: 0.037361029535532, Accuracy: 0.9882352948188782\n",
      "Epoch 171, Loss: 0.03401435539126396, Accuracy: 0.9899781942367554\n",
      "Epoch 181, Loss: 0.03172215819358826, Accuracy: 0.9895424842834473\n",
      "Epoch 191, Loss: 0.03008439391851425, Accuracy: 0.9899781942367554\n",
      "Predicting...\n",
      "[[ 232   12    1    4    2    2    5    1]\n",
      " [   3 1064    7   51    5   14   37    1]\n",
      " [   1    7  472    3    2    3    8    1]\n",
      " [   2   68    1  510   11    1   27   15]\n",
      " [   0    8    3    5  561    0   34    2]\n",
      " [   0    7    0    3    0  562   11    1]\n",
      " [  11   14    6   12   11    7 1274   23]\n",
      " [   1   11    0   11    3    1   27  173]]\n",
      "Accuracy: 90.53%\n",
      "F1-Score: 0.8966\n",
      "embedding: NODE2VEC\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 150)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 2.2075798511505127, Accuracy: 0.10283224284648895\n",
      "Epoch 11, Loss: 1.508905053138733, Accuracy: 0.7498910427093506\n",
      "Epoch 21, Loss: 1.3875056505203247, Accuracy: 0.8801742792129517\n",
      "Epoch 31, Loss: 1.3410289287567139, Accuracy: 0.9041394591331482\n",
      "Epoch 41, Loss: 1.3165173530578613, Accuracy: 0.9206971526145935\n",
      "Epoch 51, Loss: 1.3036826848983765, Accuracy: 0.927233099937439\n",
      "Epoch 61, Loss: 1.296025037765503, Accuracy: 0.9333333373069763\n",
      "Epoch 71, Loss: 1.290056586265564, Accuracy: 0.9389978051185608\n",
      "Epoch 81, Loss: 1.2847737073898315, Accuracy: 0.9459695219993591\n",
      "Epoch 91, Loss: 1.2799537181854248, Accuracy: 0.9520696997642517\n",
      "Epoch 101, Loss: 1.2757835388183594, Accuracy: 0.95686274766922\n",
      "Epoch 111, Loss: 1.2721561193466187, Accuracy: 0.9603486061096191\n",
      "Epoch 121, Loss: 1.2689224481582642, Accuracy: 0.9620915055274963\n",
      "Epoch 131, Loss: 1.265899419784546, Accuracy: 0.9651415944099426\n",
      "Epoch 141, Loss: 1.26284658908844, Accuracy: 0.9673202633857727\n",
      "Epoch 151, Loss: 1.259889006614685, Accuracy: 0.9716775417327881\n",
      "Epoch 161, Loss: 1.2570644617080688, Accuracy: 0.9729847311973572\n",
      "Epoch 171, Loss: 1.2544392347335815, Accuracy: 0.9742919206619263\n",
      "Epoch 181, Loss: 1.2518343925476074, Accuracy: 0.9777777791023254\n",
      "Epoch 191, Loss: 1.2499014139175415, Accuracy: 0.9773420691490173\n",
      "Predicting...\n",
      "[[ 250    4    1    1    0    1    1    1]\n",
      " [   7 1053    2   76    6   14   20    4]\n",
      " [   3    5  473    3    4    5    4    0]\n",
      " [   5   56    3  548    5    2   10    6]\n",
      " [   0   19    5    8  563    0   18    0]\n",
      " [   0    7    0    3    1  562   11    0]\n",
      " [  10   18   11   16   20    9 1234   40]\n",
      " [   1   10    0   20    3    1   24  168]]\n",
      "Accuracy: 90.59%\n",
      "F1-Score: 0.8968\n",
      "embedding: RANDOM\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 150)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 42.146175384521484, Accuracy: 0.09760348498821259\n",
      "Epoch 11, Loss: 4.729182243347168, Accuracy: 0.5124183297157288\n",
      "Epoch 21, Loss: 1.8514848947525024, Accuracy: 0.6884531378746033\n",
      "Epoch 31, Loss: 1.1838959455490112, Accuracy: 0.7311546802520752\n",
      "Epoch 41, Loss: 0.8760272264480591, Accuracy: 0.7633987069129944\n",
      "Epoch 51, Loss: 0.7403181791305542, Accuracy: 0.7877995371818542\n",
      "Epoch 61, Loss: 0.644955039024353, Accuracy: 0.8047930002212524\n",
      "Epoch 71, Loss: 0.5825102925300598, Accuracy: 0.8169934749603271\n",
      "Epoch 81, Loss: 0.539025068283081, Accuracy: 0.8305010795593262\n",
      "Epoch 91, Loss: 0.5057915449142456, Accuracy: 0.843137264251709\n",
      "Epoch 101, Loss: 0.4796099364757538, Accuracy: 0.8488017320632935\n",
      "Epoch 111, Loss: 0.45773589611053467, Accuracy: 0.8540304899215698\n",
      "Epoch 121, Loss: 0.4387064576148987, Accuracy: 0.8596950173377991\n",
      "Epoch 131, Loss: 0.42195290327072144, Accuracy: 0.8666666746139526\n",
      "Epoch 141, Loss: 0.40740227699279785, Accuracy: 0.871023952960968\n",
      "Epoch 151, Loss: 0.39436575770378113, Accuracy: 0.8732026219367981\n",
      "Epoch 161, Loss: 0.3826581835746765, Accuracy: 0.8762527108192444\n",
      "Epoch 171, Loss: 0.3721437156200409, Accuracy: 0.8788670897483826\n",
      "Epoch 181, Loss: 0.3626195192337036, Accuracy: 0.8806100487709045\n",
      "Epoch 191, Loss: 0.3537774682044983, Accuracy: 0.8827886581420898\n",
      "Predicting...\n",
      "[[ 18  31   3  10  25  62 108   2]\n",
      " [  4 996  14  85  12  27  31  13]\n",
      " [  1 113 224   4  23  29  94   9]\n",
      " [  7 440   2 146  11  17   7   5]\n",
      " [  0 167   7  34 227  10 159   9]\n",
      " [ 28 113   0   7   4 413  14   5]\n",
      " [  9 410  50  14  54 185 628   8]\n",
      " [  0 134   6   7   3   7  36  34]]\n",
      "Accuracy: 50.16%\n",
      "F1-Score: 0.4192\n",
      "embedding: RANDOM\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 150)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 2.0766706466674805, Accuracy: 0.1581699401140213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.7057252526283264, Accuracy: 0.7969498634338379\n",
      "Epoch 21, Loss: 0.28550148010253906, Accuracy: 0.9215686321258545\n",
      "Epoch 31, Loss: 0.1279360055923462, Accuracy: 0.9668845534324646\n",
      "Epoch 41, Loss: 0.06347998976707458, Accuracy: 0.9816993474960327\n",
      "Epoch 51, Loss: 0.0325450524687767, Accuracy: 0.9904139637947083\n",
      "Epoch 61, Loss: 0.016400236636400223, Accuracy: 0.9947712421417236\n",
      "Epoch 71, Loss: 0.009437181986868382, Accuracy: 0.9978213310241699\n",
      "Epoch 81, Loss: 0.006672711111605167, Accuracy: 0.9978213310241699\n",
      "Epoch 91, Loss: 0.005374091677367687, Accuracy: 0.9973856210708618\n",
      "Epoch 101, Loss: 0.004808951634913683, Accuracy: 0.9978213310241699\n",
      "Epoch 111, Loss: 0.004534939769655466, Accuracy: 0.9978213310241699\n",
      "Epoch 121, Loss: 0.0043600136414170265, Accuracy: 0.9978213310241699\n",
      "Epoch 131, Loss: 0.004213462118059397, Accuracy: 0.9978213310241699\n",
      "Epoch 141, Loss: 0.004112434573471546, Accuracy: 0.9978213310241699\n",
      "Epoch 151, Loss: 0.003959450405091047, Accuracy: 0.9978213310241699\n",
      "Epoch 161, Loss: 0.004153573885560036, Accuracy: 0.9978213310241699\n",
      "Epoch 171, Loss: 0.0036578462459146976, Accuracy: 0.9978213310241699\n",
      "Epoch 181, Loss: 0.003019278170540929, Accuracy: 0.9982571005821228\n",
      "Epoch 191, Loss: 0.002959061646834016, Accuracy: 0.9982571005821228\n",
      "Predicting...\n",
      "[[ 146   50    0   14    0    2    9   38]\n",
      " [   4  973   15   75   20   11   50   34]\n",
      " [   2  210  187   29   12    2   41   14]\n",
      " [   3  305    8  180   17    4   52   66]\n",
      " [   4  231    4   47  181    1  137    8]\n",
      " [   8   51    4   31    5  460   25    0]\n",
      " [  15   95   17   28   28    2 1147   26]\n",
      " [   2   28    2    6    3    0   66  120]]\n",
      "Accuracy: 63.38%\n",
      "F1-Score: 0.5820\n",
      "embedding: RANDOM\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 150)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 2.191924810409546, Accuracy: 0.07363834232091904\n",
      "Epoch 11, Loss: 1.7222626209259033, Accuracy: 0.5250544548034668\n",
      "Epoch 21, Loss: 1.5613892078399658, Accuracy: 0.7446622848510742\n",
      "Epoch 31, Loss: 1.471440076828003, Accuracy: 0.8326797485351562\n",
      "Epoch 41, Loss: 1.4170472621917725, Accuracy: 0.8819172382354736\n",
      "Epoch 51, Loss: 1.3819485902786255, Accuracy: 0.9154683947563171\n",
      "Epoch 61, Loss: 1.357108473777771, Accuracy: 0.9394335746765137\n",
      "Epoch 71, Loss: 1.3386141061782837, Accuracy: 0.9485839009284973\n",
      "Epoch 81, Loss: 1.3241783380508423, Accuracy: 0.957734227180481\n",
      "Epoch 91, Loss: 1.312890887260437, Accuracy: 0.9660130739212036\n",
      "Epoch 101, Loss: 1.3038175106048584, Accuracy: 0.9686274528503418\n",
      "Epoch 111, Loss: 1.296440601348877, Accuracy: 0.9729847311973572\n",
      "Epoch 121, Loss: 1.2901753187179565, Accuracy: 0.9773420691490173\n",
      "Epoch 131, Loss: 1.28508460521698, Accuracy: 0.9777777791023254\n",
      "Epoch 141, Loss: 1.2816675901412964, Accuracy: 0.9808278679847717\n",
      "Epoch 151, Loss: 1.2778810262680054, Accuracy: 0.9825708270072937\n",
      "Epoch 161, Loss: 1.2748866081237793, Accuracy: 0.9821350574493408\n",
      "Epoch 171, Loss: 1.2731828689575195, Accuracy: 0.9830065369606018\n",
      "Epoch 181, Loss: 1.2712900638580322, Accuracy: 0.9834422469139099\n",
      "Epoch 191, Loss: 1.269308090209961, Accuracy: 0.984749436378479\n",
      "Predicting...\n",
      "[[  5  89  12  47  12   4  89   1]\n",
      " [  2 782  16 101  66  32 182   1]\n",
      " [  0 232 145  31  14   5  69   1]\n",
      " [  2 304   9 163  42  11 104   0]\n",
      " [  0 236  25  37 164   5 143   3]\n",
      " [  0 262  30  25  42 161  64   0]\n",
      " [  3 381  12  67  31  15 847   2]\n",
      " [  0  80   9  26  15   2  86   9]]\n",
      "Accuracy: 42.50%\n",
      "F1-Score: 0.3151\n",
      "embedding: GIVEN\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 745)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 351.49029541015625, Accuracy: 0.07538126409053802\n",
      "Epoch 11, Loss: 200.5738067626953, Accuracy: 0.10501089692115784\n",
      "Epoch 21, Loss: 2.0889532566070557, Accuracy: 0.12200435996055603\n",
      "Epoch 31, Loss: 2.0698530673980713, Accuracy: 0.12200435996055603\n",
      "Epoch 41, Loss: 2.0482733249664307, Accuracy: 0.21960784494876862\n",
      "Epoch 51, Loss: 2.027738094329834, Accuracy: 0.21960784494876862\n",
      "Epoch 61, Loss: 2.009497880935669, Accuracy: 0.21960784494876862\n",
      "Epoch 71, Loss: 1.993876338005066, Accuracy: 0.21960784494876862\n",
      "Epoch 81, Loss: 1.980791449546814, Accuracy: 0.21960784494876862\n",
      "Epoch 91, Loss: 1.9699903726577759, Accuracy: 0.21960784494876862\n",
      "Epoch 101, Loss: 1.9611634016036987, Accuracy: 0.21960784494876862\n",
      "Epoch 111, Loss: 1.9540023803710938, Accuracy: 0.21960784494876862\n",
      "Epoch 121, Loss: 1.9482277631759644, Accuracy: 0.21960784494876862\n",
      "Epoch 131, Loss: 1.9435960054397583, Accuracy: 0.21960784494876862\n",
      "Epoch 141, Loss: 1.9399023056030273, Accuracy: 0.21960784494876862\n",
      "Epoch 151, Loss: 1.9369745254516602, Accuracy: 0.21960784494876862\n",
      "Epoch 161, Loss: 1.934669017791748, Accuracy: 0.2540304958820343\n",
      "Epoch 171, Loss: 1.932865023612976, Accuracy: 0.2540304958820343\n",
      "Epoch 181, Loss: 1.9314627647399902, Accuracy: 0.2540304958820343\n",
      "Epoch 191, Loss: 1.9303780794143677, Accuracy: 0.2540304958820343\n",
      "Predicting...\n",
      "[[   0    0    0    0    0    0  259    0]\n",
      " [   0    0    0    0    0    0 1182    0]\n",
      " [   0    0    0    0    0    0  497    0]\n",
      " [   0    0    0    0    0    0  635    0]\n",
      " [   0    0    0    0    0    0  613    0]\n",
      " [   0    0    0    0    0    0  584    0]\n",
      " [   0    0    0    0    0    0 1358    0]\n",
      " [   0    0    0    0    0    0  227    0]]\n",
      "Accuracy: 25.36%\n",
      "F1-Score: 0.0506\n",
      "embedding: GIVEN\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 745)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 2.0912766456604004, Accuracy: 0.2379084974527359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 1.604129433631897, Accuracy: 0.4313725531101227\n",
      "Epoch 21, Loss: 0.849682629108429, Accuracy: 0.7943354845046997\n",
      "Epoch 31, Loss: 0.42201489210128784, Accuracy: 0.8945533633232117\n",
      "Epoch 41, Loss: 0.2776717245578766, Accuracy: 0.9254902005195618\n",
      "Epoch 51, Loss: 0.20617420971393585, Accuracy: 0.9429193735122681\n",
      "Epoch 61, Loss: 0.15950222313404083, Accuracy: 0.9546840786933899\n",
      "Epoch 71, Loss: 0.12834692001342773, Accuracy: 0.9629629850387573\n",
      "Epoch 81, Loss: 0.10425954312086105, Accuracy: 0.9690631628036499\n",
      "Epoch 91, Loss: 0.08608011156320572, Accuracy: 0.9747276902198792\n",
      "Epoch 101, Loss: 0.07297579199075699, Accuracy: 0.9764705896377563\n",
      "Epoch 111, Loss: 0.06230999156832695, Accuracy: 0.9812636375427246\n",
      "Epoch 121, Loss: 0.05305098369717598, Accuracy: 0.9838780164718628\n",
      "Epoch 131, Loss: 0.0453379787504673, Accuracy: 0.986492395401001\n",
      "Epoch 141, Loss: 0.039342377334833145, Accuracy: 0.9873638153076172\n",
      "Epoch 151, Loss: 0.034279193729162216, Accuracy: 0.9891067743301392\n",
      "Epoch 161, Loss: 0.029773464426398277, Accuracy: 0.9899781942367554\n",
      "Epoch 171, Loss: 0.02590053714811802, Accuracy: 0.9930283427238464\n",
      "Epoch 181, Loss: 0.022582102566957474, Accuracy: 0.9938997626304626\n",
      "Epoch 191, Loss: 0.020113566890358925, Accuracy: 0.9943355321884155\n",
      "Predicting...\n",
      "[[ 233   19    0    1    0    1    4    1]\n",
      " [   1 1103    0   47    1   14   14    2]\n",
      " [   0    4  471    1    6    2   13    0]\n",
      " [   0   50    0  561    0    1   16    7]\n",
      " [   0    4    3    2  569    0   35    0]\n",
      " [   0    1    0    0    1  577    4    1]\n",
      " [   7    6    4    2   17    9 1306    7]\n",
      " [   2   14    0    2    3    1   44  161]]\n",
      "Accuracy: 93.02%\n",
      "F1-Score: 0.9195\n",
      "embedding: GIVEN\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (2295, 745)\n",
      "Shape of A_train_tensor: (2295, 2295)\n",
      "Shape of Y_train: (2295, 8)\n",
      "Epoch 1, Loss: 2.22906494140625, Accuracy: 0.09978213161230087\n",
      "Epoch 11, Loss: 1.8983381986618042, Accuracy: 0.3686274588108063\n",
      "Epoch 21, Loss: 1.8107770681381226, Accuracy: 0.41873639822006226\n",
      "Epoch 31, Loss: 1.6134593486785889, Accuracy: 0.7411764860153198\n",
      "Epoch 41, Loss: 1.5211806297302246, Accuracy: 0.7777777910232544\n",
      "Epoch 51, Loss: 1.4202258586883545, Accuracy: 0.8649237751960754\n",
      "Epoch 61, Loss: 1.3635814189910889, Accuracy: 0.9119825959205627\n",
      "Epoch 71, Loss: 1.3349051475524902, Accuracy: 0.9411764740943909\n",
      "Epoch 81, Loss: 1.3135581016540527, Accuracy: 0.9616557955741882\n",
      "Epoch 91, Loss: 1.2904411554336548, Accuracy: 0.9677559733390808\n",
      "Epoch 101, Loss: 1.2795239686965942, Accuracy: 0.97124183177948\n",
      "Epoch 111, Loss: 1.2765934467315674, Accuracy: 0.9751634001731873\n",
      "Epoch 121, Loss: 1.2707558870315552, Accuracy: 0.9773420691490173\n",
      "Epoch 131, Loss: 1.2646048069000244, Accuracy: 0.9812636375427246\n",
      "Epoch 141, Loss: 1.261271595954895, Accuracy: 0.9812636375427246\n",
      "Epoch 151, Loss: 1.2582311630249023, Accuracy: 0.98562091588974\n",
      "Epoch 161, Loss: 1.2585335969924927, Accuracy: 0.9882352948188782\n",
      "Epoch 171, Loss: 1.256959080696106, Accuracy: 0.9895424842834473\n",
      "Epoch 181, Loss: 1.2529058456420898, Accuracy: 0.9899781942367554\n",
      "Epoch 191, Loss: 1.2508959770202637, Accuracy: 0.9908496737480164\n",
      "Predicting...\n",
      "[[ 249    6    0    1    0    0    2    1]\n",
      " [   1 1132    1   26    1   14    6    1]\n",
      " [   1    4  473    2    7    1    9    0]\n",
      " [   1   18    4  605    3    1    1    2]\n",
      " [   0    3    4    1  587    1   17    0]\n",
      " [   0    3    0    0    1  576    3    1]\n",
      " [   5    8    5    4   29    8 1279   20]\n",
      " [   3   11    0    7    4    0   54  148]]\n",
      "Accuracy: 94.29%\n",
      "F1-Score: 0.9268\n"
     ]
    }
   ],
   "source": [
    "all_results=[]\n",
    "graph_embeddings_dict={}\n",
    "for emb in embedding_dict.keys():\n",
    "    for clf in classifiers:\n",
    "        results, embedding_matrix = train_and_evaluate(embedding_dict, emb, clf)\n",
    "        all_results.append(results)\n",
    "        key_string= emb + ' with ' + clf\n",
    "        graph_embeddings_dict[key_string]=embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b3c9e3-8e7f-4aca-b525-58e888f59e1e",
   "metadata": {},
   "source": [
    "## Saving aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b306b69c-c733-4ab2-ad6c-62ddd64bb9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved as ./photo_analysis_results/photo_seed46_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "# Define dataset name and seed\n",
    "dataset_name = \"photo\"\n",
    "seed_value = SEED\n",
    "\n",
    "# Save as CSV file without sorting\n",
    "filename = f\"{dataset_name}_seed{seed_value}_results.csv\"\n",
    "filename='./photo_analysis_results/'+filename\n",
    "df.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Results saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79b10213-6b04-4424-9290-62b94652d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings= embedding_dict | graph_embeddings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e15a828-8cd9-434e-a6d7-30ca3e94c30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_dict(original_dict, key_order):\n",
    "    \"\"\"\n",
    "    Reorders a dictionary based on a given list of keys.\n",
    "\n",
    "    Parameters:\n",
    "    - original_dict (dict): The dictionary to reorder.\n",
    "    - key_order (list): The list specifying the desired key order.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A new dictionary with keys ordered as per key_order.\n",
    "    \"\"\"\n",
    "    return {key: original_dict[key] for key in key_order if key in original_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d2162cf-8b0c-4e5d-910a-bc20dc5ff349",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_order = ['random', 'random with gcn', 'random with gat', 'random with graphsage', 'deepwalk', 'deepwalk with gcn', 'deepwalk with gat', 'deepwalk with graphsage', 'node2vec','node2vec with gcn', 'node2vec with gat', 'node2vec with graphsage', 'vgae', 'vgae with gcn', 'vgae with gat', 'vgae with graphsage', 'dgi', 'dgi with gcn', 'dgi with gat', 'dgi with graphsage', 'modularity', 'modularity with gcn', 'modularity with gat', 'modularity with graphsage', 'given', 'given with gcn', 'given with gat', 'given with graphsage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "575e78ef-fefe-42b0-aa6c-85c10b26b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = reorder_dict(all_embeddings, key_order)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f7ff891-c17e-4eba-9211-2c2c6287213f",
   "metadata": {},
   "source": [
    "visualize_all_embeddings(all_embeddings, labels, label_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
