{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c1ef1f-2372-44c0-9703-b8ac660cce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635c4039-0385-47e5-b341-f1473cc6fa05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time \n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import umap.umap_ as umap\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
    "from node2vec import Node2Vec\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import spektral\n",
    "from spektral.layers import GCNConv, GATConv\n",
    "from spektral.layers import GraphSageConv\n",
    "from spektral.data import Graph, Dataset, BatchLoader\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import DeepGraphInfomax, VGAE\n",
    "from torch_geometric.utils import from_networkx\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import normalize\n",
    "from joblib import Parallel, delayed\n",
    "from torch_geometric.nn import GCNConv as PyG_GCNConv, VGAE as PyG_VGAE\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9044d178-5de4-4fab-8b82-ca674598128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 46\n",
    "\n",
    "# Set seed for Python's built-in random module\n",
    "random.seed(SEED)\n",
    "\n",
    "# Set seed for NumPy\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Set seed for PyTorch\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b95802d-543f-4b3e-803a-cdbdb518595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom Dataset for the graph\n",
    "class PubMedDataset(Dataset):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        dataset = Planetoid(root=\".\", name=\"PubMed\")  # Load CiteSeer dataset\n",
    "        data = dataset[0]  # Access the first graph\n",
    "        \n",
    "        # Convert Torch tensors to NumPy\n",
    "        x = data.x.numpy()\n",
    "        edge_index = data.edge_index.numpy()\n",
    "        y = data.y.numpy()\n",
    "\n",
    "        # One-hot encode labels\n",
    "        num_classes = y.max() + 1  # Number of classes\n",
    "        y_one_hot = np.eye(num_classes)[y]  # One-hot encoding\n",
    "\n",
    "        # Convert edge_index to a sparse adjacency matrix\n",
    "        num_nodes = x.shape[0]\n",
    "        adj = lil_matrix((num_nodes, num_nodes), dtype=np.float32)\n",
    "        for i in range(edge_index.shape[1]):\n",
    "            src, dst = edge_index[:, i]\n",
    "            adj[src, dst] = 1\n",
    "            adj[dst, src] = 1  # Ensure undirected graph\n",
    "\n",
    "        return [Graph(x=x, a=adj, y=y_one_hot)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90c18215-d57c-47a9-957d-5f98fa330e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimensionality=150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b67b75-8102-41b3-b7d9-faac9a95ca1d",
   "metadata": {},
   "source": [
    "## Extracting modularity embedding and using it for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd20588d-2ca8-457e-ab49-a8f42f9cef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian Eigenmaps Embedding\n",
    "def deepwalk_embedding(G, k=2, walk_length=10, num_walks=80, workers=4):\n",
    "    node2vec = Node2Vec(G, dimensions=k, walk_length=walk_length, num_walks=num_walks, workers=workers)\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "    return np.array([model.wv[str(node)] for node in G.nodes()])\n",
    "\n",
    "# Node2Vec Embedding\n",
    "def node2vec_embedding(G, k=2, seed=SEED):\n",
    "    node2vec = Node2Vec(G, dimensions=k, walk_length=10, num_walks=100, workers=2, seed=seed)\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "    return np.array([model.wv[str(node)] for node in G.nodes()])\n",
    "\n",
    "\n",
    "# VGAE Embedding \n",
    "class VGAEEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = PyG_GCNConv(in_channels, 2 * out_channels)  # Use PyG_GCNConv\n",
    "        self.conv_mu = PyG_GCNConv(2 * out_channels, out_channels)  # Separate layer for mu\n",
    "        self.conv_logstd = PyG_GCNConv(2 * out_channels, out_channels)  # Separate layer for logstd\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = torch.relu(self.conv1(x, edge_index))\n",
    "        mu = self.conv_mu(x, edge_index)\n",
    "        logstd = self.conv_logstd(x, edge_index)\n",
    "        return mu, logstd\n",
    "\n",
    "def vgae_embedding(data, k=128):\n",
    "    # Use one-hot encoded node IDs as features\n",
    "    num_nodes = data.num_nodes\n",
    "    x = torch.eye(num_nodes)  # One-hot encoded node features\n",
    "\n",
    "    in_channels = x.shape[1]  # Feature dimension is equal to the number of nodes\n",
    "    model = PyG_VGAE(VGAEEncoder(in_channels, k))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    for _ in tqdm(range(200)):\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(x, data.edge_index)  # Use one-hot encoded features\n",
    "        loss = model.recon_loss(z, data.edge_index) + (1 / data.num_nodes) * model.kl_loss()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model.encode(x, data.edge_index).detach().numpy()\n",
    "\n",
    "# DGI Embedding\n",
    "def dgi_embedding(data, k=128):\n",
    "    class GCNEncoder(torch.nn.Module):\n",
    "        def __init__(self, in_channels, out_channels):\n",
    "            super().__init__()\n",
    "            self.conv1 = PyG_GCNConv(in_channels, 2 * out_channels)  # Use PyG_GCNConv\n",
    "            self.conv2 = PyG_GCNConv(2 * out_channels, out_channels)  # Use PyG_GCNConv\n",
    "\n",
    "        def forward(self, x, edge_index):\n",
    "            x = torch.relu(self.conv1(x, edge_index))\n",
    "            return self.conv2(x, edge_index)\n",
    "\n",
    "    # Use one-hot encoded node IDs as features\n",
    "    num_nodes = data.num_nodes\n",
    "    x = torch.eye(num_nodes)  # One-hot encoded node features\n",
    "\n",
    "    in_channels = x.shape[1]  # Feature dimension is equal to the number of nodes\n",
    "    model = DeepGraphInfomax(\n",
    "        hidden_channels=k,\n",
    "        encoder=GCNEncoder(in_channels, k),\n",
    "        summary=lambda z, *args, **kwargs: z.mean(dim=0),  # Ensure `summary` only takes `z`\n",
    "        corruption=lambda x, edge_index: (x[torch.randperm(x.size(0))], edge_index)  # Correct corruption function\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    for _ in tqdm(range(200)):\n",
    "        optimizer.zero_grad()\n",
    "        pos_z, neg_z, summary = model(x, data.edge_index)  # Use one-hot encoded features\n",
    "        loss = model.loss(pos_z, neg_z, summary)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return pos_z.detach().numpy()\n",
    "\n",
    "\n",
    "# Unsupervised gradient ascent for modularity maximization\n",
    "def gradient_ascent_modularity_unsupervised(G, k=2, eta=0.01, iterations=1000, seed=SEED):\n",
    "    np.random.seed(seed)  # Ensure deterministic initialization\n",
    "\n",
    "    A = nx.to_numpy_array(G)\n",
    "    l = A.sum(axis=1)\n",
    "    m = np.sum(l) / 2\n",
    "    B = A - np.outer(l, l) / (2 * m)\n",
    "    n = B.shape[0]\n",
    "\n",
    "    S = np.random.randn(n, k)  # Random Initialization\n",
    "    S, _ = np.linalg.qr(S)  # Ensure initial orthonormality\n",
    "\n",
    "    for i in tqdm(range(iterations), desc=\"Gradient Ascent Progress\"):\n",
    "        grad = (1 / (2 * m)) * B @ S\n",
    "        S += eta * grad\n",
    "        S, _ = np.linalg.qr(S)  # Orthonormalize using QR decomposition\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c468b5ec-43c2-4852-949b-521beda25e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_labeled_random_walks(G, label_mask, labels, num_walks, walk_length, walk_length_labelled=3):\n",
    "    walks = {node: [] for node in G.nodes()}\n",
    "    for node in G.nodes():\n",
    "        for _ in range(num_walks):\n",
    "            walk = [node]\n",
    "            labeled_count = 0\n",
    "            for _ in range(walk_length - 1):\n",
    "                cur = walk[-1]\n",
    "                neighbors = list(G.neighbors(cur))\n",
    "                if not neighbors:\n",
    "                    break\n",
    "                labeled_neighbors = [n for n in neighbors if label_mask[n]]\n",
    "                if labeled_neighbors and labeled_count < walk_length_labelled:\n",
    "                    next_node = random.choice(labeled_neighbors)\n",
    "                    labeled_count += 1\n",
    "                else:\n",
    "                    next_node = random.choice(neighbors)\n",
    "                walk.append(next_node)\n",
    "            walks[node].extend([n for n in walk if label_mask[n]])\n",
    "    return walks\n",
    "\n",
    "def compute_attention_weights(S, labeled_nodes):\n",
    "    weights = {}\n",
    "    for node, labeled in labeled_nodes.items():\n",
    "        if labeled:\n",
    "            similarities = {n: np.dot(S[node], S[n]) for n in labeled}\n",
    "            exp_sims = {n: np.exp(sim) for n, sim in similarities.items()}\n",
    "            total = sum(exp_sims.values())\n",
    "            weights[node] = {n: exp_sims[n] / total for n in labeled}\n",
    "    return weights\n",
    "\n",
    "def semi_supervised_gradient_ascent_modularity(G, labels, label_mask, k=2, eta=0.01, lambda_supervised=1.0, \n",
    "                                                      lambda_semi=2.0, iterations=5000, initialization='random',\n",
    "                                                      num_walks=10, walk_length=5, walk_length_labelled=3):\n",
    "    # Convert graph to sparse adjacency matrix\n",
    "    A = csr_matrix(nx.to_scipy_sparse_array(G, format='csr'))\n",
    "    degrees = np.array(A.sum(axis=1)).flatten()\n",
    "    m = G.number_of_edges()\n",
    "    n = A.shape[0]\n",
    "\n",
    "    # Initialize embeddings\n",
    "    if initialization == 'random':\n",
    "        S = np.random.randn(n, k)\n",
    "    S, _ = np.linalg.qr(S)\n",
    "\n",
    "    # Compute labeled random walks and attention weights\n",
    "    labeled_walks = perform_labeled_random_walks(G, label_mask, labels, num_walks, walk_length, walk_length_labelled)\n",
    "    attention_weights = compute_attention_weights(S, labeled_walks)\n",
    "\n",
    "    for _ in tqdm(range(iterations), desc=\"Gradient Ascent with Linear Modularity\"):\n",
    "        # Compute modularity gradient using linear approximation\n",
    "        neighbor_agg = A @ S  # Efficient aggregation of neighbor embeddings\n",
    "        global_correction = (degrees[:, None] / (2 * m)) * S.sum(axis=0)\n",
    "        grad_modularity = (1 / (2 * m)) * (neighbor_agg - global_correction)\n",
    "\n",
    "        # Compute supervised gradient\n",
    "        grad_supervised = np.zeros_like(S)\n",
    "        unique_labels = np.unique(labels[label_mask])\n",
    "        for label in unique_labels:\n",
    "            mask = (labels == label) & label_mask\n",
    "            mean_embedding = np.mean(S[mask], axis=0, keepdims=True)\n",
    "            grad_supervised[mask] = S[mask] - mean_embedding\n",
    "\n",
    "        # Compute semi-supervised gradient using adaptive attention\n",
    "        grad_semi_supervised = np.zeros_like(S)\n",
    "        for i in range(n):\n",
    "            if not label_mask[i] and i in attention_weights:\n",
    "                weighted_embedding = sum(weight * S[n] for n, weight in attention_weights[i].items())\n",
    "                grad_semi_supervised[i] = S[i] - weighted_embedding\n",
    "\n",
    "        # Update embeddings\n",
    "        grad_total = grad_modularity - lambda_supervised * grad_supervised - lambda_semi * grad_semi_supervised\n",
    "        S += eta * grad_total\n",
    "        S, _ = np.linalg.qr(S)\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d1fa1ef-526c-4ecb-a4e5-6c344f0412c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_networkx(A):\n",
    "    return nx.from_scipy_sparse_array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7fbba5b-3f7c-4821-9af5-d9d6e982b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PubMedDataset()\n",
    "ground_truth_labels = dataset[0].y\n",
    "labels=np.argmax(ground_truth_labels,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c92de7a7-bab8-4ee8-9601-e4f95f0386e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "labels_to_be_masked=np.random.choice(np.arange(len(labels)),int(len(labels)*.7),replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0cf50e3-56e5-4187-b4ef-9f05cd3bc76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_labels=[]\n",
    "for i in np.arange(len(labels)):\n",
    "    if i in labels_to_be_masked:\n",
    "        masked_labels.append(-1)\n",
    "    else:\n",
    "        masked_labels.append(labels[i])\n",
    "masked_labels=np.array(masked_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77562c2a-8c15-4b37-a4d3-674776a0edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask = masked_labels != -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "517544ea-62e6-495c-bce9-6733a551c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[0].x\n",
    "A = dataset[0].a\n",
    "G = convert_to_networkx(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42c8983a-9d5d-4f7a-9a1b-891e79fee2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency Matrix Shape: (19717, 19717)\n",
      "Graph Nodes: 19717\n",
      "Graph Edges: 44324\n"
     ]
    }
   ],
   "source": [
    "print(\"Adjacency Matrix Shape:\", A.shape)\n",
    "print(\"Graph Nodes:\", G.number_of_nodes())\n",
    "print(\"Graph Edges:\", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3afed25e-63b5-436a-8ccb-9cc8cf9c0f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert your preprocessed data into a PyTorch Geometric Data object\n",
    "X_py = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float),  # Node features\n",
    "    edge_index=torch.tensor(np.array(A.nonzero()), dtype=torch.long),  # Edge indices\n",
    "    y=torch.tensor(labels, dtype=torch.long)  # Labels\n",
    ")\n",
    "\n",
    "# Ensure edge_index is in the correct shape (2, num_edges)\n",
    "X_py.edge_index = X_py.edge_index.to(torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a20551-d0b8-45ca-b78f-530f3f038ddf",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6df67fd4-cb5e-4778-8029-d454b03c7f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing DeepWalk embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 19717/19717 [00:09<00:00, 2003.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepWalk embedding computed in 903.31 seconds.\n",
      "Computing VGAE embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [05:22<00:00,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGAE embedding computed in 323.60 seconds.\n",
      "Computing DGI embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [14:00<00:00,  4.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGI embedding computed in 840.77 seconds.\n",
      "Computing Modularity embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gradient Ascent with Linear Modularity: 100%|██████████| 200/200 [02:50<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modularity embedding computed in 176.37 seconds.\n",
      "Computing Node2Vec embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 19717/19717 [00:10<00:00, 1831.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node2Vec embedding computed in 518.67 seconds.\n",
      "Generating Random embedding...\n",
      "Random embedding generated in 0.04 seconds.\n",
      "All embeddings computed and stored in the dictionary successfully.\n",
      "\n",
      "Execution times saved to 'embedding_execution_times.csv'.\n",
      "        Model  Time (seconds)\n",
      "0    DeepWalk      903.312759\n",
      "1        VGAE      323.600382\n",
      "2         DGI      840.769592\n",
      "3  Modularity      176.374603\n",
      "4    Node2Vec      518.670925\n",
      "5      Random        0.039656\n"
     ]
    }
   ],
   "source": [
    "# Dictionary for embeddings\n",
    "embedding_dict = {}\n",
    "execution_times = []  # List to store execution times\n",
    "\n",
    "# Compute embeddings and store them with time tracking\n",
    "def record_time(model_name, func, *args, **kwargs):\n",
    "    print(f\"Computing {model_name} embedding...\")\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    execution_times.append((model_name, elapsed_time))\n",
    "    print(f\"{model_name} embedding computed in {elapsed_time:.2f} seconds.\")\n",
    "    return result\n",
    "\n",
    "X_deepwalk = record_time(\"DeepWalk\", deepwalk_embedding, G, k=embedding_dimensionality)\n",
    "X_deepwalk = tf.convert_to_tensor(X_deepwalk, dtype=tf.float32)\n",
    "embedding_dict['deepwalk'] = X_deepwalk\n",
    "\n",
    "X_vgae = record_time(\"VGAE\", vgae_embedding, X_py, k=embedding_dimensionality)\n",
    "embedding_dict['vgae'] = X_vgae\n",
    "\n",
    "X_dgi = record_time(\"DGI\", dgi_embedding, X_py, k=embedding_dimensionality)\n",
    "embedding_dict['dgi'] = X_dgi\n",
    "\n",
    "X_modularity = record_time(\"Modularity\", semi_supervised_gradient_ascent_modularity,\n",
    "                           G, labels, label_mask, k=embedding_dimensionality,\n",
    "                           eta=0.05, lambda_supervised=1.0, lambda_semi=2.0, iterations=200, initialization='random')\n",
    "embedding_dict['modularity'] = X_modularity\n",
    "\n",
    "X_node2vec = record_time(\"Node2Vec\", node2vec_embedding, G, k=embedding_dimensionality)\n",
    "X_node2vec = tf.convert_to_tensor(X_node2vec, dtype=tf.float32)\n",
    "embedding_dict['node2vec'] = X_node2vec\n",
    "\n",
    "# Generate random embedding\n",
    "print(\"Generating Random embedding...\")\n",
    "start_time = time.time()\n",
    "shape = (len(ground_truth_labels), embedding_dimensionality)\n",
    "X_random = np.random.randn(*shape)\n",
    "X_random = tf.convert_to_tensor(X_random, dtype=tf.float32)\n",
    "end_time = time.time()\n",
    "execution_times.append((\"Random\", end_time - start_time))\n",
    "print(f\"Random embedding generated in {end_time - start_time:.2f} seconds.\")\n",
    "embedding_dict['random'] = X_random\n",
    "\n",
    "# Use original node features as 'given' embedding\n",
    "embedding_dict['given'] = X\n",
    "\n",
    "print(\"All embeddings computed and stored in the dictionary successfully.\")\n",
    "\n",
    "# Store execution times in a DataFrame and save\n",
    "execution_df = pd.DataFrame(execution_times, columns=[\"Model\", \"Time (seconds)\"])\n",
    "execution_df.to_csv(\"./pubmed_analysis_results/embedding_execution_times_pubmed_\"+str(SEED)+\".csv\", index=False)\n",
    "\n",
    "print(\"\\nExecution times saved to 'embedding_execution_times.csv'.\")\n",
    "print(execution_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef266fb-0ff7-442a-a432-9d8e3e0c73bd",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e3beadc-c04d-4fb7-a594-9278fa0b772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_all_embeddings(all_embeddings, labels, label_mask):\n",
    "    \"\"\"\n",
    "    Visualize all embeddings in a grid with 4 columns per row using UMAP.\n",
    "\n",
    "    Parameters:\n",
    "    - all_embeddings: Dictionary where keys are embedding methods, and values are embeddings.\n",
    "    - labels: Labels (numpy array of shape [n_nodes]).\n",
    "    - label_mask: Boolean array indicating known labels (True for known, False for unknown).\n",
    "    \"\"\"\n",
    "    num_embeddings = len(all_embeddings)\n",
    "    num_rows = (num_embeddings + 3) // 4  # Ensure enough rows for all embeddings\n",
    "    fig, axes = plt.subplots(num_rows, 4, figsize=(8.27, 11.69))  # A4 size\n",
    "\n",
    "    for i, (embedding_type, embedding) in tqdm(enumerate(all_embeddings.items()), \n",
    "                                               total=num_embeddings, desc=\"Visualizing embeddings\"):\n",
    "        row, col = divmod(i, 4)\n",
    "        ax = axes[row, col] if num_rows > 1 else axes[col]  # Adjust for single-row case\n",
    "\n",
    "        # Ensure embedding is a NumPy array\n",
    "        if isinstance(embedding, tf.Tensor):\n",
    "            embedding = embedding.numpy()\n",
    "\n",
    "        # Reduce dimensionality using UMAP\n",
    "        reducer = umap.UMAP(n_components=2)\n",
    "        embedding_2d = reducer.fit_transform(embedding)\n",
    "\n",
    "        # Known labels\n",
    "        ax.scatter(embedding_2d[label_mask, 0], embedding_2d[label_mask, 1], \n",
    "                   c=labels[label_mask], cmap=\"Set1\", s=3, alpha=0.7, label=\"Known Labels\",\n",
    "                   edgecolors='none')\n",
    "\n",
    "        # Unknown labels\n",
    "        ax.scatter(embedding_2d[~label_mask, 0], embedding_2d[~label_mask, 1], \n",
    "                   c=labels[~label_mask], cmap=\"Set1\", s=5, alpha=0.7, \n",
    "                   label=\"Unknown Labels\", edgecolors='black', linewidths=0.2)\n",
    "\n",
    "        # Title with smaller font size\n",
    "        ax.set_title(embedding_type.upper(), fontsize=8, pad=2)\n",
    "\n",
    "        # Remove axis labels, ticks, and frames\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "    # Remove empty subplots if num_embeddings is not a multiple of 4\n",
    "    for j in range(i + 1, num_rows * 4):\n",
    "        row, col = divmod(j, 4)\n",
    "        fig.delaxes(axes[row, col])\n",
    "\n",
    "    plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05, wspace=0.2, hspace=0.2)  # Adjust margins\n",
    "    save_path = \"./pubmed_analysis_results/embedding_grid_plot_pubmed.png\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Visualization saved to {save_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02d06d16-eaab-4545-979b-122ba896a062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance using accuracy, F1-score, and confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.array): Ground truth labels (integers).\n",
    "        predicted_labels (np.array): Predicted labels (integers).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing accuracy, F1-score, and confusion matrix.\n",
    "    \"\"\"\n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    \n",
    "    # Compute F1-score (macro-averaged)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    #\n",
    "    print(cm)\n",
    "    \n",
    "    # Return results as a dictionary\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3f4b65-3785-42a1-9053-2d8dbe3e123f",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e240ad83-5c3e-45b0-a2a5-c955776d2e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(tf.keras.Model):\n",
    "    def __init__(self, n_labels, seed=42):  # Use an explicit seed\n",
    "        super().__init__()\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=seed)  # Define initializer\n",
    "        \n",
    "        self.conv1 = GCNConv(16, activation='relu', kernel_initializer=initializer)\n",
    "        self.conv2 = GCNConv(n_labels, activation='softmax', kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        intermediate_embeddings = self.conv1([x, a])  # Store intermediate embeddings\n",
    "        x = self.conv2([intermediate_embeddings, a])\n",
    "        return x, intermediate_embeddings  # Return both final output and intermediate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23274e8f-d679-4489-acb7-44f030552344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GAT model\n",
    "class GAT(tf.keras.Model):\n",
    "    def __init__(self, n_labels, num_heads=8, seed=42):\n",
    "        super().__init__()\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=seed)\n",
    "\n",
    "        self.conv1 = GATConv(16, attn_heads=num_heads, concat_heads=True, activation='elu', kernel_initializer=initializer)\n",
    "        self.conv2 = GATConv(n_labels, attn_heads=1, concat_heads=False, activation='softmax', kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        intermediate_embeddings = self.conv1([x, a])  # Store intermediate embeddings\n",
    "        x = self.conv2([intermediate_embeddings, a])\n",
    "        return x, intermediate_embeddings  # Return both final output and intermediate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "069f479d-ac8f-4d2e-82a3-3bc14d8cc4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphSAGE model\n",
    "class GraphSAGE(tf.keras.Model):\n",
    "    def __init__(self, n_labels, hidden_dim=16, aggregator='mean', seed=42):\n",
    "        super().__init__()\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=seed)\n",
    "\n",
    "        self.conv1 = GraphSageConv(hidden_dim, activation='relu', aggregator=aggregator, kernel_initializer=initializer)\n",
    "        self.conv2 = GraphSageConv(n_labels, activation='softmax', aggregator=aggregator, kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        intermediate_embeddings = self.conv1([x, a])  # Store intermediate embeddings\n",
    "        x = self.conv2([intermediate_embeddings, a])\n",
    "        return x, intermediate_embeddings  # Return both final output and intermediate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "998cf90d-9a35-429f-ae91-122307c2d262",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers=['gcn','gat','graphsage']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fb8569-8c63-4d64-8f6b-5485e0ed1d42",
   "metadata": {},
   "source": [
    "## Classification using different node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b351b542-9cd4-4f08-85f6-542495114e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(embedding_dict, embedding, classifier, ground_truth_labels=ground_truth_labels, masked_labels=masked_labels):\n",
    "    \"the labels have to be one hot encoded\"\n",
    "    \"model take values: gcn, gat, graphsage\"\n",
    "    print('embedding: ' + embedding.upper())\n",
    "    print('model: ' + classifier.upper())\n",
    "\n",
    "    X = embedding_dict[embedding]\n",
    "\n",
    "    print(\"Processing...\")\n",
    "    # Create boolean mask for training\n",
    "    train_mask = masked_labels != -1\n",
    "\n",
    "    # Split the data into training and prediction sets\n",
    "    X_train = X[train_mask]  # Training node features\n",
    "    Y_train = ground_truth_labels[train_mask]  # Training labels (one-hot encoded)\n",
    "    Y_train = tf.cast(Y_train, dtype='int32')\n",
    "    \n",
    "    # Reduce the adjacency matrix to only include training nodes\n",
    "    A_train = A[train_mask, :][:, train_mask]  # Correctly reduce the adjacency matrix\n",
    "    \n",
    "    # Convert sparse adjacency matrix to COO format\n",
    "    A_coo = A_train.tocoo()\n",
    "    indices = np.column_stack((A_coo.row, A_coo.col))  # Corrected indices format\n",
    "    values = A_coo.data\n",
    "    shape = A_coo.shape  # Shape: (num_nodes, num_nodes)\n",
    "    \n",
    "    # Create a sparse tensor for the adjacency matrix\n",
    "    A_train_tensor = tf.sparse.SparseTensor(indices=indices, values=values, dense_shape=shape)\n",
    "    \n",
    "    # Ensure the sparse tensor is ordered correctly\n",
    "    A_train_tensor = tf.sparse.reorder(A_train_tensor)\n",
    "\n",
    "    print(\"Training...\")\n",
    "    # Initialize the model\n",
    "    if classifier == 'gcn':\n",
    "        n_labels = ground_truth_labels.shape[1]  # Number of classes\n",
    "        model = GCN(n_labels)\n",
    "    elif classifier == 'gat':\n",
    "        n_labels = ground_truth_labels.shape[1]  # Number of classes\n",
    "        model = GAT(n_labels)\n",
    "    elif classifier == 'graphsage':\n",
    "        n_labels = ground_truth_labels.shape[1]  # Number of classes\n",
    "        model = GraphSAGE(n_labels)\n",
    "    \n",
    "    # Compile the model (not strictly necessary when using GradientTape, but useful for metrics)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.01),\n",
    "        loss=CategoricalCrossentropy(),\n",
    "        metrics=[CategoricalAccuracy()]\n",
    "    )\n",
    "    \n",
    "    # Print shapes for debugging\n",
    "    print(f\"Shape of X_train: {X_train.shape}\")\n",
    "    print(f\"Shape of A_train_tensor: {A_train_tensor.shape}\")\n",
    "    print(f\"Shape of Y_train: {Y_train.shape}\")\n",
    "    \n",
    "    # Define the optimizer and loss function\n",
    "    optimizer = Adam(learning_rate=0.01)\n",
    "    loss_fn = CategoricalCrossentropy()\n",
    "    \n",
    "    # Training loop with GradientTape\n",
    "    epochs = 200\n",
    "    for epoch in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            predictions, intermediate_embeddings = model([X_train, A_train_tensor])  # Unpack both outputs\n",
    "                \n",
    "            # Compute supervised loss (cross-entropy)\n",
    "            supervised_loss = loss_fn(Y_train, predictions)\n",
    "            \n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(supervised_loss, model.trainable_variables)\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "        # Print loss and accuracy for monitoring\n",
    "        if epoch % 10 == 0:\n",
    "            accuracy = CategoricalAccuracy()(Y_train, predictions)\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {supervised_loss.numpy()}, Accuracy: {accuracy.numpy()}\")\n",
    "\n",
    "    print(\"Predicting...\")\n",
    "    # Prepare the full graph for prediction\n",
    "    X_full = X  # Full node features\n",
    "    A_full = A  # Full adjacency matrix\n",
    "    \n",
    "    # Convert the full adjacency matrix to COO format\n",
    "    A_full_coo = A_full.tocoo()\n",
    "    indices_full = np.column_stack((A_full_coo.row, A_full_coo.col))\n",
    "    values_full = A_full_coo.data\n",
    "    shape_full = A_full_coo.shape\n",
    "    \n",
    "    # Create a sparse tensor for the full adjacency matrix\n",
    "    A_full_tensor = tf.sparse.SparseTensor(indices=indices_full, values=values_full, dense_shape=shape_full)\n",
    "    A_full_tensor = tf.sparse.reorder(A_full_tensor)\n",
    "    \n",
    "    # Make predictions for all nodes\n",
    "    predictions, emb = model([X_full, A_full_tensor])  # Shape: [num_nodes, n_labels]\n",
    "\n",
    "    # Convert predictions to class labels (integers)\n",
    "    predicted_labels = tf.argmax(predictions, axis=1).numpy()  # Shape: [num_nodes]\n",
    "    \n",
    "    # Extract predictions for the masked nodes\n",
    "    predicted_labels_masked = predicted_labels[labels_to_be_masked]\n",
    "\n",
    "    # True labels for the masked nodes\n",
    "    true_labels_masked = labels[labels_to_be_masked]\n",
    "    \n",
    "    # Predicted labels for the masked nodes\n",
    "    predicted_labels_masked = predicted_labels[labels_to_be_masked]\n",
    "    \n",
    "    # Evaluate the model's performance\n",
    "    results = evaluate_model(true_labels_masked, predicted_labels_masked)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Accuracy: {results['accuracy'] * 100:.2f}%\")\n",
    "    print(f\"F1-Score: {results['f1_score']:.4f}\")\n",
    "\n",
    "    results['model'] = classifier\n",
    "    results['embedding'] = embedding\n",
    "\n",
    "    # Return results and intermediate embeddings for visualization\n",
    "    return results, emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "22973cce-dff8-4f59-abe8-1b91ac702849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding: DEEPWALK\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 150)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 3.3151021003723145, Accuracy: 0.3049357533454895\n",
      "Epoch 11, Loss: 0.8751522898674011, Accuracy: 0.5848546028137207\n",
      "Epoch 21, Loss: 0.823583722114563, Accuracy: 0.5975320935249329\n",
      "Epoch 31, Loss: 0.7882698178291321, Accuracy: 0.6071670055389404\n",
      "Epoch 41, Loss: 0.7688202857971191, Accuracy: 0.6154496073722839\n",
      "Epoch 51, Loss: 0.7550916075706482, Accuracy: 0.6210277080535889\n",
      "Epoch 61, Loss: 0.7439541816711426, Accuracy: 0.6249154806137085\n",
      "Epoch 71, Loss: 0.7352607846260071, Accuracy: 0.6279580593109131\n",
      "Epoch 81, Loss: 0.7280264496803284, Accuracy: 0.6294793486595154\n",
      "Epoch 91, Loss: 0.7214968800544739, Accuracy: 0.6320148706436157\n",
      "Epoch 101, Loss: 0.7155686020851135, Accuracy: 0.6328600645065308\n",
      "Epoch 111, Loss: 0.7099736332893372, Accuracy: 0.6364097595214844\n",
      "Epoch 121, Loss: 0.7045320868492126, Accuracy: 0.639621376991272\n",
      "Epoch 131, Loss: 0.6992949843406677, Accuracy: 0.6406355500221252\n",
      "Epoch 141, Loss: 0.6943209171295166, Accuracy: 0.6409736275672913\n",
      "Epoch 151, Loss: 0.6893999576568604, Accuracy: 0.6426639556884766\n",
      "Epoch 161, Loss: 0.6847952604293823, Accuracy: 0.6441852450370789\n",
      "Epoch 171, Loss: 0.6802854537963867, Accuracy: 0.6453685164451599\n",
      "Epoch 181, Loss: 0.6763156652450562, Accuracy: 0.6451994776725769\n",
      "Epoch 191, Loss: 0.6727151274681091, Accuracy: 0.6458755731582642\n",
      "Predicting...\n",
      "[[2046  324  487]\n",
      " [ 352 4522  555]\n",
      " [ 653  602 4260]]\n",
      "Accuracy: 78.46%\n",
      "F1-Score: 0.7706\n",
      "embedding: DEEPWALK\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 150)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 1.1014662981033325, Accuracy: 0.32927653193473816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.5341686010360718, Accuracy: 0.8000338077545166\n",
      "Epoch 21, Loss: 0.4844798147678375, Accuracy: 0.8167681097984314\n",
      "Epoch 31, Loss: 0.4637574255466461, Accuracy: 0.8236984610557556\n",
      "Epoch 41, Loss: 0.45135146379470825, Accuracy: 0.8313049077987671\n",
      "Epoch 51, Loss: 0.44182106852531433, Accuracy: 0.8331642746925354\n",
      "Epoch 61, Loss: 0.43097200989723206, Accuracy: 0.8351926803588867\n",
      "Epoch 71, Loss: 0.41623198986053467, Accuracy: 0.8407707810401917\n",
      "Epoch 81, Loss: 0.39593803882598877, Accuracy: 0.8507437705993652\n",
      "Epoch 91, Loss: 0.3702104389667511, Accuracy: 0.8578431606292725\n",
      "Epoch 101, Loss: 0.34406763315200806, Accuracy: 0.8693373799324036\n",
      "Epoch 111, Loss: 0.31408828496932983, Accuracy: 0.8823529481887817\n",
      "Epoch 121, Loss: 0.2826573848724365, Accuracy: 0.8941852450370789\n",
      "Epoch 131, Loss: 0.25692445039749146, Accuracy: 0.9009465575218201\n",
      "Epoch 141, Loss: 0.22867651283740997, Accuracy: 0.913116991519928\n",
      "Epoch 151, Loss: 0.20672854781150818, Accuracy: 0.9215686321258545\n",
      "Epoch 161, Loss: 0.17910566926002502, Accuracy: 0.9349222183227539\n",
      "Epoch 171, Loss: 0.1661069542169571, Accuracy: 0.9366125464439392\n",
      "Epoch 181, Loss: 0.14305318892002106, Accuracy: 0.9464164972305298\n",
      "Epoch 191, Loss: 0.12453022599220276, Accuracy: 0.9582487940788269\n",
      "Predicting...\n",
      "[[2019  352  486]\n",
      " [ 261 4579  589]\n",
      " [ 522  624 4369]]\n",
      "Accuracy: 79.47%\n",
      "F1-Score: 0.7815\n",
      "embedding: DEEPWALK\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 150)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 1.2305158376693726, Accuracy: 0.33553075790405273\n",
      "Epoch 11, Loss: 0.701872706413269, Accuracy: 0.7941176295280457\n",
      "Epoch 21, Loss: 0.6772595643997192, Accuracy: 0.8144016265869141\n",
      "Epoch 31, Loss: 0.6657015681266785, Accuracy: 0.8221771717071533\n",
      "Epoch 41, Loss: 0.6565020084381104, Accuracy: 0.8275862336158752\n",
      "Epoch 51, Loss: 0.6492592096328735, Accuracy: 0.8336713910102844\n",
      "Epoch 61, Loss: 0.642562747001648, Accuracy: 0.8411088585853577\n",
      "Epoch 71, Loss: 0.6362237930297852, Accuracy: 0.8463488817214966\n",
      "Epoch 81, Loss: 0.629805326461792, Accuracy: 0.8504056930541992\n",
      "Epoch 91, Loss: 0.6224411725997925, Accuracy: 0.8588573336601257\n",
      "Epoch 101, Loss: 0.6157503128051758, Accuracy: 0.8635902404785156\n",
      "Epoch 111, Loss: 0.6097888946533203, Accuracy: 0.8706896305084229\n",
      "Epoch 121, Loss: 0.6027254462242126, Accuracy: 0.8764367699623108\n",
      "Epoch 131, Loss: 0.5959708094596863, Accuracy: 0.8848884105682373\n",
      "Epoch 141, Loss: 0.5941687822341919, Accuracy: 0.8862407207489014\n",
      "Epoch 151, Loss: 0.5870606303215027, Accuracy: 0.8945233225822449\n",
      "Epoch 161, Loss: 0.5809463262557983, Accuracy: 0.9006085395812988\n",
      "Epoch 171, Loss: 0.5756223797798157, Accuracy: 0.9048343300819397\n",
      "Epoch 181, Loss: 0.5719892382621765, Accuracy: 0.9080459475517273\n",
      "Epoch 191, Loss: 0.5681658387184143, Accuracy: 0.913286030292511\n",
      "Predicting...\n",
      "[[1954  351  552]\n",
      " [ 235 4698  496]\n",
      " [ 452  639 4424]]\n",
      "Accuracy: 80.26%\n",
      "F1-Score: 0.7871\n",
      "embedding: VGAE\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 150)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 2.051957130432129, Accuracy: 0.2599729597568512\n",
      "Epoch 11, Loss: 0.8703362345695496, Accuracy: 0.5863759517669678\n",
      "Epoch 21, Loss: 0.8152567744255066, Accuracy: 0.6005747318267822\n",
      "Epoch 31, Loss: 0.7858384847640991, Accuracy: 0.6076741218566895\n",
      "Epoch 41, Loss: 0.7672305107116699, Accuracy: 0.6178160905838013\n",
      "Epoch 51, Loss: 0.7544535398483276, Accuracy: 0.6195064187049866\n",
      "Epoch 61, Loss: 0.7451764345169067, Accuracy: 0.6240703463554382\n",
      "Epoch 71, Loss: 0.7369935512542725, Accuracy: 0.6276200413703918\n",
      "Epoch 81, Loss: 0.7296445369720459, Accuracy: 0.6267748475074768\n",
      "Epoch 91, Loss: 0.7226552367210388, Accuracy: 0.6311697363853455\n",
      "Epoch 101, Loss: 0.7160729765892029, Accuracy: 0.6355645656585693\n",
      "Epoch 111, Loss: 0.7099655866622925, Accuracy: 0.6374239325523376\n",
      "Epoch 121, Loss: 0.7040954828262329, Accuracy: 0.639621376991272\n",
      "Epoch 131, Loss: 0.698576033115387, Accuracy: 0.6416497826576233\n",
      "Epoch 141, Loss: 0.6934962868690491, Accuracy: 0.6441852450370789\n",
      "Epoch 151, Loss: 0.6885043978691101, Accuracy: 0.6472278833389282\n",
      "Epoch 161, Loss: 0.6838775873184204, Accuracy: 0.6480730175971985\n",
      "Epoch 171, Loss: 0.6794484853744507, Accuracy: 0.6490872502326965\n",
      "Epoch 181, Loss: 0.6750108599662781, Accuracy: 0.6495943069458008\n",
      "Epoch 191, Loss: 0.670785665512085, Accuracy: 0.6522988677024841\n",
      "Predicting...\n",
      "[[1907  340  610]\n",
      " [ 539 4238  652]\n",
      " [ 637  641 4237]]\n",
      "Accuracy: 75.23%\n",
      "F1-Score: 0.7358\n",
      "embedding: VGAE\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 150)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 1.0966218709945679, Accuracy: 0.3711967468261719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.6716559529304504, Accuracy: 0.7307302355766296\n",
      "Epoch 21, Loss: 0.6239644289016724, Accuracy: 0.7447599768638611\n",
      "Epoch 31, Loss: 0.6083436608314514, Accuracy: 0.7511832118034363\n",
      "Epoch 41, Loss: 0.6010280251502991, Accuracy: 0.7591277956962585\n",
      "Epoch 51, Loss: 0.5950042605400085, Accuracy: 0.7592968344688416\n",
      "Epoch 61, Loss: 0.5881367325782776, Accuracy: 0.7630155682563782\n",
      "Epoch 71, Loss: 0.5781629681587219, Accuracy: 0.7660581469535828\n",
      "Epoch 81, Loss: 0.5617530345916748, Accuracy: 0.773833692073822\n",
      "Epoch 91, Loss: 0.5340700149536133, Accuracy: 0.7876943945884705\n",
      "Epoch 101, Loss: 0.49340301752090454, Accuracy: 0.8040906190872192\n",
      "Epoch 111, Loss: 0.4442346394062042, Accuracy: 0.8269100785255432\n",
      "Epoch 121, Loss: 0.38881343603134155, Accuracy: 0.8551385998725891\n",
      "Epoch 131, Loss: 0.33058294653892517, Accuracy: 0.8828600645065308\n",
      "Epoch 141, Loss: 0.2791329324245453, Accuracy: 0.9016227126121521\n",
      "Epoch 151, Loss: 0.23104162514209747, Accuracy: 0.9213995933532715\n",
      "Epoch 161, Loss: 0.18845050036907196, Accuracy: 0.9399932622909546\n",
      "Epoch 171, Loss: 0.1513456404209137, Accuracy: 0.9565584659576416\n",
      "Epoch 181, Loss: 0.12119174748659134, Accuracy: 0.9682217836380005\n",
      "Epoch 191, Loss: 0.09631137549877167, Accuracy: 0.9746450185775757\n",
      "Predicting...\n",
      "[[1810  460  587]\n",
      " [ 389 4308  732]\n",
      " [ 558  831 4126]]\n",
      "Accuracy: 74.23%\n",
      "F1-Score: 0.7263\n",
      "embedding: VGAE\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 150)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 1.256742000579834, Accuracy: 0.2996957302093506\n",
      "Epoch 11, Loss: 0.7514740228652954, Accuracy: 0.7525355219841003\n",
      "Epoch 21, Loss: 0.7171950340270996, Accuracy: 0.7795807719230652\n",
      "Epoch 31, Loss: 0.6934449076652527, Accuracy: 0.7993576526641846\n",
      "Epoch 41, Loss: 0.6735008358955383, Accuracy: 0.820317804813385\n",
      "Epoch 51, Loss: 0.6579819917678833, Accuracy: 0.8329952955245972\n",
      "Epoch 61, Loss: 0.6433426737785339, Accuracy: 0.8463488817214966\n",
      "Epoch 71, Loss: 0.6307447552680969, Accuracy: 0.860378623008728\n",
      "Epoch 81, Loss: 0.6192930340766907, Accuracy: 0.8679851293563843\n",
      "Epoch 91, Loss: 0.6095812320709229, Accuracy: 0.8766058087348938\n",
      "Epoch 101, Loss: 0.6027373671531677, Accuracy: 0.883874237537384\n",
      "Epoch 111, Loss: 0.5971978902816772, Accuracy: 0.8916497826576233\n",
      "Epoch 121, Loss: 0.5898057222366333, Accuracy: 0.8992562294006348\n",
      "Epoch 131, Loss: 0.5860217809677124, Accuracy: 0.9029749631881714\n",
      "Epoch 141, Loss: 0.5787340402603149, Accuracy: 0.907031774520874\n",
      "Epoch 151, Loss: 0.5725811719894409, Accuracy: 0.9134550094604492\n",
      "Epoch 161, Loss: 0.5688451528549194, Accuracy: 0.9175118207931519\n",
      "Epoch 171, Loss: 0.564809262752533, Accuracy: 0.9207234382629395\n",
      "Epoch 181, Loss: 0.5646456480026245, Accuracy: 0.9220757484436035\n",
      "Epoch 191, Loss: 0.5699824690818787, Accuracy: 0.9173427820205688\n",
      "Predicting...\n",
      "[[1872  363  622]\n",
      " [ 373 4344  712]\n",
      " [ 543  666 4306]]\n",
      "Accuracy: 76.24%\n",
      "F1-Score: 0.7465\n",
      "embedding: DGI\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 150)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 2.272908926010132, Accuracy: 0.31575387716293335\n",
      "Epoch 11, Loss: 1.0896493196487427, Accuracy: 0.39891818165779114\n",
      "Epoch 21, Loss: 1.080041527748108, Accuracy: 0.39891818165779114\n",
      "Epoch 31, Loss: 1.0718231201171875, Accuracy: 0.39891818165779114\n",
      "Epoch 41, Loss: 1.0664912462234497, Accuracy: 0.39891818165779114\n",
      "Epoch 51, Loss: 1.063658595085144, Accuracy: 0.39891818165779114\n",
      "Epoch 61, Loss: 1.0624276399612427, Accuracy: 0.39891818165779114\n",
      "Epoch 71, Loss: 1.0620059967041016, Accuracy: 0.39891818165779114\n",
      "Epoch 81, Loss: 1.0619007349014282, Accuracy: 0.39891818165779114\n",
      "Epoch 91, Loss: 1.0618863105773926, Accuracy: 0.39891818165779114\n",
      "Epoch 101, Loss: 1.0618869066238403, Accuracy: 0.39891818165779114\n",
      "Epoch 111, Loss: 1.0618870258331299, Accuracy: 0.39891818165779114\n",
      "Epoch 121, Loss: 1.0618863105773926, Accuracy: 0.39891818165779114\n",
      "Epoch 131, Loss: 1.0618857145309448, Accuracy: 0.39891818165779114\n",
      "Epoch 141, Loss: 1.0618853569030762, Accuracy: 0.39891818165779114\n",
      "Epoch 151, Loss: 1.0618852376937866, Accuracy: 0.39891818165779114\n",
      "Epoch 161, Loss: 1.0618852376937866, Accuracy: 0.39891818165779114\n",
      "Epoch 171, Loss: 1.0618852376937866, Accuracy: 0.39891818165779114\n",
      "Epoch 181, Loss: 1.0618852376937866, Accuracy: 0.39891818165779114\n",
      "Epoch 191, Loss: 1.0618852376937866, Accuracy: 0.39891818165779114\n",
      "Predicting...\n",
      "[[   0    0 2857]\n",
      " [   0    0 5429]\n",
      " [   0    0 5515]]\n",
      "Accuracy: 39.96%\n",
      "F1-Score: 0.1903\n",
      "embedding: DGI\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 150)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 1.1064484119415283, Accuracy: 0.23411089181900024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 1.0628708600997925, Accuracy: 0.4399932324886322\n",
      "Epoch 21, Loss: 1.0334193706512451, Accuracy: 0.4682217836380005\n",
      "Epoch 31, Loss: 1.0010277032852173, Accuracy: 0.4881676733493805\n",
      "Epoch 41, Loss: 0.9745643138885498, Accuracy: 0.5143678188323975\n",
      "Epoch 51, Loss: 0.956035315990448, Accuracy: 0.5204530358314514\n",
      "Epoch 61, Loss: 0.944864809513092, Accuracy: 0.5189316868782043\n",
      "Epoch 71, Loss: 0.9334852695465088, Accuracy: 0.5273833870887756\n",
      "Epoch 81, Loss: 0.9134989380836487, Accuracy: 0.5425963401794434\n",
      "Epoch 91, Loss: 0.9107478857040405, Accuracy: 0.5518931746482849\n",
      "Epoch 101, Loss: 0.9348294734954834, Accuracy: 0.5214672088623047\n",
      "Epoch 111, Loss: 0.8863257765769958, Accuracy: 0.5706558227539062\n",
      "Epoch 121, Loss: 0.8772276639938354, Accuracy: 0.5791075229644775\n",
      "Epoch 131, Loss: 0.8700950145721436, Accuracy: 0.5823191404342651\n",
      "Epoch 141, Loss: 0.861958384513855, Accuracy: 0.5941514372825623\n",
      "Epoch 151, Loss: 0.963180661201477, Accuracy: 0.5378634333610535\n",
      "Epoch 161, Loss: 0.8642962574958801, Accuracy: 0.5983772873878479\n",
      "Epoch 171, Loss: 0.8518606424331665, Accuracy: 0.6014198660850525\n",
      "Epoch 181, Loss: 0.8463501930236816, Accuracy: 0.6010817885398865\n",
      "Epoch 191, Loss: 0.8399551510810852, Accuracy: 0.6076741218566895\n",
      "Predicting...\n",
      "[[1164  713  980]\n",
      " [ 595 3665 1169]\n",
      " [ 654  910 3951]]\n",
      "Accuracy: 63.62%\n",
      "F1-Score: 0.6020\n",
      "embedding: DGI\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 150)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 1.2222241163253784, Accuracy: 0.3715348243713379\n",
      "Epoch 11, Loss: 1.0557035207748413, Accuracy: 0.40449628233909607\n",
      "Epoch 21, Loss: 1.049033522605896, Accuracy: 0.4450642466545105\n",
      "Epoch 31, Loss: 1.0365012884140015, Accuracy: 0.46264368295669556\n",
      "Epoch 41, Loss: 1.0186623334884644, Accuracy: 0.4869844615459442\n",
      "Epoch 51, Loss: 0.9940794706344604, Accuracy: 0.5020284056663513\n",
      "Epoch 61, Loss: 0.9876458644866943, Accuracy: 0.5169033408164978\n",
      "Epoch 71, Loss: 0.9797534942626953, Accuracy: 0.5221433639526367\n",
      "Epoch 81, Loss: 0.9706390500068665, Accuracy: 0.5326234102249146\n",
      "Epoch 91, Loss: 0.9641497731208801, Accuracy: 0.5383705496788025\n",
      "Epoch 101, Loss: 0.9594357013702393, Accuracy: 0.5474982857704163\n",
      "Epoch 111, Loss: 0.9607158303260803, Accuracy: 0.5380324721336365\n",
      "Epoch 121, Loss: 0.9668082594871521, Accuracy: 0.5324543714523315\n",
      "Epoch 131, Loss: 0.9528532028198242, Accuracy: 0.545976996421814\n",
      "Epoch 141, Loss: 0.9480628967285156, Accuracy: 0.5545976758003235\n",
      "Epoch 151, Loss: 0.9354910850524902, Accuracy: 0.569810688495636\n",
      "Epoch 161, Loss: 0.9316747784614563, Accuracy: 0.5775862336158752\n",
      "Epoch 171, Loss: 0.9240292906761169, Accuracy: 0.5757268667221069\n",
      "Epoch 181, Loss: 0.9315856695175171, Accuracy: 0.5794456005096436\n",
      "Epoch 191, Loss: 0.9181742668151855, Accuracy: 0.5752197504043579\n",
      "Predicting...\n",
      "[[  10 1740 1107]\n",
      " [   9 4459  961]\n",
      " [   2 2020 3493]]\n",
      "Accuracy: 57.69%\n",
      "F1-Score: 0.4304\n",
      "embedding: MODULARITY\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 150)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 1.09989333152771, Accuracy: 0.25760647654533386\n",
      "Epoch 11, Loss: 1.0230348110198975, Accuracy: 0.5040568113327026\n",
      "Epoch 21, Loss: 0.9539432525634766, Accuracy: 0.5429344177246094\n",
      "Epoch 31, Loss: 0.8851814270019531, Accuracy: 0.5843475461006165\n",
      "Epoch 41, Loss: 0.8266941905021667, Accuracy: 0.6139283180236816\n",
      "Epoch 51, Loss: 0.7793129682540894, Accuracy: 0.633874237537384\n",
      "Epoch 61, Loss: 0.7427579760551453, Accuracy: 0.6445233225822449\n",
      "Epoch 71, Loss: 0.7156581878662109, Accuracy: 0.6519607901573181\n",
      "Epoch 81, Loss: 0.6959885358810425, Accuracy: 0.6556795239448547\n",
      "Epoch 91, Loss: 0.68168044090271, Accuracy: 0.6588911414146423\n",
      "Epoch 101, Loss: 0.6710546612739563, Accuracy: 0.662609875202179\n",
      "Epoch 111, Loss: 0.6629467606544495, Accuracy: 0.6649763584136963\n",
      "Epoch 121, Loss: 0.6565276384353638, Accuracy: 0.6656524538993835\n",
      "Epoch 131, Loss: 0.6511756777763367, Accuracy: 0.6668357253074646\n",
      "Epoch 141, Loss: 0.6464921236038208, Accuracy: 0.6678498983383179\n",
      "Epoch 151, Loss: 0.6422425508499146, Accuracy: 0.6692021489143372\n",
      "Epoch 161, Loss: 0.6383668780326843, Accuracy: 0.6702163815498352\n",
      "Epoch 171, Loss: 0.6347864866256714, Accuracy: 0.6705543994903564\n",
      "Epoch 181, Loss: 0.6314708590507507, Accuracy: 0.6719067096710205\n",
      "Epoch 191, Loss: 0.6284002065658569, Accuracy: 0.6727518439292908\n",
      "Predicting...\n",
      "[[2111  331  415]\n",
      " [ 302 4583  544]\n",
      " [ 480  671 4364]]\n",
      "Accuracy: 80.12%\n",
      "F1-Score: 0.7906\n",
      "embedding: MODULARITY\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 150)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 1.0986359119415283, Accuracy: 0.3067951202392578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 1.0310654640197754, Accuracy: 0.6151115894317627\n",
      "Epoch 21, Loss: 0.9537420272827148, Accuracy: 0.6228870749473572\n",
      "Epoch 31, Loss: 0.8258379101753235, Accuracy: 0.6925287246704102\n",
      "Epoch 41, Loss: 0.6687868237495422, Accuracy: 0.7841446995735168\n",
      "Epoch 51, Loss: 0.4916967451572418, Accuracy: 0.8973968625068665\n",
      "Epoch 61, Loss: 0.3335939943790436, Accuracy: 0.9403312802314758\n",
      "Epoch 71, Loss: 0.2280096560716629, Accuracy: 0.9479377865791321\n",
      "Epoch 81, Loss: 0.167161226272583, Accuracy: 0.953008770942688\n",
      "Epoch 91, Loss: 0.13209505379199982, Accuracy: 0.9580797553062439\n",
      "Epoch 101, Loss: 0.11054950207471848, Accuracy: 0.9643340110778809\n",
      "Epoch 111, Loss: 0.095212921500206, Accuracy: 0.9678837060928345\n",
      "Epoch 121, Loss: 0.0831550881266594, Accuracy: 0.9722785949707031\n",
      "Epoch 131, Loss: 0.07352902740240097, Accuracy: 0.9743069410324097\n",
      "Epoch 141, Loss: 0.06485848873853683, Accuracy: 0.9785327911376953\n",
      "Epoch 151, Loss: 0.05769648775458336, Accuracy: 0.9822515249252319\n",
      "Epoch 161, Loss: 0.052058178931474686, Accuracy: 0.9847870469093323\n",
      "Epoch 171, Loss: 0.047469206154346466, Accuracy: 0.9868153929710388\n",
      "Epoch 181, Loss: 0.04373135790228844, Accuracy: 0.9885057210922241\n",
      "Epoch 191, Loss: 0.04043583571910858, Accuracy: 0.9898580312728882\n",
      "Predicting...\n",
      "[[1991  332  534]\n",
      " [ 207 4746  476]\n",
      " [ 397  679 4439]]\n",
      "Accuracy: 80.98%\n",
      "F1-Score: 0.7962\n",
      "embedding: MODULARITY\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 150)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 1.2734473943710327, Accuracy: 0.30240026116371155\n",
      "Epoch 11, Loss: 0.9928308725357056, Accuracy: 0.5900946855545044\n",
      "Epoch 21, Loss: 0.7456591725349426, Accuracy: 0.7635226249694824\n",
      "Epoch 31, Loss: 0.511150062084198, Accuracy: 0.9885057210922241\n",
      "Epoch 41, Loss: 0.4876159429550171, Accuracy: 0.9932386875152588\n",
      "Epoch 51, Loss: 0.47644877433776855, Accuracy: 0.9981406331062317\n",
      "Epoch 61, Loss: 0.4722340703010559, Accuracy: 0.9989858269691467\n",
      "Epoch 71, Loss: 0.46995460987091064, Accuracy: 1.0\n",
      "Epoch 81, Loss: 0.4684211015701294, Accuracy: 1.0\n",
      "Epoch 91, Loss: 0.467368483543396, Accuracy: 1.0\n",
      "Epoch 101, Loss: 0.46659132838249207, Accuracy: 1.0\n",
      "Epoch 111, Loss: 0.4659906327724457, Accuracy: 1.0\n",
      "Epoch 121, Loss: 0.46550148725509644, Accuracy: 1.0\n",
      "Epoch 131, Loss: 0.46508967876434326, Accuracy: 1.0\n",
      "Epoch 141, Loss: 0.4647381901741028, Accuracy: 1.0\n",
      "Epoch 151, Loss: 0.46444156765937805, Accuracy: 1.0\n",
      "Epoch 161, Loss: 0.4641858637332916, Accuracy: 1.0\n",
      "Epoch 171, Loss: 0.463964581489563, Accuracy: 1.0\n",
      "Epoch 181, Loss: 0.4637719690799713, Accuracy: 1.0\n",
      "Epoch 191, Loss: 0.4635993540287018, Accuracy: 1.0\n",
      "Predicting...\n",
      "[[2132  355  370]\n",
      " [ 272 4811  346]\n",
      " [ 532  818 4165]]\n",
      "Accuracy: 80.49%\n",
      "F1-Score: 0.7935\n",
      "embedding: NODE2VEC\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 150)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 3.3096086978912354, Accuracy: 0.2532116174697876\n",
      "Epoch 11, Loss: 0.9456208348274231, Accuracy: 0.563894510269165\n",
      "Epoch 21, Loss: 0.8468656539916992, Accuracy: 0.5877282023429871\n",
      "Epoch 31, Loss: 0.7994692921638489, Accuracy: 0.6012508273124695\n",
      "Epoch 41, Loss: 0.7781257033348083, Accuracy: 0.6117308735847473\n",
      "Epoch 51, Loss: 0.7628986835479736, Accuracy: 0.6186612844467163\n",
      "Epoch 61, Loss: 0.7522428035736084, Accuracy: 0.6198444962501526\n",
      "Epoch 71, Loss: 0.7433832883834839, Accuracy: 0.6225489974021912\n",
      "Epoch 81, Loss: 0.7351649403572083, Accuracy: 0.6262677311897278\n",
      "Epoch 91, Loss: 0.7277706861495972, Accuracy: 0.6284651756286621\n",
      "Epoch 101, Loss: 0.7218232750892639, Accuracy: 0.6306626200675964\n",
      "Epoch 111, Loss: 0.7164130806922913, Accuracy: 0.63421231508255\n",
      "Epoch 121, Loss: 0.7112206220626831, Accuracy: 0.6350574493408203\n",
      "Epoch 131, Loss: 0.7060469388961792, Accuracy: 0.6377620100975037\n",
      "Epoch 141, Loss: 0.7010117769241333, Accuracy: 0.6382691264152527\n",
      "Epoch 151, Loss: 0.6958326697349548, Accuracy: 0.6389452219009399\n",
      "Epoch 161, Loss: 0.6909899115562439, Accuracy: 0.6414807438850403\n",
      "Epoch 171, Loss: 0.6866491436958313, Accuracy: 0.6418188214302063\n",
      "Epoch 181, Loss: 0.6824017763137817, Accuracy: 0.6438471674919128\n",
      "Epoch 191, Loss: 0.6784196496009827, Accuracy: 0.6458755731582642\n",
      "Predicting...\n",
      "[[2114  374  369]\n",
      " [ 327 4585  517]\n",
      " [ 665  643 4207]]\n",
      "Accuracy: 79.02%\n",
      "F1-Score: 0.7778\n",
      "embedding: NODE2VEC\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 150)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 1.1027978658676147, Accuracy: 0.3067951202392578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.5407021641731262, Accuracy: 0.8044286966323853\n",
      "Epoch 21, Loss: 0.4912573993206024, Accuracy: 0.8162609934806824\n",
      "Epoch 31, Loss: 0.4692041575908661, Accuracy: 0.8240365386009216\n",
      "Epoch 41, Loss: 0.45643848180770874, Accuracy: 0.8297836184501648\n",
      "Epoch 51, Loss: 0.44697892665863037, Accuracy: 0.8348546028137207\n",
      "Epoch 61, Loss: 0.43702900409698486, Accuracy: 0.8346856236457825\n",
      "Epoch 71, Loss: 0.4240882396697998, Accuracy: 0.8390804529190063\n",
      "Epoch 81, Loss: 0.40615615248680115, Accuracy: 0.8453347086906433\n",
      "Epoch 91, Loss: 0.38497617840766907, Accuracy: 0.8534482717514038\n",
      "Epoch 101, Loss: 0.35809338092803955, Accuracy: 0.8649425506591797\n",
      "Epoch 111, Loss: 0.33017173409461975, Accuracy: 0.8767748475074768\n",
      "Epoch 121, Loss: 0.3080112338066101, Accuracy: 0.8798174262046814\n",
      "Epoch 131, Loss: 0.27652883529663086, Accuracy: 0.8931710720062256\n",
      "Epoch 141, Loss: 0.24603036046028137, Accuracy: 0.9022988677024841\n",
      "Epoch 151, Loss: 0.2204398512840271, Accuracy: 0.9154834151268005\n",
      "Epoch 161, Loss: 0.20504122972488403, Accuracy: 0.9170047044754028\n",
      "Epoch 171, Loss: 0.17801466584205627, Accuracy: 0.9352602958679199\n",
      "Epoch 181, Loss: 0.1557217538356781, Accuracy: 0.9420216083526611\n",
      "Epoch 191, Loss: 0.13595585525035858, Accuracy: 0.9525017142295837\n",
      "Predicting...\n",
      "[[2022  271  564]\n",
      " [ 329 4353  747]\n",
      " [ 428  558 4529]]\n",
      "Accuracy: 79.01%\n",
      "F1-Score: 0.7786\n",
      "embedding: NODE2VEC\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 150)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 1.3677482604980469, Accuracy: 0.23968897759914398\n",
      "Epoch 11, Loss: 0.7026965618133545, Accuracy: 0.7934415340423584\n",
      "Epoch 21, Loss: 0.6761052012443542, Accuracy: 0.8091616034507751\n",
      "Epoch 31, Loss: 0.6649491786956787, Accuracy: 0.820148766040802\n",
      "Epoch 41, Loss: 0.6554437279701233, Accuracy: 0.8291075229644775\n",
      "Epoch 51, Loss: 0.6479498744010925, Accuracy: 0.836713969707489\n",
      "Epoch 61, Loss: 0.6408668756484985, Accuracy: 0.843644380569458\n",
      "Epoch 71, Loss: 0.6336351037025452, Accuracy: 0.8517579436302185\n",
      "Epoch 81, Loss: 0.6265988349914551, Accuracy: 0.8571670055389404\n",
      "Epoch 91, Loss: 0.6194906830787659, Accuracy: 0.8640973567962646\n",
      "Epoch 101, Loss: 0.6142723560333252, Accuracy: 0.8695064187049866\n",
      "Epoch 111, Loss: 0.6072924733161926, Accuracy: 0.8781270980834961\n",
      "Epoch 121, Loss: 0.6011195182800293, Accuracy: 0.88421231508255\n",
      "Epoch 131, Loss: 0.5967800617218018, Accuracy: 0.8886071443557739\n",
      "Epoch 141, Loss: 0.5922772884368896, Accuracy: 0.8902974724769592\n",
      "Epoch 151, Loss: 0.5863011479377747, Accuracy: 0.8940162062644958\n",
      "Epoch 161, Loss: 0.5822505950927734, Accuracy: 0.8984110951423645\n",
      "Epoch 171, Loss: 0.5772897601127625, Accuracy: 0.9034820795059204\n",
      "Epoch 181, Loss: 0.5748243927955627, Accuracy: 0.907200813293457\n",
      "Epoch 191, Loss: 0.5700153112411499, Accuracy: 0.9097363352775574\n",
      "Predicting...\n",
      "[[2051  295  511]\n",
      " [ 325 4576  528]\n",
      " [ 473  566 4476]]\n",
      "Accuracy: 80.45%\n",
      "F1-Score: 0.7909\n",
      "embedding: RANDOM\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 150)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 2.8201863765716553, Accuracy: 0.27755239605903625\n",
      "Epoch 11, Loss: 1.03786039352417, Accuracy: 0.5251859426498413\n",
      "Epoch 21, Loss: 0.8634397387504578, Accuracy: 0.563725471496582\n",
      "Epoch 31, Loss: 0.7954081892967224, Accuracy: 0.593644380569458\n",
      "Epoch 41, Loss: 0.760399580001831, Accuracy: 0.6120689511299133\n",
      "Epoch 51, Loss: 0.7356558442115784, Accuracy: 0.6200135350227356\n",
      "Epoch 61, Loss: 0.7144034504890442, Accuracy: 0.6330291032791138\n",
      "Epoch 71, Loss: 0.6956484913825989, Accuracy: 0.6413117051124573\n",
      "Epoch 81, Loss: 0.6793164014816284, Accuracy: 0.6453685164451599\n",
      "Epoch 91, Loss: 0.6651846170425415, Accuracy: 0.6539891958236694\n",
      "Epoch 101, Loss: 0.6528624892234802, Accuracy: 0.6600743532180786\n",
      "Epoch 111, Loss: 0.641997218132019, Accuracy: 0.662778913974762\n",
      "Epoch 121, Loss: 0.6325778961181641, Accuracy: 0.6661595702171326\n",
      "Epoch 131, Loss: 0.6241768598556519, Accuracy: 0.6705543994903564\n",
      "Epoch 141, Loss: 0.6166636347770691, Accuracy: 0.6729208827018738\n",
      "Epoch 151, Loss: 0.6101147532463074, Accuracy: 0.6752873659133911\n",
      "Epoch 161, Loss: 0.604379415512085, Accuracy: 0.6766396164894104\n",
      "Epoch 171, Loss: 0.5993347764015198, Accuracy: 0.6784989833831787\n",
      "Epoch 181, Loss: 0.5948775410652161, Accuracy: 0.680189311504364\n",
      "Epoch 191, Loss: 0.5908979177474976, Accuracy: 0.6815415620803833\n",
      "Predicting...\n",
      "[[ 714  997 1146]\n",
      " [ 809 2608 2012]\n",
      " [ 834 2123 2558]]\n",
      "Accuracy: 42.61%\n",
      "F1-Score: 0.3990\n",
      "embedding: RANDOM\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 150)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 1.106123447418213, Accuracy: 0.32944557070732117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.9449153542518616, Accuracy: 0.5534144639968872\n",
      "Epoch 21, Loss: 0.6423506736755371, Accuracy: 0.7466193437576294\n",
      "Epoch 31, Loss: 0.3132026791572571, Accuracy: 0.9083840250968933\n",
      "Epoch 41, Loss: 0.10672739893198013, Accuracy: 0.9743069410324097\n",
      "Epoch 51, Loss: 0.04531536251306534, Accuracy: 0.9879986643791199\n",
      "Epoch 61, Loss: 0.026792582124471664, Accuracy: 0.9910412430763245\n",
      "Epoch 71, Loss: 0.01942538283765316, Accuracy: 0.9923934936523438\n",
      "Epoch 81, Loss: 0.015606238506734371, Accuracy: 0.9937458038330078\n",
      "Epoch 91, Loss: 0.012461155652999878, Accuracy: 0.9945909380912781\n",
      "Epoch 101, Loss: 0.010539916343986988, Accuracy: 0.9954361319541931\n",
      "Epoch 111, Loss: 0.00927830208092928, Accuracy: 0.9957741498947144\n",
      "Epoch 121, Loss: 0.008350533433258533, Accuracy: 0.9961122274398804\n",
      "Epoch 131, Loss: 0.007651806343346834, Accuracy: 0.9962812662124634\n",
      "Epoch 141, Loss: 0.00716338912025094, Accuracy: 0.9964503049850464\n",
      "Epoch 151, Loss: 0.007279972080141306, Accuracy: 0.9961122274398804\n",
      "Epoch 161, Loss: 0.006305496208369732, Accuracy: 0.9967883825302124\n",
      "Epoch 171, Loss: 0.005959662143141031, Accuracy: 0.9967883825302124\n",
      "Epoch 181, Loss: 0.005743660498410463, Accuracy: 0.9967883825302124\n",
      "Epoch 191, Loss: 0.005624707788228989, Accuracy: 0.9966193437576294\n",
      "Predicting...\n",
      "[[ 614  956 1287]\n",
      " [ 573 2824 2032]\n",
      " [ 607 1728 3180]]\n",
      "Accuracy: 47.95%\n",
      "F1-Score: 0.4366\n",
      "embedding: RANDOM\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 150)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 1.2571579217910767, Accuracy: 0.29885056614875793\n",
      "Epoch 11, Loss: 0.9662889242172241, Accuracy: 0.5490196347236633\n",
      "Epoch 21, Loss: 0.8957071900367737, Accuracy: 0.6298174262046814\n",
      "Epoch 31, Loss: 0.8332133889198303, Accuracy: 0.6891480684280396\n",
      "Epoch 41, Loss: 0.7752535343170166, Accuracy: 0.7429006099700928\n",
      "Epoch 51, Loss: 0.7275078892707825, Accuracy: 0.7844827771186829\n",
      "Epoch 61, Loss: 0.6944791078567505, Accuracy: 0.8133874535560608\n",
      "Epoch 71, Loss: 0.671031653881073, Accuracy: 0.836883008480072\n",
      "Epoch 81, Loss: 0.6568613648414612, Accuracy: 0.8509127497673035\n",
      "Epoch 91, Loss: 0.6469473838806152, Accuracy: 0.8597025275230408\n",
      "Epoch 101, Loss: 0.6390408873558044, Accuracy: 0.86578768491745\n",
      "Epoch 111, Loss: 0.6369030475616455, Accuracy: 0.8718729019165039\n",
      "Epoch 121, Loss: 0.6333315968513489, Accuracy: 0.8723799586296082\n",
      "Epoch 131, Loss: 0.6271465420722961, Accuracy: 0.8793103694915771\n",
      "Epoch 141, Loss: 0.6162132620811462, Accuracy: 0.8886071443557739\n",
      "Epoch 151, Loss: 0.6111736297607422, Accuracy: 0.8913117051124573\n",
      "Epoch 161, Loss: 0.613656222820282, Accuracy: 0.8913117051124573\n",
      "Epoch 171, Loss: 0.6094110012054443, Accuracy: 0.8943542838096619\n",
      "Epoch 181, Loss: 0.6000824570655823, Accuracy: 0.9038201570510864\n",
      "Epoch 191, Loss: 0.5984811186790466, Accuracy: 0.9041582345962524\n",
      "Predicting...\n",
      "[[ 470 1097 1290]\n",
      " [ 607 2652 2170]\n",
      " [ 685 2036 2794]]\n",
      "Accuracy: 42.87%\n",
      "F1-Score: 0.3838\n",
      "embedding: GIVEN\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 500)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 1.1318813562393188, Accuracy: 0.25\n",
      "Epoch 11, Loss: 0.829212486743927, Accuracy: 0.610716700553894\n",
      "Epoch 21, Loss: 0.765073835849762, Accuracy: 0.6223799586296082\n",
      "Epoch 31, Loss: 0.7360114455223083, Accuracy: 0.6347194314002991\n",
      "Epoch 41, Loss: 0.7164320945739746, Accuracy: 0.640128493309021\n",
      "Epoch 51, Loss: 0.7004409432411194, Accuracy: 0.6482420563697815\n",
      "Epoch 61, Loss: 0.6874818801879883, Accuracy: 0.6504395008087158\n",
      "Epoch 71, Loss: 0.6762696504592896, Accuracy: 0.6522988677024841\n",
      "Epoch 81, Loss: 0.6664777994155884, Accuracy: 0.6551724076271057\n",
      "Epoch 91, Loss: 0.6577361226081848, Accuracy: 0.657538890838623\n",
      "Epoch 101, Loss: 0.649815022945404, Accuracy: 0.6592292189598083\n",
      "Epoch 111, Loss: 0.6425363421440125, Accuracy: 0.6614266633987427\n",
      "Epoch 121, Loss: 0.6357642412185669, Accuracy: 0.6639621257781982\n",
      "Epoch 131, Loss: 0.6294438242912292, Accuracy: 0.6649763584136963\n",
      "Epoch 141, Loss: 0.6236194372177124, Accuracy: 0.6675118207931519\n",
      "Epoch 151, Loss: 0.6187632083892822, Accuracy: 0.6698783040046692\n",
      "Epoch 161, Loss: 0.6136826872825623, Accuracy: 0.6722447872161865\n",
      "Epoch 171, Loss: 0.6095530390739441, Accuracy: 0.6739351153373718\n",
      "Epoch 181, Loss: 0.6055179238319397, Accuracy: 0.6754564046859741\n",
      "Epoch 191, Loss: 0.6021526455879211, Accuracy: 0.6763015389442444\n",
      "Predicting...\n",
      "[[2151  231  475]\n",
      " [ 274 4527  628]\n",
      " [ 387  573 4555]]\n",
      "Accuracy: 81.39%\n",
      "F1-Score: 0.8052\n",
      "embedding: GIVEN\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 500)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 1.0986099243164062, Accuracy: 0.31220418214797974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.6330666542053223, Accuracy: 0.7883705496788025\n",
      "Epoch 21, Loss: 0.42645367980003357, Accuracy: 0.8291075229644775\n",
      "Epoch 31, Loss: 0.36713677644729614, Accuracy: 0.8585192561149597\n",
      "Epoch 41, Loss: 0.3270653784275055, Accuracy: 0.8759296536445618\n",
      "Epoch 51, Loss: 0.3024786114692688, Accuracy: 0.8853955268859863\n",
      "Epoch 61, Loss: 0.28416725993156433, Accuracy: 0.8935091495513916\n",
      "Epoch 71, Loss: 0.2687815725803375, Accuracy: 0.8989182114601135\n",
      "Epoch 81, Loss: 0.2552790939807892, Accuracy: 0.907031774520874\n",
      "Epoch 91, Loss: 0.24247705936431885, Accuracy: 0.9099053144454956\n",
      "Epoch 101, Loss: 0.2292059361934662, Accuracy: 0.9161595702171326\n",
      "Epoch 111, Loss: 0.215067520737648, Accuracy: 0.9224137663841248\n",
      "Epoch 121, Loss: 0.1998629868030548, Accuracy: 0.931034505367279\n",
      "Epoch 131, Loss: 0.18419408798217773, Accuracy: 0.9374577403068542\n",
      "Epoch 141, Loss: 0.16842998564243317, Accuracy: 0.9425287246704102\n",
      "Epoch 151, Loss: 0.1528058499097824, Accuracy: 0.9492900371551514\n",
      "Epoch 161, Loss: 0.13734374940395355, Accuracy: 0.953346848487854\n",
      "Epoch 171, Loss: 0.12268099188804626, Accuracy: 0.959263026714325\n",
      "Epoch 181, Loss: 0.10919290781021118, Accuracy: 0.9621365666389465\n",
      "Epoch 191, Loss: 0.09663190692663193, Accuracy: 0.9677146673202515\n",
      "Predicting...\n",
      "[[2297  238  322]\n",
      " [ 209 4787  433]\n",
      " [ 386  603 4526]]\n",
      "Accuracy: 84.12%\n",
      "F1-Score: 0.8345\n",
      "embedding: GIVEN\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (5916, 500)\n",
      "Shape of A_train_tensor: (5916, 5916)\n",
      "Shape of Y_train: (5916, 3)\n",
      "Epoch 1, Loss: 1.2952113151550293, Accuracy: 0.2900608479976654\n",
      "Epoch 11, Loss: 0.6648676991462708, Accuracy: 0.8324881792068481\n",
      "Epoch 21, Loss: 0.6156269311904907, Accuracy: 0.8651115894317627\n",
      "Epoch 31, Loss: 0.5906160473823547, Accuracy: 0.8882691264152527\n",
      "Epoch 41, Loss: 0.5722451210021973, Accuracy: 0.9048343300819397\n",
      "Epoch 51, Loss: 0.5573529005050659, Accuracy: 0.9205543994903564\n",
      "Epoch 61, Loss: 0.543018102645874, Accuracy: 0.9337390065193176\n",
      "Epoch 71, Loss: 0.5301272869110107, Accuracy: 0.9454023241996765\n",
      "Epoch 81, Loss: 0.5183481574058533, Accuracy: 0.9553752541542053\n",
      "Epoch 91, Loss: 0.507526695728302, Accuracy: 0.9670385122299194\n",
      "Epoch 101, Loss: 0.49799439311027527, Accuracy: 0.976335346698761\n",
      "Epoch 111, Loss: 0.4911949336528778, Accuracy: 0.9802231192588806\n",
      "Epoch 121, Loss: 0.48601406812667847, Accuracy: 0.9836037755012512\n",
      "Epoch 131, Loss: 0.48241567611694336, Accuracy: 0.9863083362579346\n",
      "Epoch 141, Loss: 0.479708731174469, Accuracy: 0.9879986643791199\n",
      "Epoch 151, Loss: 0.47918254137039185, Accuracy: 0.9893509149551392\n",
      "Epoch 161, Loss: 0.48629990220069885, Accuracy: 0.9836037755012512\n",
      "Epoch 171, Loss: 0.47900059819221497, Accuracy: 0.9898580312728882\n",
      "Epoch 181, Loss: 0.47652387619018555, Accuracy: 0.9910412430763245\n",
      "Epoch 191, Loss: 0.4743005633354187, Accuracy: 0.9922244548797607\n",
      "Predicting...\n",
      "[[2392  160  305]\n",
      " [ 160 4778  491]\n",
      " [ 297  571 4647]]\n",
      "Accuracy: 85.62%\n",
      "F1-Score: 0.8534\n"
     ]
    }
   ],
   "source": [
    "all_results=[]\n",
    "graph_embeddings_dict={}\n",
    "for emb in embedding_dict.keys():\n",
    "    for clf in classifiers:\n",
    "        results, embedding_matrix = train_and_evaluate(embedding_dict, emb, clf)\n",
    "        all_results.append(results)\n",
    "        key_string= emb + ' with ' + clf\n",
    "        graph_embeddings_dict[key_string]=embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febc0edf-dcf6-4085-9bcb-99e00878ca90",
   "metadata": {},
   "source": [
    "## Saving aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92a88879-f5b1-42d4-b705-a09d92320009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved as ./pubmed_analysis_results/pubmed_seed46_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "# Define dataset name and seed\n",
    "dataset_name = \"pubmed\"\n",
    "seed_value = SEED\n",
    "\n",
    "# Save as CSV file without sorting\n",
    "filename = f\"{dataset_name}_seed{seed_value}_results.csv\"\n",
    "filename='./pubmed_analysis_results/'+filename\n",
    "df.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Results saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f240fc2-1363-4419-86a7-a65c94f3a6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings= embedding_dict | graph_embeddings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09ca62ce-310f-45e0-8fc9-b375476258ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_dict(original_dict, key_order):\n",
    "    \"\"\"\n",
    "    Reorders a dictionary based on a given list of keys.\n",
    "\n",
    "    Parameters:\n",
    "    - original_dict (dict): The dictionary to reorder.\n",
    "    - key_order (list): The list specifying the desired key order.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A new dictionary with keys ordered as per key_order.\n",
    "    \"\"\"\n",
    "    return {key: original_dict[key] for key in key_order if key in original_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9a9c6f1-030a-42c1-9782-d9a3ca64dd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_order = ['random', 'random with gcn', 'random with gat', 'random with graphsage', 'deepwalk', 'deepwalk with gcn', 'deepwalk with gat', 'deepwalk with graphsage', 'node2vec','node2vec with gcn', 'node2vec with gat', 'node2vec with graphsage', 'vgae', 'vgae with gcn', 'vgae with gat', 'vgae with graphsage', 'dgi', 'dgi with gcn', 'dgi with gat', 'dgi with graphsage', 'modularity', 'modularity with gcn', 'modularity with gat', 'modularity with graphsage', 'given', 'given with gcn', 'given with gat', 'given with graphsage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ced34dc-10c4-4771-bfcd-253a8c664614",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = reorder_dict(all_embeddings, key_order)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e538e5aa-7b45-45b1-bd82-8d797011655c",
   "metadata": {},
   "source": [
    "visualize_all_embeddings(all_embeddings, labels, label_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
