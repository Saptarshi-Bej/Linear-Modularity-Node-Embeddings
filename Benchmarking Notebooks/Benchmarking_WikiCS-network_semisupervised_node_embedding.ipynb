{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c1ef1f-2372-44c0-9703-b8ac660cce10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2258f4d-c9fd-4f88-9c7f-3e5f04853725",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time \n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import umap.umap_ as umap\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
    "from node2vec import Node2Vec\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import spektral\n",
    "from spektral.layers import GCNConv, GATConv\n",
    "from spektral.layers import GraphSageConv\n",
    "from spektral.data import Graph, Dataset, BatchLoader\n",
    "from scipy.sparse import csr_matrix, lil_matrix\n",
    "from torch_geometric.datasets import WikiCS\n",
    "from torch_geometric.nn import DeepGraphInfomax, VGAE\n",
    "from torch_geometric.utils import from_networkx\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "from scipy.sparse.csgraph import laplacian\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import normalize\n",
    "from joblib import Parallel, delayed\n",
    "from torch_geometric.nn import GCNConv as PyG_GCNConv, VGAE as PyG_VGAE\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9044d178-5de4-4fab-8b82-ca674598128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 46\n",
    "\n",
    "# Set seed for Python's built-in random module\n",
    "random.seed(SEED)\n",
    "\n",
    "# Set seed for NumPy\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Set seed for TensorFlow\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# Set seed for PyTorch\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b95802d-543f-4b3e-803a-cdbdb518595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom Dataset\n",
    "class WikiCSDataset(Dataset):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        dataset = WikiCS(root=\"./WikiCS\")  # Load WikiCS dataset\n",
    "        data = dataset[0]  # Access the first graph\n",
    "\n",
    "        # Convert to NumPy\n",
    "        x = data.x.numpy()\n",
    "        edge_index = data.edge_index.numpy()\n",
    "        y = data.y.numpy()\n",
    "\n",
    "        # One-hot encode labels\n",
    "        num_classes = y.max() + 1\n",
    "        y_one_hot = np.eye(num_classes)[y]\n",
    "\n",
    "        # Convert edge_index to sparse adjacency matrix\n",
    "        num_nodes = x.shape[0]\n",
    "        adj = lil_matrix((num_nodes, num_nodes), dtype=np.float32)\n",
    "        for i in range(edge_index.shape[1]):\n",
    "            src, dst = edge_index[:, i]\n",
    "            adj[src, dst] = 1\n",
    "            adj[dst, src] = 1  # Ensure undirected graph\n",
    "\n",
    "        return [Graph(x=x, a=adj, y=y_one_hot)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90c18215-d57c-47a9-957d-5f98fa330e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimensionality=150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b67b75-8102-41b3-b7d9-faac9a95ca1d",
   "metadata": {},
   "source": [
    "## Extracting modularity embedding and using it for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd20588d-2ca8-457e-ab49-a8f42f9cef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplacian Eigenmaps Embedding\n",
    "def deepwalk_embedding(G, k=2, walk_length=10, num_walks=80, workers=4):\n",
    "    node2vec = Node2Vec(G, dimensions=k, walk_length=walk_length, num_walks=num_walks, workers=workers)\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "    return np.array([model.wv[str(node)] for node in G.nodes()])\n",
    "\n",
    "# Node2Vec Embedding\n",
    "def node2vec_embedding(G, k=2, seed=SEED):\n",
    "    node2vec = Node2Vec(G, dimensions=k, walk_length=10, num_walks=100, workers=2, seed=seed)\n",
    "    model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "    return np.array([model.wv[str(node)] for node in G.nodes()])\n",
    "\n",
    "\n",
    "# VGAE Embedding \n",
    "class VGAEEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = PyG_GCNConv(in_channels, 2 * out_channels)  # Use PyG_GCNConv\n",
    "        self.conv_mu = PyG_GCNConv(2 * out_channels, out_channels)  # Separate layer for mu\n",
    "        self.conv_logstd = PyG_GCNConv(2 * out_channels, out_channels)  # Separate layer for logstd\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = torch.relu(self.conv1(x, edge_index))\n",
    "        mu = self.conv_mu(x, edge_index)\n",
    "        logstd = self.conv_logstd(x, edge_index)\n",
    "        return mu, logstd\n",
    "\n",
    "def vgae_embedding(data, k=128):\n",
    "    # Use one-hot encoded node IDs as features\n",
    "    num_nodes = data.num_nodes\n",
    "    x = torch.eye(num_nodes)  # One-hot encoded node features\n",
    "\n",
    "    in_channels = x.shape[1]  # Feature dimension is equal to the number of nodes\n",
    "    model = PyG_VGAE(VGAEEncoder(in_channels, k))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    for _ in tqdm(range(200)):\n",
    "        optimizer.zero_grad()\n",
    "        z = model.encode(x, data.edge_index)  # Use one-hot encoded features\n",
    "        loss = model.recon_loss(z, data.edge_index) + (1 / data.num_nodes) * model.kl_loss()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return model.encode(x, data.edge_index).detach().numpy()\n",
    "\n",
    "# DGI Embedding\n",
    "def dgi_embedding(data, k=128):\n",
    "    class GCNEncoder(torch.nn.Module):\n",
    "        def __init__(self, in_channels, out_channels):\n",
    "            super().__init__()\n",
    "            self.conv1 = PyG_GCNConv(in_channels, 2 * out_channels)  # Use PyG_GCNConv\n",
    "            self.conv2 = PyG_GCNConv(2 * out_channels, out_channels)  # Use PyG_GCNConv\n",
    "\n",
    "        def forward(self, x, edge_index):\n",
    "            x = torch.relu(self.conv1(x, edge_index))\n",
    "            return self.conv2(x, edge_index)\n",
    "\n",
    "    # Use one-hot encoded node IDs as features\n",
    "    num_nodes = data.num_nodes\n",
    "    x = torch.eye(num_nodes)  # One-hot encoded node features\n",
    "\n",
    "    in_channels = x.shape[1]  # Feature dimension is equal to the number of nodes\n",
    "    model = DeepGraphInfomax(\n",
    "        hidden_channels=k,\n",
    "        encoder=GCNEncoder(in_channels, k),\n",
    "        summary=lambda z, *args, **kwargs: z.mean(dim=0),  # Ensure `summary` only takes `z`\n",
    "        corruption=lambda x, edge_index: (x[torch.randperm(x.size(0))], edge_index)  # Correct corruption function\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    for _ in tqdm(range(200)):\n",
    "        optimizer.zero_grad()\n",
    "        pos_z, neg_z, summary = model(x, data.edge_index)  # Use one-hot encoded features\n",
    "        loss = model.loss(pos_z, neg_z, summary)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return pos_z.detach().numpy()\n",
    "\n",
    "\n",
    "# Unsupervised gradient ascent for modularity maximization\n",
    "def gradient_ascent_modularity_unsupervised(G, k=2, eta=0.01, iterations=1000, seed=SEED):\n",
    "    np.random.seed(seed)  # Ensure deterministic initialization\n",
    "\n",
    "    A = nx.to_numpy_array(G)\n",
    "    l = A.sum(axis=1)\n",
    "    m = np.sum(l) / 2\n",
    "    B = A - np.outer(l, l) / (2 * m)\n",
    "    n = B.shape[0]\n",
    "\n",
    "    S = np.random.randn(n, k)  # Random Initialization\n",
    "    S, _ = np.linalg.qr(S)  # Ensure initial orthonormality\n",
    "\n",
    "    for i in tqdm(range(iterations), desc=\"Gradient Ascent Progress\"):\n",
    "        grad = (1 / (2 * m)) * B @ S\n",
    "        S += eta * grad\n",
    "        S, _ = np.linalg.qr(S)  # Orthonormalize using QR decomposition\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c468b5ec-43c2-4852-949b-521beda25e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_labeled_random_walks(G, label_mask, labels, num_walks, walk_length, walk_length_labelled=3):\n",
    "    walks = {node: [] for node in G.nodes()}\n",
    "    for node in G.nodes():\n",
    "        for _ in range(num_walks):\n",
    "            walk = [node]\n",
    "            labeled_count = 0\n",
    "            for _ in range(walk_length - 1):\n",
    "                cur = walk[-1]\n",
    "                neighbors = list(G.neighbors(cur))\n",
    "                if not neighbors:\n",
    "                    break\n",
    "                labeled_neighbors = [n for n in neighbors if label_mask[n]]\n",
    "                if labeled_neighbors and labeled_count < walk_length_labelled:\n",
    "                    next_node = random.choice(labeled_neighbors)\n",
    "                    labeled_count += 1\n",
    "                else:\n",
    "                    next_node = random.choice(neighbors)\n",
    "                walk.append(next_node)\n",
    "            walks[node].extend([n for n in walk if label_mask[n]])\n",
    "    return walks\n",
    "\n",
    "def compute_attention_weights(S, labeled_nodes):\n",
    "    weights = {}\n",
    "    for node, labeled in labeled_nodes.items():\n",
    "        if labeled:\n",
    "            similarities = {n: np.dot(S[node], S[n]) for n in labeled}\n",
    "            exp_sims = {n: np.exp(sim) for n, sim in similarities.items()}\n",
    "            total = sum(exp_sims.values())\n",
    "            weights[node] = {n: exp_sims[n] / total for n in labeled}\n",
    "    return weights\n",
    "\n",
    "def semi_supervised_gradient_ascent_modularity(G, labels, label_mask, k=2, eta=0.01, lambda_supervised=1.0, \n",
    "                                                      lambda_semi=2.0, iterations=5000, initialization='random',\n",
    "                                                      num_walks=10, walk_length=5, walk_length_labelled=3):\n",
    "    # Convert graph to sparse adjacency matrix\n",
    "    A = csr_matrix(nx.to_scipy_sparse_array(G, format='csr'))\n",
    "    degrees = np.array(A.sum(axis=1)).flatten()\n",
    "    m = G.number_of_edges()\n",
    "    n = A.shape[0]\n",
    "\n",
    "    # Initialize embeddings\n",
    "    if initialization == 'random':\n",
    "        S = np.random.randn(n, k)\n",
    "    S, _ = np.linalg.qr(S)\n",
    "\n",
    "    # Compute labeled random walks and attention weights\n",
    "    labeled_walks = perform_labeled_random_walks(G, label_mask, labels, num_walks, walk_length, walk_length_labelled)\n",
    "    attention_weights = compute_attention_weights(S, labeled_walks)\n",
    "\n",
    "    for _ in tqdm(range(iterations), desc=\"Gradient Ascent with Linear Modularity\"):\n",
    "        # Compute modularity gradient using linear approximation\n",
    "        neighbor_agg = A @ S  # Efficient aggregation of neighbor embeddings\n",
    "        global_correction = (degrees[:, None] / (2 * m)) * S.sum(axis=0)\n",
    "        grad_modularity = (1 / (2 * m)) * (neighbor_agg - global_correction)\n",
    "\n",
    "        # Compute supervised gradient\n",
    "        grad_supervised = np.zeros_like(S)\n",
    "        unique_labels = np.unique(labels[label_mask])\n",
    "        for label in unique_labels:\n",
    "            mask = (labels == label) & label_mask\n",
    "            mean_embedding = np.mean(S[mask], axis=0, keepdims=True)\n",
    "            grad_supervised[mask] = S[mask] - mean_embedding\n",
    "\n",
    "        # Compute semi-supervised gradient using adaptive attention\n",
    "        grad_semi_supervised = np.zeros_like(S)\n",
    "        for i in range(n):\n",
    "            if not label_mask[i] and i in attention_weights:\n",
    "                weighted_embedding = sum(weight * S[n] for n, weight in attention_weights[i].items())\n",
    "                grad_semi_supervised[i] = S[i] - weighted_embedding\n",
    "\n",
    "        # Update embeddings\n",
    "        grad_total = grad_modularity - lambda_supervised * grad_supervised - lambda_semi * grad_semi_supervised\n",
    "        S += eta * grad_total\n",
    "        S, _ = np.linalg.qr(S)\n",
    "\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d1fa1ef-526c-4ecb-a4e5-6c344f0412c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_networkx(A):\n",
    "    return nx.from_scipy_sparse_array(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7fbba5b-3f7c-4821-9af5-d9d6e982b9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\torch_geometric\\datasets\\wikics.py:45: UserWarning: The WikiCS dataset now returns an undirected graph by default. Please explicitly specify 'is_undirected=False' to restore the old behavior.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = WikiCSDataset()\n",
    "ground_truth_labels = dataset[0].y\n",
    "labels=np.argmax(ground_truth_labels,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c92de7a7-bab8-4ee8-9601-e4f95f0386e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_be_masked=np.random.choice(np.arange(len(labels)),int(len(labels)*.7),replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0cf50e3-56e5-4187-b4ef-9f05cd3bc76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_labels=[]\n",
    "for i in np.arange(len(labels)):\n",
    "    if i in labels_to_be_masked:\n",
    "        masked_labels.append(-1)\n",
    "    else:\n",
    "        masked_labels.append(labels[i])\n",
    "masked_labels=np.array(masked_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77562c2a-8c15-4b37-a4d3-674776a0edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask = masked_labels != -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "517544ea-62e6-495c-bce9-6733a551c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[0].x\n",
    "A = dataset[0].a\n",
    "G = convert_to_networkx(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42c8983a-9d5d-4f7a-9a1b-891e79fee2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency Matrix Shape: (11701, 11701)\n",
      "Graph Nodes: 11701\n",
      "Graph Edges: 216123\n"
     ]
    }
   ],
   "source": [
    "print(\"Adjacency Matrix Shape:\", A.shape)\n",
    "print(\"Graph Nodes:\", G.number_of_nodes())\n",
    "print(\"Graph Edges:\", G.number_of_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdc2c11a-b491-4f86-9669-ab36d986c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert your preprocessed data into a PyTorch Geometric Data object\n",
    "X_py = Data(\n",
    "    x=torch.tensor(X, dtype=torch.float),  # Node features\n",
    "    edge_index=torch.tensor(np.array(A.nonzero()), dtype=torch.long),  # Edge indices\n",
    "    y=torch.tensor(labels, dtype=torch.long)  # Labels\n",
    ")\n",
    "\n",
    "# Ensure edge_index is in the correct shape (2, num_edges)\n",
    "X_py.edge_index = X_py.edge_index.to(torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf301f7-3888-4a0b-aef4-0b179a862008",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c1a53cd-3d03-47cb-8078-78b593fb48e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing DeepWalk embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 11701/11701 [08:54<00:00, 21.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepWalk embedding computed in 1400.99 seconds.\n",
      "Computing VGAE embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [10:54<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGAE embedding computed in 655.49 seconds.\n",
      "Computing DGI embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [04:29<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DGI embedding computed in 269.58 seconds.\n",
      "Computing Modularity embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gradient Ascent with Linear Modularity: 100%|██████████| 200/200 [01:17<00:00,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modularity embedding computed in 83.03 seconds.\n",
      "Computing Node2Vec embedding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 11701/11701 [03:48<00:00, 51.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node2Vec embedding computed in 561.71 seconds.\n",
      "Generating Random embedding...\n",
      "Random embedding generated in 0.02 seconds.\n",
      "All embeddings computed and stored in the dictionary successfully.\n",
      "\n",
      "Execution times saved to 'embedding_execution_times.csv'.\n",
      "        Model  Time (seconds)\n",
      "0    DeepWalk     1400.991565\n",
      "1        VGAE      655.488353\n",
      "2         DGI      269.578326\n",
      "3  Modularity       83.026353\n",
      "4    Node2Vec      561.712193\n",
      "5      Random        0.021474\n"
     ]
    }
   ],
   "source": [
    "# Dictionary for embeddings\n",
    "embedding_dict = {}\n",
    "execution_times = []  # List to store execution times\n",
    "\n",
    "# Compute embeddings and store them with time tracking\n",
    "def record_time(model_name, func, *args, **kwargs):\n",
    "    print(f\"Computing {model_name} embedding...\")\n",
    "    start_time = time.time()\n",
    "    result = func(*args, **kwargs)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    execution_times.append((model_name, elapsed_time))\n",
    "    print(f\"{model_name} embedding computed in {elapsed_time:.2f} seconds.\")\n",
    "    return result\n",
    "\n",
    "X_deepwalk = record_time(\"DeepWalk\", deepwalk_embedding, G, k=embedding_dimensionality)\n",
    "X_deepwalk = tf.convert_to_tensor(X_deepwalk, dtype=tf.float32)\n",
    "embedding_dict['deepwalk'] = X_deepwalk\n",
    "\n",
    "X_vgae = record_time(\"VGAE\", vgae_embedding, X_py, k=embedding_dimensionality)\n",
    "embedding_dict['vgae'] = X_vgae\n",
    "\n",
    "X_dgi = record_time(\"DGI\", dgi_embedding, X_py, k=embedding_dimensionality)\n",
    "embedding_dict['dgi'] = X_dgi\n",
    "\n",
    "X_modularity = record_time(\"Modularity\", semi_supervised_gradient_ascent_modularity,\n",
    "                           G, labels, label_mask, k=embedding_dimensionality,\n",
    "                           eta=0.05, lambda_supervised=1.0, lambda_semi=2.0, iterations=200, initialization='random')\n",
    "embedding_dict['modularity'] = X_modularity\n",
    "\n",
    "X_node2vec = record_time(\"Node2Vec\", node2vec_embedding, G, k=embedding_dimensionality)\n",
    "X_node2vec = tf.convert_to_tensor(X_node2vec, dtype=tf.float32)\n",
    "embedding_dict['node2vec'] = X_node2vec\n",
    "\n",
    "# Generate random embedding\n",
    "print(\"Generating Random embedding...\")\n",
    "start_time = time.time()\n",
    "shape = (len(ground_truth_labels), embedding_dimensionality)\n",
    "X_random = np.random.randn(*shape)\n",
    "X_random = tf.convert_to_tensor(X_random, dtype=tf.float32)\n",
    "end_time = time.time()\n",
    "execution_times.append((\"Random\", end_time - start_time))\n",
    "print(f\"Random embedding generated in {end_time - start_time:.2f} seconds.\")\n",
    "embedding_dict['random'] = X_random\n",
    "\n",
    "# Use original node features as 'given' embedding\n",
    "embedding_dict['given'] = X\n",
    "\n",
    "print(\"All embeddings computed and stored in the dictionary successfully.\")\n",
    "\n",
    "# Store execution times in a DataFrame and save\n",
    "execution_df = pd.DataFrame(execution_times, columns=[\"Model\", \"Time (seconds)\"])\n",
    "execution_df.to_csv(\"./wikics_analysis_results/embedding_execution_times_wikics_\"+str(SEED)+\".csv\", index=False)\n",
    "\n",
    "print(\"\\nExecution times saved to 'embedding_execution_times.csv'.\")\n",
    "print(execution_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f17802-6fa6-4d5c-ada5-0bb6ef4d1f1f",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed68e9f9-a284-4469-ab59-c1e4234dc264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_all_embeddings(all_embeddings, labels, label_mask):\n",
    "    \"\"\"\n",
    "    Visualize all embeddings in a grid with 4 columns per row using UMAP.\n",
    "\n",
    "    Parameters:\n",
    "    - all_embeddings: Dictionary where keys are embedding methods, and values are embeddings.\n",
    "    - labels: Labels (numpy array of shape [n_nodes]).\n",
    "    - label_mask: Boolean array indicating known labels (True for known, False for unknown).\n",
    "    \"\"\"\n",
    "    num_embeddings = len(all_embeddings)\n",
    "    num_rows = (num_embeddings + 3) // 4  # Ensure enough rows for all embeddings\n",
    "    fig, axes = plt.subplots(num_rows, 4, figsize=(8.27, 11.69))  # A4 size\n",
    "\n",
    "    for i, (embedding_type, embedding) in tqdm(enumerate(all_embeddings.items()), \n",
    "                                               total=num_embeddings, desc=\"Visualizing embeddings\"):\n",
    "        row, col = divmod(i, 4)\n",
    "        ax = axes[row, col] if num_rows > 1 else axes[col]  # Adjust for single-row case\n",
    "\n",
    "        # Ensure embedding is a NumPy array\n",
    "        if isinstance(embedding, tf.Tensor):\n",
    "            embedding = embedding.numpy()\n",
    "\n",
    "        # Reduce dimensionality using UMAP\n",
    "        reducer = umap.UMAP(n_components=2)\n",
    "        embedding_2d = reducer.fit_transform(embedding)\n",
    "\n",
    "        # Known labels\n",
    "        ax.scatter(embedding_2d[label_mask, 0], embedding_2d[label_mask, 1], \n",
    "                   c=labels[label_mask], cmap=\"Set1\", s=3, alpha=0.7, label=\"Known Labels\",\n",
    "                   edgecolors='none')\n",
    "\n",
    "        # Unknown labels\n",
    "        ax.scatter(embedding_2d[~label_mask, 0], embedding_2d[~label_mask, 1], \n",
    "                   c=labels[~label_mask], cmap=\"Set1\", s=5, alpha=0.7, \n",
    "                   label=\"Unknown Labels\", edgecolors='black', linewidths=0.2)\n",
    "\n",
    "        # Title with smaller font size\n",
    "        ax.set_title(embedding_type.upper(), fontsize=8, pad=2)\n",
    "\n",
    "        # Remove axis labels, ticks, and frames\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_frame_on(False)\n",
    "\n",
    "    # Remove empty subplots if num_embeddings is not a multiple of 4\n",
    "    for j in range(i + 1, num_rows * 4):\n",
    "        row, col = divmod(j, 4)\n",
    "        fig.delaxes(axes[row, col])\n",
    "\n",
    "    plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05, wspace=0.2, hspace=0.2)  # Adjust margins\n",
    "    save_path = \"./wikics_analysis_results/embedding_grid_plot_wikics.png\"\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    print(f\"Visualization saved to {save_path}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54e03467-9366-4fe3-852c-a97d6f08d53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(true_labels, predicted_labels):\n",
    "    \"\"\"\n",
    "    Evaluate the model's performance using accuracy, F1-score, and confusion matrix.\n",
    "\n",
    "    Args:\n",
    "        true_labels (np.array): Ground truth labels (integers).\n",
    "        predicted_labels (np.array): Predicted labels (integers).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing accuracy, F1-score, and confusion matrix.\n",
    "    \"\"\"\n",
    "    # Compute accuracy\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    \n",
    "    # Compute F1-score (macro-averaged)\n",
    "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "    #\n",
    "    print(cm)\n",
    "    \n",
    "    # Return results as a dictionary\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df52f5b2-f16e-4ff9-9c2f-a4864423790e",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a49bc01-8d65-495c-9d6e-3910beeeb8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(tf.keras.Model):\n",
    "    def __init__(self, n_labels, seed=42):  # Use an explicit seed\n",
    "        super().__init__()\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=seed)  # Define initializer\n",
    "        \n",
    "        self.conv1 = GCNConv(16, activation='relu', kernel_initializer=initializer)\n",
    "        self.conv2 = GCNConv(n_labels, activation='softmax', kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        intermediate_embeddings = self.conv1([x, a])  # Store intermediate embeddings\n",
    "        x = self.conv2([intermediate_embeddings, a])\n",
    "        return x, intermediate_embeddings  # Return both final output and intermediate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0940847f-7630-4359-94d6-55bfa89cb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GAT model\n",
    "class GAT(tf.keras.Model):\n",
    "    def __init__(self, n_labels, num_heads=8, seed=42):\n",
    "        super().__init__()\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=seed)\n",
    "\n",
    "        self.conv1 = GATConv(16, attn_heads=num_heads, concat_heads=True, activation='elu', kernel_initializer=initializer)\n",
    "        self.conv2 = GATConv(n_labels, attn_heads=1, concat_heads=False, activation='softmax', kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        intermediate_embeddings = self.conv1([x, a])  # Store intermediate embeddings\n",
    "        x = self.conv2([intermediate_embeddings, a])\n",
    "        return x, intermediate_embeddings  # Return both final output and intermediate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d80d723e-e860-4d80-a4a9-111c45755ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GraphSAGE model\n",
    "class GraphSAGE(tf.keras.Model):\n",
    "    def __init__(self, n_labels, hidden_dim=16, aggregator='mean', seed=42):\n",
    "        super().__init__()\n",
    "        initializer = tf.keras.initializers.GlorotUniform(seed=seed)\n",
    "\n",
    "        self.conv1 = GraphSageConv(hidden_dim, activation='relu', aggregator=aggregator, kernel_initializer=initializer)\n",
    "        self.conv2 = GraphSageConv(n_labels, activation='softmax', aggregator=aggregator, kernel_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x, a = inputs\n",
    "        intermediate_embeddings = self.conv1([x, a])  # Store intermediate embeddings\n",
    "        x = self.conv2([intermediate_embeddings, a])\n",
    "        return x, intermediate_embeddings  # Return both final output and intermediate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f672acf4-d874-4ad6-9591-b076bfa70b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers=['gcn','gat','graphsage']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612842ab-92fa-45cc-aa76-a19b1a833857",
   "metadata": {},
   "source": [
    "## Classification using different node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11be1654-a7b6-4ca8-80b1-29b2956c5e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(embedding_dict, embedding, classifier, ground_truth_labels=ground_truth_labels, masked_labels=masked_labels):\n",
    "    \"the labels have to be one hot encoded\"\n",
    "    \"model take values: gcn, gat, graphsage\"\n",
    "    print('embedding: ' + embedding.upper())\n",
    "    print('model: ' + classifier.upper())\n",
    "\n",
    "    X = embedding_dict[embedding]\n",
    "\n",
    "    print(\"Processing...\")\n",
    "    # Create boolean mask for training\n",
    "    train_mask = masked_labels != -1\n",
    "\n",
    "    # Split the data into training and prediction sets\n",
    "    X_train = X[train_mask]  # Training node features\n",
    "    Y_train = ground_truth_labels[train_mask]  # Training labels (one-hot encoded)\n",
    "    Y_train = tf.cast(Y_train, dtype='int32')\n",
    "    \n",
    "    # Reduce the adjacency matrix to only include training nodes\n",
    "    A_train = A[train_mask, :][:, train_mask]  # Correctly reduce the adjacency matrix\n",
    "    \n",
    "    # Convert sparse adjacency matrix to COO format\n",
    "    A_coo = A_train.tocoo()\n",
    "    indices = np.column_stack((A_coo.row, A_coo.col))  # Corrected indices format\n",
    "    values = A_coo.data\n",
    "    shape = A_coo.shape  # Shape: (num_nodes, num_nodes)\n",
    "    \n",
    "    # Create a sparse tensor for the adjacency matrix\n",
    "    A_train_tensor = tf.sparse.SparseTensor(indices=indices, values=values, dense_shape=shape)\n",
    "    \n",
    "    # Ensure the sparse tensor is ordered correctly\n",
    "    A_train_tensor = tf.sparse.reorder(A_train_tensor)\n",
    "\n",
    "    print(\"Training...\")\n",
    "    # Initialize the model\n",
    "    if classifier == 'gcn':\n",
    "        n_labels = ground_truth_labels.shape[1]  # Number of classes\n",
    "        model = GCN(n_labels)\n",
    "    elif classifier == 'gat':\n",
    "        n_labels = ground_truth_labels.shape[1]  # Number of classes\n",
    "        model = GAT(n_labels)\n",
    "    elif classifier == 'graphsage':\n",
    "        n_labels = ground_truth_labels.shape[1]  # Number of classes\n",
    "        model = GraphSAGE(n_labels)\n",
    "    \n",
    "    # Compile the model (not strictly necessary when using GradientTape, but useful for metrics)\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.01),\n",
    "        loss=CategoricalCrossentropy(),\n",
    "        metrics=[CategoricalAccuracy()]\n",
    "    )\n",
    "    \n",
    "    # Print shapes for debugging\n",
    "    print(f\"Shape of X_train: {X_train.shape}\")\n",
    "    print(f\"Shape of A_train_tensor: {A_train_tensor.shape}\")\n",
    "    print(f\"Shape of Y_train: {Y_train.shape}\")\n",
    "    \n",
    "    # Define the optimizer and loss function\n",
    "    optimizer = Adam(learning_rate=0.01)\n",
    "    loss_fn = CategoricalCrossentropy()\n",
    "    \n",
    "    # Training loop with GradientTape\n",
    "    epochs = 200\n",
    "    for epoch in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass\n",
    "            predictions, intermediate_embeddings = model([X_train, A_train_tensor])  # Unpack both outputs\n",
    "                \n",
    "            # Compute supervised loss (cross-entropy)\n",
    "            supervised_loss = loss_fn(Y_train, predictions)\n",
    "            \n",
    "        # Compute gradients\n",
    "        gradients = tape.gradient(supervised_loss, model.trainable_variables)\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "        # Print loss and accuracy for monitoring\n",
    "        if epoch % 10 == 0:\n",
    "            accuracy = CategoricalAccuracy()(Y_train, predictions)\n",
    "            print(f\"Epoch {epoch + 1}, Loss: {supervised_loss.numpy()}, Accuracy: {accuracy.numpy()}\")\n",
    "\n",
    "    print(\"Predicting...\")\n",
    "    # Prepare the full graph for prediction\n",
    "    X_full = X  # Full node features\n",
    "    A_full = A  # Full adjacency matrix\n",
    "    \n",
    "    # Convert the full adjacency matrix to COO format\n",
    "    A_full_coo = A_full.tocoo()\n",
    "    indices_full = np.column_stack((A_full_coo.row, A_full_coo.col))\n",
    "    values_full = A_full_coo.data\n",
    "    shape_full = A_full_coo.shape\n",
    "    \n",
    "    # Create a sparse tensor for the full adjacency matrix\n",
    "    A_full_tensor = tf.sparse.SparseTensor(indices=indices_full, values=values_full, dense_shape=shape_full)\n",
    "    A_full_tensor = tf.sparse.reorder(A_full_tensor)\n",
    "    \n",
    "    # Make predictions for all nodes\n",
    "    predictions, emb = model([X_full, A_full_tensor])  # Shape: [num_nodes, n_labels]\n",
    "\n",
    "    # Convert predictions to class labels (integers)\n",
    "    predicted_labels = tf.argmax(predictions, axis=1).numpy()  # Shape: [num_nodes]\n",
    "    \n",
    "    # Extract predictions for the masked nodes\n",
    "    predicted_labels_masked = predicted_labels[labels_to_be_masked]\n",
    "\n",
    "    # True labels for the masked nodes\n",
    "    true_labels_masked = labels[labels_to_be_masked]\n",
    "    \n",
    "    # Predicted labels for the masked nodes\n",
    "    predicted_labels_masked = predicted_labels[labels_to_be_masked]\n",
    "    \n",
    "    # Evaluate the model's performance\n",
    "    results = evaluate_model(true_labels_masked, predicted_labels_masked)\n",
    "    \n",
    "    # Print the results\n",
    "    print(f\"Accuracy: {results['accuracy'] * 100:.2f}%\")\n",
    "    print(f\"F1-Score: {results['f1_score']:.4f}\")\n",
    "\n",
    "    results['model'] = classifier\n",
    "    results['embedding'] = embedding\n",
    "\n",
    "    # Return results and intermediate embeddings for visualization\n",
    "    return results, emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31449457-a308-4782-bb7d-c3ab4463dfca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding: DEEPWALK\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 150)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 115.68543243408203, Accuracy: 0.03674167022109032\n",
      "Epoch 11, Loss: 8.77559757232666, Accuracy: 0.44232413172721863\n",
      "Epoch 21, Loss: 2.6286704540252686, Accuracy: 0.4474508762359619\n",
      "Epoch 31, Loss: 1.9450163841247559, Accuracy: 0.46226146817207336\n",
      "Epoch 41, Loss: 1.8319092988967896, Accuracy: 0.4389062821865082\n",
      "Epoch 51, Loss: 1.7532421350479126, Accuracy: 0.44317859411239624\n",
      "Epoch 61, Loss: 1.6972224712371826, Accuracy: 0.4571347236633301\n",
      "Epoch 71, Loss: 1.6411986351013184, Accuracy: 0.46254628896713257\n",
      "Epoch 81, Loss: 1.6094704866409302, Accuracy: 0.4693819284439087\n",
      "Epoch 91, Loss: 1.5741814374923706, Accuracy: 0.47849616408348083\n",
      "Epoch 101, Loss: 1.5570604801177979, Accuracy: 0.4776417016983032\n",
      "Epoch 111, Loss: 1.5384483337402344, Accuracy: 0.486755907535553\n",
      "Epoch 121, Loss: 1.5238734483718872, Accuracy: 0.4870407283306122\n",
      "Epoch 131, Loss: 1.5087584257125854, Accuracy: 0.49074336886405945\n",
      "Epoch 141, Loss: 1.4951695203781128, Accuracy: 0.49814867973327637\n",
      "Epoch 151, Loss: 1.482582926750183, Accuracy: 0.49843350052833557\n",
      "Epoch 161, Loss: 1.4676300287246704, Accuracy: 0.5064084529876709\n",
      "Epoch 171, Loss: 1.4535354375839233, Accuracy: 0.5118200182914734\n",
      "Epoch 181, Loss: 1.4400907754898071, Accuracy: 0.5140985250473022\n",
      "Epoch 191, Loss: 1.4270037412643433, Accuracy: 0.5203645825386047\n",
      "Predicting...\n",
      "[[   0    1    0    1  169    0    3    0    0   34]\n",
      " [   0  241   11    0  171    0    0    0    0   49]\n",
      " [   0    6  777  146  415   27   20    0    0  158]\n",
      " [   0    5  137  934  170    4    1    6    0   71]\n",
      " [   0    7   71   14 1689   27   12    0    0   29]\n",
      " [   0    4  134   12  193  175    4    0    0   36]\n",
      " [   0    1  102    4   72    3  111    0    0    2]\n",
      " [   0   20   45   30  428    9    7    1    0   68]\n",
      " [   1    7   21    1  256    5    2    0    0   44]\n",
      " [   0   16   40   28  165    1    0    0    0  736]]\n",
      "Accuracy: 56.95%\n",
      "F1-Score: 0.4099\n",
      "embedding: DEEPWALK\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 150)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 2.3032641410827637, Accuracy: 0.07775562256574631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.9300974011421204, Accuracy: 0.7205924391746521\n",
      "Epoch 21, Loss: 0.7698954939842224, Accuracy: 0.7678723931312561\n",
      "Epoch 31, Loss: 0.64713454246521, Accuracy: 0.7994873523712158\n",
      "Epoch 41, Loss: 0.583782970905304, Accuracy: 0.8174309134483337\n",
      "Epoch 51, Loss: 0.5271232724189758, Accuracy: 0.8336656093597412\n",
      "Epoch 61, Loss: 0.4785342216491699, Accuracy: 0.8450583815574646\n",
      "Epoch 71, Loss: 0.43271467089653015, Accuracy: 0.8627171516418457\n",
      "Epoch 81, Loss: 0.3860606551170349, Accuracy: 0.8709769248962402\n",
      "Epoch 91, Loss: 0.33824217319488525, Accuracy: 0.8869268298149109\n",
      "Epoch 101, Loss: 0.2933032214641571, Accuracy: 0.9034463167190552\n",
      "Epoch 111, Loss: 0.2537045180797577, Accuracy: 0.9188265204429626\n",
      "Epoch 121, Loss: 0.21726755797863007, Accuracy: 0.9342067837715149\n",
      "Epoch 131, Loss: 0.19300468266010284, Accuracy: 0.9401879906654358\n",
      "Epoch 141, Loss: 0.16577138006687164, Accuracy: 0.9501566290855408\n",
      "Epoch 151, Loss: 0.1486230492591858, Accuracy: 0.953859269618988\n",
      "Epoch 161, Loss: 0.13297852873802185, Accuracy: 0.9578467607498169\n",
      "Epoch 171, Loss: 0.1222165897488594, Accuracy: 0.9612646102905273\n",
      "Epoch 181, Loss: 0.11427764594554901, Accuracy: 0.962688684463501\n",
      "Epoch 191, Loss: 0.12066897004842758, Accuracy: 0.9606949687004089\n",
      "Predicting...\n",
      "[[ 181    8    4    0    7    0    0    0    3    5]\n",
      " [   6  327   33   14   27    6    0   21   10   28]\n",
      " [   3   12 1345   54   44    9    9   20    8   45]\n",
      " [   2   10  222  974   22   14    3   39    5   37]\n",
      " [   1   52  191   29 1466   31    5   45   20    9]\n",
      " [   0   16  111    7   65  335    1   10    9    4]\n",
      " [   1    5   95   11   12    2  155    9    4    1]\n",
      " [   1   42   78   23   50   22    3  346   27   16]\n",
      " [   1   27   47    6   23    9    0   22  163   39]\n",
      " [   4   25   83   11   15    1    1   10   18  818]]\n",
      "Accuracy: 74.60%\n",
      "F1-Score: 0.7182\n",
      "embedding: DEEPWALK\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 150)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 2.3578875064849854, Accuracy: 0.059242382645606995\n",
      "Epoch 11, Loss: 1.8262706995010376, Accuracy: 0.6465394496917725\n",
      "Epoch 21, Loss: 1.6986303329467773, Accuracy: 0.7576189041137695\n",
      "Epoch 31, Loss: 1.6590656042099, Accuracy: 0.7878097295761108\n",
      "Epoch 41, Loss: 1.6336956024169922, Accuracy: 0.810310423374176\n",
      "Epoch 51, Loss: 1.619170904159546, Accuracy: 0.8197094798088074\n",
      "Epoch 61, Loss: 1.60837984085083, Accuracy: 0.8288236856460571\n",
      "Epoch 71, Loss: 1.599637746810913, Accuracy: 0.8353745341300964\n",
      "Epoch 81, Loss: 1.5921767950057983, Accuracy: 0.847621738910675\n",
      "Epoch 91, Loss: 1.5855786800384521, Accuracy: 0.8558815121650696\n",
      "Epoch 101, Loss: 1.5794678926467896, Accuracy: 0.8632867932319641\n",
      "Epoch 111, Loss: 1.5738434791564941, Accuracy: 0.8718313574790955\n",
      "Epoch 121, Loss: 1.568544626235962, Accuracy: 0.8792366981506348\n",
      "Epoch 131, Loss: 1.5633628368377686, Accuracy: 0.8863571882247925\n",
      "Epoch 141, Loss: 1.5582163333892822, Accuracy: 0.8914839029312134\n",
      "Epoch 151, Loss: 1.5536810159683228, Accuracy: 0.896610677242279\n",
      "Epoch 161, Loss: 1.5482004880905151, Accuracy: 0.9008829593658447\n",
      "Epoch 171, Loss: 1.5433862209320068, Accuracy: 0.904585599899292\n",
      "Epoch 181, Loss: 1.537750244140625, Accuracy: 0.9088578820228577\n",
      "Epoch 191, Loss: 1.5330026149749756, Accuracy: 0.9122757315635681\n",
      "Predicting...\n",
      "[[ 176    5    2    3   12    1    1    4    2    2]\n",
      " [   5  311   19   34   32    3    1   29    7   31]\n",
      " [   2   10 1220  103   65   17   19   40    7   66]\n",
      " [   3    6  123 1090   32   13    5   25    5   26]\n",
      " [   2   23   65   38 1617   37    4   34   11   18]\n",
      " [   0    7   32   15   68  397    3   12   18    6]\n",
      " [   0    2   67   14   29    1  169   10    2    1]\n",
      " [   3   23   32   34   67   23    2  387   16   21]\n",
      " [   0   12   19    9   38   18    2   33  166   40]\n",
      " [   5    8   44   27   28    5    1   19   11  838]]\n",
      "Accuracy: 77.79%\n",
      "F1-Score: 0.7452\n",
      "embedding: VGAE\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 150)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 71.7182846069336, Accuracy: 0.10025633871555328\n",
      "Epoch 11, Loss: 5.593278884887695, Accuracy: 0.5246368646621704\n",
      "Epoch 21, Loss: 2.904733657836914, Accuracy: 0.5519794821739197\n",
      "Epoch 31, Loss: 2.0272631645202637, Accuracy: 0.5328966379165649\n",
      "Epoch 41, Loss: 1.681957721710205, Accuracy: 0.5508401989936829\n",
      "Epoch 51, Loss: 1.4945926666259766, Accuracy: 0.558530330657959\n",
      "Epoch 61, Loss: 1.4091887474060059, Accuracy: 0.5747650265693665\n",
      "Epoch 71, Loss: 1.3679840564727783, Accuracy: 0.5767587423324585\n",
      "Epoch 81, Loss: 1.343232274055481, Accuracy: 0.5793221592903137\n",
      "Epoch 91, Loss: 1.3249437808990479, Accuracy: 0.5773283839225769\n",
      "Epoch 101, Loss: 1.3117940425872803, Accuracy: 0.5827399492263794\n",
      "Epoch 111, Loss: 1.300040602684021, Accuracy: 0.5833095908164978\n",
      "Epoch 121, Loss: 1.2899959087371826, Accuracy: 0.5858729481697083\n",
      "Epoch 131, Loss: 1.2813754081726074, Accuracy: 0.5861577987670898\n",
      "Epoch 141, Loss: 1.2736141681671143, Accuracy: 0.5861577987670898\n",
      "Epoch 151, Loss: 1.2660140991210938, Accuracy: 0.5881515145301819\n",
      "Epoch 161, Loss: 1.2580503225326538, Accuracy: 0.5918541550636292\n",
      "Epoch 171, Loss: 1.2505203485488892, Accuracy: 0.5932782888412476\n",
      "Epoch 181, Loss: 1.2440435886383057, Accuracy: 0.5941327214241028\n",
      "Epoch 191, Loss: 1.236912727355957, Accuracy: 0.5961264371871948\n",
      "Predicting...\n",
      "[[ 165    0    0    0   23    0    0    0    0   20]\n",
      " [   6  190   20   15  191    6    0    3   11   30]\n",
      " [   4   71  793  131  267   53    8    2   14  206]\n",
      " [   3    9  291  818   97   23    3    4    3   77]\n",
      " [   1   29   73   12 1539  142    2    4   24   23]\n",
      " [   0    3   26    3   76  424    1    3   16    6]\n",
      " [   0    3  104    3   53    2  125    0    2    3]\n",
      " [   4  170   36   60  203   45    2   21   30   37]\n",
      " [   4   21    7    1   96   42    1    0  139   26]\n",
      " [   7   11   19    8   80   30    2    1    7  821]]\n",
      "Accuracy: 61.48%\n",
      "F1-Score: 0.5614\n",
      "embedding: VGAE\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 150)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 2.3084065914154053, Accuracy: 0.05838792398571968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 1.035008430480957, Accuracy: 0.6915408968925476\n",
      "Epoch 21, Loss: 0.8854212164878845, Accuracy: 0.7262887954711914\n",
      "Epoch 31, Loss: 0.8051554560661316, Accuracy: 0.7533466219902039\n",
      "Epoch 41, Loss: 0.7500538229942322, Accuracy: 0.7670179605484009\n",
      "Epoch 51, Loss: 0.7001828551292419, Accuracy: 0.7761321663856506\n",
      "Epoch 61, Loss: 0.6540089249610901, Accuracy: 0.7892338633537292\n",
      "Epoch 71, Loss: 0.60956871509552, Accuracy: 0.8048989176750183\n",
      "Epoch 81, Loss: 0.5632889270782471, Accuracy: 0.8214184045791626\n",
      "Epoch 91, Loss: 0.51694655418396, Accuracy: 0.835659384727478\n",
      "Epoch 101, Loss: 0.4693875014781952, Accuracy: 0.8550270795822144\n",
      "Epoch 111, Loss: 0.42214736342430115, Accuracy: 0.8706921339035034\n",
      "Epoch 121, Loss: 0.376056045293808, Accuracy: 0.8883509039878845\n",
      "Epoch 131, Loss: 0.33207547664642334, Accuracy: 0.9040159583091736\n",
      "Epoch 141, Loss: 0.28966471552848816, Accuracy: 0.9191113710403442\n",
      "Epoch 151, Loss: 0.25420019030570984, Accuracy: 0.930219292640686\n",
      "Epoch 161, Loss: 0.21702714264392853, Accuracy: 0.9427513480186462\n",
      "Epoch 171, Loss: 0.18591582775115967, Accuracy: 0.9478781223297119\n",
      "Epoch 181, Loss: 0.15984942018985748, Accuracy: 0.9555681943893433\n",
      "Epoch 191, Loss: 0.1539773941040039, Accuracy: 0.9555681943893433\n",
      "Predicting...\n",
      "[[ 179    4    2    1    7    1    0    2    1   11]\n",
      " [   7  324   13   24   26   10    4   22   17   25]\n",
      " [   4   42  991  183   76   57   48   45   38   65]\n",
      " [   2   32  115 1022   30   25    6   40   13   43]\n",
      " [   5   60   50   39 1493   50   19   58   52   23]\n",
      " [   0    8   38   22   56  373   12   17   24    8]\n",
      " [   0    4   18   25   14    5  217    6    3    3]\n",
      " [   2   54   33   50   44   45   10  299   50   21]\n",
      " [   5   33   16    7   20   26    2   37  173   18]\n",
      " [   8   52   57   38   15    9    9   18   45  735]]\n",
      "Accuracy: 70.89%\n",
      "F1-Score: 0.6785\n",
      "embedding: VGAE\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 150)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 2.2749388217926025, Accuracy: 0.09199658036231995\n",
      "Epoch 11, Loss: 1.7728159427642822, Accuracy: 0.6861293315887451\n",
      "Epoch 21, Loss: 1.705674648284912, Accuracy: 0.7322700023651123\n",
      "Epoch 31, Loss: 1.6795817613601685, Accuracy: 0.7519225478172302\n",
      "Epoch 41, Loss: 1.6615198850631714, Accuracy: 0.7732839584350586\n",
      "Epoch 51, Loss: 1.647499680519104, Accuracy: 0.7878097295761108\n",
      "Epoch 61, Loss: 1.6349953413009644, Accuracy: 0.8017658591270447\n",
      "Epoch 71, Loss: 1.624106764793396, Accuracy: 0.8137282729148865\n",
      "Epoch 81, Loss: 1.614504337310791, Accuracy: 0.8254058957099915\n",
      "Epoch 91, Loss: 1.6058748960494995, Accuracy: 0.8342352509498596\n",
      "Epoch 101, Loss: 1.5979816913604736, Accuracy: 0.8407860994338989\n",
      "Epoch 111, Loss: 1.590441107749939, Accuracy: 0.8490458726882935\n",
      "Epoch 121, Loss: 1.583427906036377, Accuracy: 0.8555967211723328\n",
      "Epoch 131, Loss: 1.576734185218811, Accuracy: 0.8615778684616089\n",
      "Epoch 141, Loss: 1.5701316595077515, Accuracy: 0.8686983585357666\n",
      "Epoch 151, Loss: 1.5639897584915161, Accuracy: 0.8783822059631348\n",
      "Epoch 161, Loss: 1.5583499670028687, Accuracy: 0.8815152645111084\n",
      "Epoch 171, Loss: 1.5532302856445312, Accuracy: 0.8877812623977661\n",
      "Epoch 181, Loss: 1.548412561416626, Accuracy: 0.891768753528595\n",
      "Epoch 191, Loss: 1.5441997051239014, Accuracy: 0.8980347514152527\n",
      "Predicting...\n",
      "[[ 174    2    9    0    9    0    0    5    4    5]\n",
      " [   6  274   33   16   46    7    7   35   18   30]\n",
      " [   5   11 1227   95   83   17   30   29   11   41]\n",
      " [   4    6  141 1043   25    9    8   45   16   31]\n",
      " [   8   24   96   28 1507   36   25   87   17   21]\n",
      " [   3    4   66   13   59  371    4   10   19    9]\n",
      " [   0    3   60   11   13    1  190   13    3    1]\n",
      " [   5   13   64   36   51   30    3  369   17   20]\n",
      " [   5   10   39    2   44   25    0   53  122   37]\n",
      " [   6   22   94   25   28    6    4   11   24  766]]\n",
      "Accuracy: 73.79%\n",
      "F1-Score: 0.6970\n",
      "embedding: DGI\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 150)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 119.9688491821289, Accuracy: 0.06294503062963486\n",
      "Epoch 11, Loss: 2.2818894386291504, Accuracy: 0.23639988899230957\n",
      "Epoch 21, Loss: 2.2265655994415283, Accuracy: 0.2566220462322235\n",
      "Epoch 31, Loss: 2.1929666996002197, Accuracy: 0.2566220462322235\n",
      "Epoch 41, Loss: 2.154829263687134, Accuracy: 0.2566220462322235\n",
      "Epoch 51, Loss: 2.0956664085388184, Accuracy: 0.28396469354629517\n",
      "Epoch 61, Loss: 2.118656873703003, Accuracy: 0.2566220462322235\n",
      "Epoch 71, Loss: 2.1057870388031006, Accuracy: 0.2563372254371643\n",
      "Epoch 81, Loss: 2.091320514678955, Accuracy: 0.2566220462322235\n",
      "Epoch 91, Loss: 2.08054780960083, Accuracy: 0.2566220462322235\n",
      "Epoch 101, Loss: 2.073209285736084, Accuracy: 0.2566220462322235\n",
      "Epoch 111, Loss: 2.067837953567505, Accuracy: 0.2566220462322235\n",
      "Epoch 121, Loss: 2.063645839691162, Accuracy: 0.2566220462322235\n",
      "Epoch 131, Loss: 2.0601227283477783, Accuracy: 0.2566220462322235\n",
      "Epoch 141, Loss: 2.0526108741760254, Accuracy: 0.3044716715812683\n",
      "Epoch 151, Loss: 2.0191566944122314, Accuracy: 0.2808316648006439\n",
      "Epoch 161, Loss: 2.0098979473114014, Accuracy: 0.28168612718582153\n",
      "Epoch 171, Loss: 2.0081214904785156, Accuracy: 0.28140130639076233\n",
      "Epoch 181, Loss: 2.006753444671631, Accuracy: 0.28140130639076233\n",
      "Epoch 191, Loss: 2.005868434906006, Accuracy: 0.28140130639076233\n",
      "Predicting...\n",
      "[[   0    0    0    2  206    0    0    0    0    0]\n",
      " [   0    0    0    1  471    0    0    0    0    0]\n",
      " [   0    0    0   31 1518    0    0    0    0    0]\n",
      " [   0    0    0  361  967    0    0    0    0    0]\n",
      " [   0    0    0    9 1840    0    0    0    0    0]\n",
      " [   0    0    0    4  554    0    0    0    0    0]\n",
      " [   0    0    0    1  294    0    0    0    0    0]\n",
      " [   0    0    0    5  603    0    0    0    0    0]\n",
      " [   0    0    0    3  334    0    0    0    0    0]\n",
      " [   0    0    0   12  974    0    0    0    0    0]]\n",
      "Accuracy: 26.87%\n",
      "F1-Score: 0.0794\n",
      "embedding: DGI\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 150)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 2.304671049118042, Accuracy: 0.106807179749012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 1.7985327243804932, Accuracy: 0.46653375029563904\n",
      "Epoch 21, Loss: 1.5947238206863403, Accuracy: 0.46112218499183655\n",
      "Epoch 31, Loss: 1.423924207687378, Accuracy: 0.548561692237854\n",
      "Epoch 41, Loss: 1.3035420179367065, Accuracy: 0.5952720046043396\n",
      "Epoch 51, Loss: 1.214573860168457, Accuracy: 0.6183423399925232\n",
      "Epoch 61, Loss: 1.145402431488037, Accuracy: 0.6493876576423645\n",
      "Epoch 71, Loss: 1.080390214920044, Accuracy: 0.6693249940872192\n",
      "Epoch 81, Loss: 1.0236294269561768, Accuracy: 0.6829962730407715\n",
      "Epoch 91, Loss: 0.9798058867454529, Accuracy: 0.6926801204681396\n",
      "Epoch 101, Loss: 0.9442342519760132, Accuracy: 0.7043577432632446\n",
      "Epoch 111, Loss: 0.9176545143127441, Accuracy: 0.7077755331993103\n",
      "Epoch 121, Loss: 0.8860204219818115, Accuracy: 0.7200227975845337\n",
      "Epoch 131, Loss: 0.8623431324958801, Accuracy: 0.7251495122909546\n",
      "Epoch 141, Loss: 0.851526141166687, Accuracy: 0.7308459281921387\n",
      "Epoch 151, Loss: 0.8291932940483093, Accuracy: 0.7334092855453491\n",
      "Epoch 161, Loss: 0.815570592880249, Accuracy: 0.7436627745628357\n",
      "Epoch 171, Loss: 0.7960934042930603, Accuracy: 0.7462261319160461\n",
      "Epoch 181, Loss: 0.7836138010025024, Accuracy: 0.7507832646369934\n",
      "Epoch 191, Loss: 0.7698076367378235, Accuracy: 0.7547706961631775\n",
      "Predicting...\n",
      "[[ 176   12    0    2    9    0    0    1    1    7]\n",
      " [   7  312   14   22   53    1    3   22   14   24]\n",
      " [   2   25 1244   69   56    5   60   12   18   58]\n",
      " [   5   17  243  971   23    5   14   19    8   23]\n",
      " [   5   30   92   28 1575   37   10   29   24   19]\n",
      " [   1   10   66   11   89  323    2    7   41    8]\n",
      " [   0    3   96   13   19    1  156    4    2    1]\n",
      " [   3   56   61   30   81   11    6  305   36   19]\n",
      " [   1   22   27    5   44    8    1   31  160   38]\n",
      " [   7   25   94   24   14    4    2   11   43  762]]\n",
      "Accuracy: 73.06%\n",
      "F1-Score: 0.6877\n",
      "embedding: DGI\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 150)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 2.361537218093872, Accuracy: 0.07376815378665924\n",
      "Epoch 11, Loss: 2.117246150970459, Accuracy: 0.23668470978736877\n",
      "Epoch 21, Loss: 2.095031499862671, Accuracy: 0.24921675026416779\n",
      "Epoch 31, Loss: 2.0650107860565186, Accuracy: 0.3227000832557678\n",
      "Epoch 41, Loss: 2.0298573970794678, Accuracy: 0.40216463804244995\n",
      "Epoch 51, Loss: 1.966355323791504, Accuracy: 0.44346341490745544\n",
      "Epoch 61, Loss: 1.900006651878357, Accuracy: 0.5314725041389465\n",
      "Epoch 71, Loss: 1.8589311838150024, Accuracy: 0.5759043097496033\n",
      "Epoch 81, Loss: 1.8229107856750488, Accuracy: 0.6106522083282471\n",
      "Epoch 91, Loss: 1.803884506225586, Accuracy: 0.606664776802063\n",
      "Epoch 101, Loss: 1.7916418313980103, Accuracy: 0.617487907409668\n",
      "Epoch 111, Loss: 1.7782776355743408, Accuracy: 0.627456545829773\n",
      "Epoch 121, Loss: 1.7739323377609253, Accuracy: 0.6254628300666809\n",
      "Epoch 131, Loss: 1.7640655040740967, Accuracy: 0.6479635238647461\n",
      "Epoch 141, Loss: 1.7502317428588867, Accuracy: 0.6599259376525879\n",
      "Epoch 151, Loss: 1.7424530982971191, Accuracy: 0.6730276346206665\n",
      "Epoch 161, Loss: 1.7355161905288696, Accuracy: 0.6815721988677979\n",
      "Epoch 171, Loss: 1.7359933853149414, Accuracy: 0.6815721988677979\n",
      "Epoch 181, Loss: 1.7252261638641357, Accuracy: 0.6858444809913635\n",
      "Epoch 191, Loss: 1.7230174541473389, Accuracy: 0.7023640275001526\n",
      "Predicting...\n",
      "[[ 168    2    5    4   16    1    0    2    0   10]\n",
      " [   6   90   53   22   64    4    0  203    1   29]\n",
      " [   1    7 1267  111   73   14    0   29    0   47]\n",
      " [   2    6  164 1071   21   15    0   24    1   24]\n",
      " [   2   26  103   39 1564   70    0   26    1   18]\n",
      " [   2    2   62   18   61  398    0   11    1    3]\n",
      " [   0    1  252   10   26    2    0    3    0    1]\n",
      " [   2   21   87   48   99   28    0  311    1   11]\n",
      " [   1   11   88    5   86   61    0   39   18   28]\n",
      " [   3   10  122   35   24   21    0   11    2  758]]\n",
      "Accuracy: 68.93%\n",
      "F1-Score: 0.5467\n",
      "embedding: MODULARITY\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 150)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 2.408579111099243, Accuracy: 0.16861292719841003\n",
      "Epoch 11, Loss: 1.4926174879074097, Accuracy: 0.5984050035476685\n",
      "Epoch 21, Loss: 1.3650310039520264, Accuracy: 0.6397038102149963\n",
      "Epoch 31, Loss: 1.2937588691711426, Accuracy: 0.6525206565856934\n",
      "Epoch 41, Loss: 1.246943712234497, Accuracy: 0.6622045040130615\n",
      "Epoch 51, Loss: 1.2129961252212524, Accuracy: 0.6644830703735352\n",
      "Epoch 61, Loss: 1.1862188577651978, Accuracy: 0.6627741456031799\n",
      "Epoch 71, Loss: 1.1625299453735352, Accuracy: 0.6661919951438904\n",
      "Epoch 81, Loss: 1.1428802013397217, Accuracy: 0.6690401434898376\n",
      "Epoch 91, Loss: 1.1258412599563599, Accuracy: 0.6670464277267456\n",
      "Epoch 101, Loss: 1.1104118824005127, Accuracy: 0.6659071445465088\n",
      "Epoch 111, Loss: 1.0957938432693481, Accuracy: 0.669609785079956\n",
      "Epoch 121, Loss: 1.0818432569503784, Accuracy: 0.6716035604476929\n",
      "Epoch 131, Loss: 1.068567156791687, Accuracy: 0.6753062009811401\n",
      "Epoch 141, Loss: 1.055290699005127, Accuracy: 0.6778695583343506\n",
      "Epoch 151, Loss: 1.0420855283737183, Accuracy: 0.6815721988677979\n",
      "Epoch 161, Loss: 1.0286540985107422, Accuracy: 0.6847051978111267\n",
      "Epoch 171, Loss: 1.015033483505249, Accuracy: 0.689262330532074\n",
      "Epoch 181, Loss: 1.0018123388290405, Accuracy: 0.6923953294754028\n",
      "Epoch 191, Loss: 0.9892996549606323, Accuracy: 0.6943890452384949\n",
      "Predicting...\n",
      "[[ 174    2    8    0   12    0    0    0    6    6]\n",
      " [   3  263    5    2   96    1    0   16   11   75]\n",
      " [   2    9  839   11   65   50  220   89  127  137]\n",
      " [   4    9  248  713   39   34   46  151    6   78]\n",
      " [   1    8  283    5 1437    8   31   30   13   33]\n",
      " [   0    2  374   10   52   75    6   13   14   12]\n",
      " [   0    3   31    3    7    1  227    5    4   14]\n",
      " [   2   37   69    5  194    7   14  155   87   38]\n",
      " [   2   15   55    0   59    1    5   12  149   39]\n",
      " [   7   18   91    4   29    0   15   27  101  694]]\n",
      "Accuracy: 57.70%\n",
      "F1-Score: 0.5416\n",
      "embedding: MODULARITY\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 150)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 2.302638530731201, Accuracy: 0.045571062713861465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 2.061417579650879, Accuracy: 0.23639988899230957\n",
      "Epoch 21, Loss: 1.9427027702331543, Accuracy: 0.23639988899230957\n",
      "Epoch 31, Loss: 1.7228965759277344, Accuracy: 0.42010822892189026\n",
      "Epoch 41, Loss: 1.3786962032318115, Accuracy: 0.7288521528244019\n",
      "Epoch 51, Loss: 0.9974873661994934, Accuracy: 0.8205639123916626\n",
      "Epoch 61, Loss: 0.6979177594184875, Accuracy: 0.8487610220909119\n",
      "Epoch 71, Loss: 0.5119797587394714, Accuracy: 0.8601537942886353\n",
      "Epoch 81, Loss: 0.42193901538848877, Accuracy: 0.8732554912567139\n",
      "Epoch 91, Loss: 0.3775746822357178, Accuracy: 0.8769581317901611\n",
      "Epoch 101, Loss: 0.3528193235397339, Accuracy: 0.8823696970939636\n",
      "Epoch 111, Loss: 0.3342541754245758, Accuracy: 0.8889205455780029\n",
      "Epoch 121, Loss: 0.3164854645729065, Accuracy: 0.8940472602844238\n",
      "Epoch 131, Loss: 0.30071553587913513, Accuracy: 0.895756185054779\n",
      "Epoch 141, Loss: 0.28697705268859863, Accuracy: 0.9023070335388184\n",
      "Epoch 151, Loss: 0.276190847158432, Accuracy: 0.9071489572525024\n",
      "Epoch 161, Loss: 0.2675323784351349, Accuracy: 0.9085730314254761\n",
      "Epoch 171, Loss: 0.2602766156196594, Accuracy: 0.9108515977859497\n",
      "Epoch 181, Loss: 0.2535094916820526, Accuracy: 0.9117060899734497\n",
      "Epoch 191, Loss: 0.2448391169309616, Accuracy: 0.9159783720970154\n",
      "Predicting...\n",
      "[[ 152    3   21    3   10    1    0    2    0   16]\n",
      " [   5  292   45   21   29    8    1   36    9   26]\n",
      " [   0    3 1285  142   45    8   11   17    5   33]\n",
      " [   1    3  120 1122   27    4    3   14    8   26]\n",
      " [   3   14  107   48 1595   29    5   24   10   14]\n",
      " [   1    2   96   23   80  319    3    7   18    9]\n",
      " [   0    1   73   15   12    4  184    5    1    0]\n",
      " [   4   16  103   64   69   12    3  289   21   27]\n",
      " [   1   14   33   10   45   18    2   14  161   39]\n",
      " [   2    8  101   33   14    4    1   19   15  789]]\n",
      "Accuracy: 75.56%\n",
      "F1-Score: 0.7180\n",
      "embedding: MODULARITY\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 150)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 2.3084700107574463, Accuracy: 0.04101395606994629\n",
      "Epoch 11, Loss: 1.8611053228378296, Accuracy: 0.6607804298400879\n",
      "Epoch 21, Loss: 1.6078139543533325, Accuracy: 0.9256622195243835\n",
      "Epoch 31, Loss: 1.523633360862732, Accuracy: 0.9700939655303955\n",
      "Epoch 41, Loss: 1.4731413125991821, Accuracy: 0.9897465109825134\n",
      "Epoch 51, Loss: 1.4541298151016235, Accuracy: 0.9948732256889343\n",
      "Epoch 61, Loss: 1.4448283910751343, Accuracy: 0.998006284236908\n",
      "Epoch 71, Loss: 1.4392430782318115, Accuracy: 0.9991455674171448\n",
      "Epoch 81, Loss: 1.434996485710144, Accuracy: 0.9991455674171448\n",
      "Epoch 91, Loss: 1.4319193363189697, Accuracy: 0.9994303584098816\n",
      "Epoch 101, Loss: 1.4294911623001099, Accuracy: 0.9997152090072632\n",
      "Epoch 111, Loss: 1.4276643991470337, Accuracy: 1.0\n",
      "Epoch 121, Loss: 1.426336646080017, Accuracy: 1.0\n",
      "Epoch 131, Loss: 1.425295352935791, Accuracy: 1.0\n",
      "Epoch 141, Loss: 1.4244084358215332, Accuracy: 1.0\n",
      "Epoch 151, Loss: 1.4236948490142822, Accuracy: 1.0\n",
      "Epoch 161, Loss: 1.4231321811676025, Accuracy: 1.0\n",
      "Epoch 171, Loss: 1.4226702451705933, Accuracy: 1.0\n",
      "Epoch 181, Loss: 1.4223923683166504, Accuracy: 1.0\n",
      "Epoch 191, Loss: 1.4221521615982056, Accuracy: 1.0\n",
      "Predicting...\n",
      "[[ 165    4   19    2    5    1    0    1    4    7]\n",
      " [   7  286   62   16   29   14    3   23    8   24]\n",
      " [   5    4 1310  107   38   14   19    6    8   38]\n",
      " [   3    7  205 1044   21    5    6    7   12   18]\n",
      " [   5   15  170   36 1496   50   10   26   21   20]\n",
      " [   1    3   98   34   69  307    2    5   25   14]\n",
      " [   1    2   98   10   18    3  157    2    2    2]\n",
      " [   6   46  137   54   85   21    4  176   38   41]\n",
      " [   2   12   58   11   21   18    2    4  170   39]\n",
      " [   4   23  175   62   17    6    2    9   25  663]]\n",
      "Accuracy: 70.50%\n",
      "F1-Score: 0.6622\n",
      "embedding: NODE2VEC\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 150)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 93.38114166259766, Accuracy: 0.03446311503648758\n",
      "Epoch 11, Loss: 8.614826202392578, Accuracy: 0.453716903924942\n",
      "Epoch 21, Loss: 2.9378139972686768, Accuracy: 0.43805184960365295\n",
      "Epoch 31, Loss: 2.2233071327209473, Accuracy: 0.40187981724739075\n",
      "Epoch 41, Loss: 1.932867407798767, Accuracy: 0.3699800670146942\n",
      "Epoch 51, Loss: 1.8965797424316406, Accuracy: 0.36684703826904297\n",
      "Epoch 61, Loss: 1.8255977630615234, Accuracy: 0.37710052728652954\n",
      "Epoch 71, Loss: 1.7848114967346191, Accuracy: 0.38906294107437134\n",
      "Epoch 81, Loss: 1.745729684829712, Accuracy: 0.4001708924770355\n",
      "Epoch 91, Loss: 1.7242847681045532, Accuracy: 0.40786099433898926\n",
      "Epoch 101, Loss: 1.7026041746139526, Accuracy: 0.417829692363739\n",
      "Epoch 111, Loss: 1.6817867755889893, Accuracy: 0.42551979422569275\n",
      "Epoch 121, Loss: 1.6684818267822266, Accuracy: 0.43064653873443604\n",
      "Epoch 131, Loss: 1.6578850746154785, Accuracy: 0.4337795376777649\n",
      "Epoch 141, Loss: 1.648529291152954, Accuracy: 0.4340643584728241\n",
      "Epoch 151, Loss: 1.626389503479004, Accuracy: 0.4349188208580017\n",
      "Epoch 161, Loss: 1.6101443767547607, Accuracy: 0.44289377331733704\n",
      "Epoch 171, Loss: 1.5965970754623413, Accuracy: 0.44972941279411316\n",
      "Epoch 181, Loss: 1.583896517753601, Accuracy: 0.4582740068435669\n",
      "Epoch 191, Loss: 1.5711369514465332, Accuracy: 0.4588436484336853\n",
      "Predicting...\n",
      "[[   0    2    6    5  178    0    2    0    0   15]\n",
      " [   0  122   91    8  216    6    1    0    5   23]\n",
      " [   0    5  521  307  413   62   52    2    0  187]\n",
      " [   0    3  130  931  168   15    2    0    0   79]\n",
      " [   0   14   67   26 1602  108    6    1    0   25]\n",
      " [   0    0   27    7  195  302    1    0    1   25]\n",
      " [   0    1   34    9   93   14  127    0    1   16]\n",
      " [   0  133   90   39  287   29    4    0    2   24]\n",
      " [   0   25   33    9  201   52    1    2    1   13]\n",
      " [   0    9   58  414  143    5    3    0    2  352]]\n",
      "Accuracy: 48.33%\n",
      "F1-Score: 0.3362\n",
      "embedding: NODE2VEC\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 150)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 2.3068597316741943, Accuracy: 0.05468527600169182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.9254922866821289, Accuracy: 0.7197379469871521\n",
      "Epoch 21, Loss: 0.7597125172615051, Accuracy: 0.7678723931312561\n",
      "Epoch 31, Loss: 0.6382719278335571, Accuracy: 0.8009114265441895\n",
      "Epoch 41, Loss: 0.5707075595855713, Accuracy: 0.821133553981781\n",
      "Epoch 51, Loss: 0.5164716839790344, Accuracy: 0.8393620252609253\n",
      "Epoch 61, Loss: 0.4634150266647339, Accuracy: 0.8550270795822144\n",
      "Epoch 71, Loss: 0.4101620316505432, Accuracy: 0.8715465664863586\n",
      "Epoch 81, Loss: 0.35885077714920044, Accuracy: 0.8852179050445557\n",
      "Epoch 91, Loss: 0.31028833985328674, Accuracy: 0.9017373919487\n",
      "Epoch 101, Loss: 0.26513826847076416, Accuracy: 0.9122757315635681\n",
      "Epoch 111, Loss: 0.22613245248794556, Accuracy: 0.9276559352874756\n",
      "Epoch 121, Loss: 0.1904897689819336, Accuracy: 0.941896915435791\n",
      "Epoch 131, Loss: 0.16311459243297577, Accuracy: 0.9504414796829224\n",
      "Epoch 141, Loss: 0.14400714635849, Accuracy: 0.952720046043396\n",
      "Epoch 151, Loss: 0.13312917947769165, Accuracy: 0.9549985527992249\n",
      "Epoch 161, Loss: 0.13023732602596283, Accuracy: 0.9549985527992249\n",
      "Epoch 171, Loss: 0.11655576527118683, Accuracy: 0.9609797596931458\n",
      "Epoch 181, Loss: 0.10572294145822525, Accuracy: 0.9621190428733826\n",
      "Epoch 191, Loss: 0.09854555875062943, Accuracy: 0.9638279676437378\n",
      "Predicting...\n",
      "[[ 177    9    3    0    5    0    0    1    6    7]\n",
      " [   5  293   30   14   32    5    8   58    8   19]\n",
      " [   3   21 1147  101   58   51   55   29   19   65]\n",
      " [   2   15  159 1014   15   13   11   59   10   30]\n",
      " [   2   65   75   18 1582   31   10   37   20    9]\n",
      " [   1   13   44   17   90  327    6   39   18    3]\n",
      " [   0    2   62   14   19    1  183   11    2    1]\n",
      " [   1   30   47   22   62   26    3  383   26    8]\n",
      " [   0   28   46    7   29   18    1   34  153   21]\n",
      " [   6   22   71   35   20    3    7   21   24  777]]\n",
      "Accuracy: 73.70%\n",
      "F1-Score: 0.6980\n",
      "embedding: NODE2VEC\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 150)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 2.354482412338257, Accuracy: 0.02905155159533024\n",
      "Epoch 11, Loss: 1.8276361227035522, Accuracy: 0.6473938822746277\n",
      "Epoch 21, Loss: 1.7166118621826172, Accuracy: 0.7274280786514282\n",
      "Epoch 31, Loss: 1.6634232997894287, Accuracy: 0.7735688090324402\n",
      "Epoch 41, Loss: 1.6370409727096558, Accuracy: 0.8034747838973999\n",
      "Epoch 51, Loss: 1.617854356765747, Accuracy: 0.8225576877593994\n",
      "Epoch 61, Loss: 1.6033718585968018, Accuracy: 0.8353745341300964\n",
      "Epoch 71, Loss: 1.591894268989563, Accuracy: 0.8450583815574646\n",
      "Epoch 81, Loss: 1.5820366144180298, Accuracy: 0.8527485132217407\n",
      "Epoch 91, Loss: 1.5726544857025146, Accuracy: 0.8630020022392273\n",
      "Epoch 101, Loss: 1.563396692276001, Accuracy: 0.8752492070198059\n",
      "Epoch 111, Loss: 1.5536465644836426, Accuracy: 0.8863571882247925\n",
      "Epoch 121, Loss: 1.5434684753417969, Accuracy: 0.8954713940620422\n",
      "Epoch 131, Loss: 1.5337655544281006, Accuracy: 0.9028766751289368\n",
      "Epoch 141, Loss: 1.5248979330062866, Accuracy: 0.9117060899734497\n",
      "Epoch 151, Loss: 1.5174648761749268, Accuracy: 0.9182568788528442\n",
      "Epoch 161, Loss: 1.5111987590789795, Accuracy: 0.9256622195243835\n",
      "Epoch 171, Loss: 1.5043838024139404, Accuracy: 0.931073784828186\n",
      "Epoch 181, Loss: 1.4975537061691284, Accuracy: 0.9376246333122253\n",
      "Epoch 191, Loss: 1.4929865598678589, Accuracy: 0.9404727816581726\n",
      "Predicting...\n",
      "[[ 191    4    0    2    5    0    0    3    0    3]\n",
      " [   7  306   25   13   42    2    4   39   12   22]\n",
      " [  11   13 1169  113   71   23   41   28   22   58]\n",
      " [   6    9  131 1073   25    6    6   32    8   32]\n",
      " [   5   27   69   36 1587   26    4   58   25   12]\n",
      " [   2   13   27   12   58  394    6   15   24    7]\n",
      " [   4    3   46   22   27    1  181    8    2    1]\n",
      " [   2   29   48   30   66   19    4  358   33   19]\n",
      " [   4   20   15    7   20   15    1   23  201   31]\n",
      " [   7   14   54   16   14    7    2   18   21  833]]\n",
      "Accuracy: 76.84%\n",
      "F1-Score: 0.7361\n",
      "embedding: RANDOM\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 150)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 56.909881591796875, Accuracy: 0.14981487393379211\n",
      "Epoch 11, Loss: 5.8536295890808105, Accuracy: 0.5186556577682495\n",
      "Epoch 21, Loss: 3.1611392498016357, Accuracy: 0.5465679168701172\n",
      "Epoch 31, Loss: 2.2667605876922607, Accuracy: 0.5289091467857361\n",
      "Epoch 41, Loss: 1.7809807062149048, Accuracy: 0.5739105939865112\n",
      "Epoch 51, Loss: 1.5426746606826782, Accuracy: 0.5807462334632874\n",
      "Epoch 61, Loss: 1.3927937746047974, Accuracy: 0.5892907977104187\n",
      "Epoch 71, Loss: 1.30166494846344, Accuracy: 0.6012532114982605\n",
      "Epoch 81, Loss: 1.2435873746871948, Accuracy: 0.6092281341552734\n",
      "Epoch 91, Loss: 1.302193522453308, Accuracy: 0.6146396994590759\n",
      "Epoch 101, Loss: 1.1879231929779053, Accuracy: 0.6197664737701416\n",
      "Epoch 111, Loss: 1.1242181062698364, Accuracy: 0.6308743953704834\n",
      "Epoch 121, Loss: 1.0972586870193481, Accuracy: 0.6360011100769043\n",
      "Epoch 131, Loss: 1.0647826194763184, Accuracy: 0.6388493180274963\n",
      "Epoch 141, Loss: 1.0416152477264404, Accuracy: 0.6456850171089172\n",
      "Epoch 151, Loss: 1.0217609405517578, Accuracy: 0.6482483744621277\n",
      "Epoch 161, Loss: 1.0053918361663818, Accuracy: 0.6565080881118774\n",
      "Epoch 171, Loss: 0.9910865426063538, Accuracy: 0.6596411466598511\n",
      "Epoch 181, Loss: 0.9783178567886353, Accuracy: 0.6627741456031799\n",
      "Epoch 191, Loss: 0.966667890548706, Accuracy: 0.6664767861366272\n",
      "Predicting...\n",
      "[[   0    0    6   16   17    1    0   64   11   93]\n",
      " [   1   23   19  200  113    7    6   33    6   64]\n",
      " [  13    8  266  611  221   35   97   97   78  123]\n",
      " [  26    1   36  886   67   33    7  172   23   77]\n",
      " [   8    5  112  243 1126   93   12  125   48   77]\n",
      " [   5    1   74   40   86  217   14   42   29   50]\n",
      " [   0    0   12  183   36   22   20    7    2   13]\n",
      " [   5    2   17  146  108   22    7  217   21   63]\n",
      " [   3    4   34   36   76   25    6   66   30   57]\n",
      " [   4   12   43  184  122   58    4   32   29  498]]\n",
      "Accuracy: 40.09%\n",
      "F1-Score: 0.2739\n",
      "embedding: RANDOM\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 150)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 2.3045692443847656, Accuracy: 0.09171175956726074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 1.3205773830413818, Accuracy: 0.609512984752655\n",
      "Epoch 21, Loss: 0.8859952688217163, Accuracy: 0.7274280786514282\n",
      "Epoch 31, Loss: 0.5803922414779663, Accuracy: 0.8182854056358337\n",
      "Epoch 41, Loss: 0.35367128252983093, Accuracy: 0.9017373919487\n",
      "Epoch 51, Loss: 0.2092457115650177, Accuracy: 0.9413272738456726\n",
      "Epoch 61, Loss: 0.14493437111377716, Accuracy: 0.9598404765129089\n",
      "Epoch 71, Loss: 0.09907355904579163, Accuracy: 0.9729421734809875\n",
      "Epoch 81, Loss: 0.0740928202867508, Accuracy: 0.9800626635551453\n",
      "Epoch 91, Loss: 0.059070561081171036, Accuracy: 0.9837653040885925\n",
      "Epoch 101, Loss: 0.04915054515004158, Accuracy: 0.9857590198516846\n",
      "Epoch 111, Loss: 0.04150977358222008, Accuracy: 0.9874679446220398\n",
      "Epoch 121, Loss: 0.035311248153448105, Accuracy: 0.9897465109825134\n",
      "Epoch 131, Loss: 0.030131828039884567, Accuracy: 0.9914554357528687\n",
      "Epoch 141, Loss: 0.02622896246612072, Accuracy: 0.9920250773429871\n",
      "Epoch 151, Loss: 0.06723947823047638, Accuracy: 0.976360023021698\n",
      "Epoch 161, Loss: 0.0479409322142601, Accuracy: 0.9880375862121582\n",
      "Epoch 171, Loss: 0.03227079287171364, Accuracy: 0.9911705851554871\n",
      "Epoch 181, Loss: 0.025084318593144417, Accuracy: 0.9920250773429871\n",
      "Epoch 191, Loss: 0.020817214623093605, Accuracy: 0.9937340021133423\n",
      "Predicting...\n",
      "[[  25    4   80   17   46   14    4    9    1    8]\n",
      " [   6   76  129   80   41    7   33   26   13   61]\n",
      " [   4    8 1101  229   77   10   28   14   41   37]\n",
      " [   8    3  437  735   56   15   22   17   14   21]\n",
      " [  26   24  447   80 1028   45   44   58   37   60]\n",
      " [   3    1  174   41  119  144   15   19   17   25]\n",
      " [   2    2   88   46   31    0  117    2    5    2]\n",
      " [  13    6  280   57   79   24   15   74   25   35]\n",
      " [   4   10  106   22   58   18    8   17   70   24]\n",
      " [   6    9  519  108   76   20   22   31   23  172]]\n",
      "Accuracy: 43.25%\n",
      "F1-Score: 0.3364\n",
      "embedding: RANDOM\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 150)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 2.327486991882324, Accuracy: 0.09342067688703537\n",
      "Epoch 11, Loss: 2.026259183883667, Accuracy: 0.42039304971694946\n",
      "Epoch 21, Loss: 1.925569772720337, Accuracy: 0.5126744508743286\n",
      "Epoch 31, Loss: 1.8357266187667847, Accuracy: 0.6510965824127197\n",
      "Epoch 41, Loss: 1.7734135389328003, Accuracy: 0.699230968952179\n",
      "Epoch 51, Loss: 1.7336838245391846, Accuracy: 0.7436627745628357\n",
      "Epoch 61, Loss: 1.7055301666259766, Accuracy: 0.7684420347213745\n",
      "Epoch 71, Loss: 1.6846537590026855, Accuracy: 0.7946454286575317\n",
      "Epoch 81, Loss: 1.667818546295166, Accuracy: 0.8094559907913208\n",
      "Epoch 91, Loss: 1.6542634963989258, Accuracy: 0.8279692530632019\n",
      "Epoch 101, Loss: 1.642993688583374, Accuracy: 0.8393620252609253\n",
      "Epoch 111, Loss: 1.6332019567489624, Accuracy: 0.847621738910675\n",
      "Epoch 121, Loss: 1.6253844499588013, Accuracy: 0.8538877964019775\n",
      "Epoch 131, Loss: 1.6184464693069458, Accuracy: 0.8607234358787537\n",
      "Epoch 141, Loss: 1.6123130321502686, Accuracy: 0.8667046427726746\n",
      "Epoch 151, Loss: 1.6076252460479736, Accuracy: 0.8704072833061218\n",
      "Epoch 161, Loss: 1.6054044961929321, Accuracy: 0.8735402822494507\n",
      "Epoch 171, Loss: 1.6007035970687866, Accuracy: 0.8775277733802795\n",
      "Epoch 181, Loss: 1.5975635051727295, Accuracy: 0.8812304139137268\n",
      "Epoch 191, Loss: 1.595576286315918, Accuracy: 0.8826544880867004\n",
      "Predicting...\n",
      "[[   5    8   50   27   62    3    1   18    0   34]\n",
      " [   0   42  102   56  182    3    0   23    0   64]\n",
      " [   0    4  597  290  519   10    2   32    2   93]\n",
      " [   0    5  291  742  220    8    1   24    1   36]\n",
      " [   0   14  230  184 1222   25    1   41    5  127]\n",
      " [   0    4  122  137  213   21    1   18    0   42]\n",
      " [   0    0   70   63  139    0    0    8    0   15]\n",
      " [   0    2  164  124  176   11    0   40    3   88]\n",
      " [   1    1   78   39  144    4    1   13    3   53]\n",
      " [   0   14  265   89  270    8    0   20    2  318]]\n",
      "Accuracy: 36.51%\n",
      "F1-Score: 0.2025\n",
      "embedding: GIVEN\n",
      "model: GCN\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 300)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 51.49116516113281, Accuracy: 0.20022785663604736\n",
      "Epoch 11, Loss: 14.777077674865723, Accuracy: 0.3158644139766693\n",
      "Epoch 21, Loss: 2.2898664474487305, Accuracy: 0.30048418045043945\n",
      "Epoch 31, Loss: 2.139774799346924, Accuracy: 0.3742523491382599\n",
      "Epoch 41, Loss: 2.0671467781066895, Accuracy: 0.30618056654930115\n",
      "Epoch 51, Loss: 2.032506227493286, Accuracy: 0.3019082844257355\n",
      "Epoch 61, Loss: 2.0006449222564697, Accuracy: 0.31330105662345886\n",
      "Epoch 71, Loss: 1.9780563116073608, Accuracy: 0.31358587741851807\n",
      "Epoch 81, Loss: 1.9599508047103882, Accuracy: 0.31244659423828125\n",
      "Epoch 91, Loss: 1.9447293281555176, Accuracy: 0.3147251605987549\n",
      "Epoch 101, Loss: 1.931762456893921, Accuracy: 0.3144403398036957\n",
      "Epoch 111, Loss: 1.9200352430343628, Accuracy: 0.3152948021888733\n",
      "Epoch 121, Loss: 1.9088201522827148, Accuracy: 0.31928226351737976\n",
      "Epoch 131, Loss: 1.8924068212509155, Accuracy: 0.3289661109447479\n",
      "Epoch 141, Loss: 1.8614100217819214, Accuracy: 0.33722585439682007\n",
      "Epoch 151, Loss: 1.847577691078186, Accuracy: 0.35403019189834595\n",
      "Epoch 161, Loss: 1.8356359004974365, Accuracy: 0.3517516255378723\n",
      "Epoch 171, Loss: 1.8196653127670288, Accuracy: 0.3500427305698395\n",
      "Epoch 181, Loss: 1.8015673160552979, Accuracy: 0.35289090871810913\n",
      "Epoch 191, Loss: 1.775521993637085, Accuracy: 0.3560239374637604\n",
      "Predicting...\n",
      "[[   0    0    0    0   28    0    0    0    0  180]\n",
      " [   0    0    1    4  392    0    1    0    0   74]\n",
      " [   0    4  195   59 1139    0   16    0    0  136]\n",
      " [   0    3  389  510  376    0    1    0    0   49]\n",
      " [   0    0    7   12 1787    0    5    0    0   38]\n",
      " [   0    0   10   23  502    0    1    0    0   22]\n",
      " [   0    0    1    3  182    0  104    0    0    5]\n",
      " [   0    0    5   16  553    0    0    0    0   34]\n",
      " [   0    0    5    1  293    0    0    0    0   38]\n",
      " [   0    3    4    9  296    0    0    0    0  674]]\n",
      "Accuracy: 39.93%\n",
      "F1-Score: 0.2277\n",
      "embedding: GIVEN\n",
      "model: GAT\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 300)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 2.2987873554229736, Accuracy: 0.14611221849918365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\modularity_node_embedding\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 1.225242018699646, Accuracy: 0.595841646194458\n",
      "Epoch 21, Loss: 0.9118409156799316, Accuracy: 0.7299914360046387\n",
      "Epoch 31, Loss: 0.7632795572280884, Accuracy: 0.7544859051704407\n",
      "Epoch 41, Loss: 0.6725379824638367, Accuracy: 0.7821133732795715\n",
      "Epoch 51, Loss: 0.6093865633010864, Accuracy: 0.8037596344947815\n",
      "Epoch 61, Loss: 0.5557217597961426, Accuracy: 0.8194246888160706\n",
      "Epoch 71, Loss: 0.5083109736442566, Accuracy: 0.8362289667129517\n",
      "Epoch 81, Loss: 0.4668281674385071, Accuracy: 0.8516092300415039\n",
      "Epoch 91, Loss: 0.4320566654205322, Accuracy: 0.8641412854194641\n",
      "Epoch 101, Loss: 0.39699122309684753, Accuracy: 0.8718313574790955\n",
      "Epoch 111, Loss: 0.36419445276260376, Accuracy: 0.8849330544471741\n",
      "Epoch 121, Loss: 0.3389788568019867, Accuracy: 0.8920535445213318\n",
      "Epoch 131, Loss: 0.31090247631073, Accuracy: 0.9020222425460815\n",
      "Epoch 141, Loss: 0.2741140127182007, Accuracy: 0.9142694473266602\n",
      "Epoch 151, Loss: 0.25018757581710815, Accuracy: 0.9233836531639099\n",
      "Epoch 161, Loss: 0.22367039322853088, Accuracy: 0.9313585758209229\n",
      "Epoch 171, Loss: 0.19754667580127716, Accuracy: 0.9396183490753174\n",
      "Epoch 181, Loss: 0.18950968980789185, Accuracy: 0.9421817064285278\n",
      "Epoch 191, Loss: 0.17057010531425476, Accuracy: 0.9487325549125671\n",
      "Predicting...\n",
      "[[ 197    0    0    0    0    2    0    2    2    5]\n",
      " [  12  358    3    5   17    1    3   44   10   19]\n",
      " [   2    8 1098   72   66   13  114  106   12   58]\n",
      " [   3    6  147 1057   20   13   14   30    8   30]\n",
      " [   6   17   70   12 1629   32   19   38   17    9]\n",
      " [   0    5   47   17   63  359   11   19   29    8]\n",
      " [   0    3   35    4   17    2  221    8    2    3]\n",
      " [   3   16   42   29   38   36    6  383   37   18]\n",
      " [   5   10    8    4   34   16    5   34  187   34]\n",
      " [   5   11   52   20    7    1    4   22    9  855]]\n",
      "Accuracy: 77.46%\n",
      "F1-Score: 0.7450\n",
      "embedding: GIVEN\n",
      "model: GRAPHSAGE\n",
      "Processing...\n",
      "Training...\n",
      "Shape of X_train: (3511, 300)\n",
      "Shape of A_train_tensor: (3511, 3511)\n",
      "Shape of Y_train: (3511, 10)\n",
      "Epoch 1, Loss: 2.3520514965057373, Accuracy: 0.038450583815574646\n",
      "Epoch 11, Loss: 1.938116192817688, Accuracy: 0.5081173181533813\n",
      "Epoch 21, Loss: 1.800396203994751, Accuracy: 0.6716035604476929\n",
      "Epoch 31, Loss: 1.7381749153137207, Accuracy: 0.7035032510757446\n",
      "Epoch 41, Loss: 1.6983813047409058, Accuracy: 0.7314155697822571\n",
      "Epoch 51, Loss: 1.6704716682434082, Accuracy: 0.7542010545730591\n",
      "Epoch 61, Loss: 1.6506624221801758, Accuracy: 0.7801195979118347\n",
      "Epoch 71, Loss: 1.635330080986023, Accuracy: 0.7989177107810974\n",
      "Epoch 81, Loss: 1.6205378770828247, Accuracy: 0.8171461224555969\n",
      "Epoch 91, Loss: 1.608248233795166, Accuracy: 0.8382227420806885\n",
      "Epoch 101, Loss: 1.5954351425170898, Accuracy: 0.8530333042144775\n",
      "Epoch 111, Loss: 1.5840425491333008, Accuracy: 0.8632867932319641\n",
      "Epoch 121, Loss: 1.5768351554870605, Accuracy: 0.8681287169456482\n",
      "Epoch 131, Loss: 1.5668854713439941, Accuracy: 0.8812304139137268\n",
      "Epoch 141, Loss: 1.5592103004455566, Accuracy: 0.8863571882247925\n",
      "Epoch 151, Loss: 1.5517233610153198, Accuracy: 0.8906294703483582\n",
      "Epoch 161, Loss: 1.5471869707107544, Accuracy: 0.8997436761856079\n",
      "Epoch 171, Loss: 1.5389150381088257, Accuracy: 0.9082882404327393\n",
      "Epoch 181, Loss: 1.5375850200653076, Accuracy: 0.9111364483833313\n",
      "Epoch 191, Loss: 1.530644178390503, Accuracy: 0.9136998057365417\n",
      "Predicting...\n",
      "[[ 195    1    1    0    1    1    0    1    0    8]\n",
      " [  14  371    9    4   24    1    1   25    6   17]\n",
      " [   2    8 1297   66   71   11   10   19   10   55]\n",
      " [   3    8  146 1074   25   12    3   24    6   27]\n",
      " [   3   11   47   18 1692   33    5   20   11    9]\n",
      " [   0    3   52   10   50  403    3    7   21    9]\n",
      " [   0    3   71    1   27    3  179    7    1    3]\n",
      " [   5   25   54   15   51   21    0  394   15   28]\n",
      " [  12   11   25    1   20   19    0   21  190   38]\n",
      " [  21   11   33   15    8    2    0    1    9  886]]\n",
      "Accuracy: 81.58%\n",
      "F1-Score: 0.7833\n"
     ]
    }
   ],
   "source": [
    "all_results=[]\n",
    "graph_embeddings_dict={}\n",
    "for emb in embedding_dict.keys():\n",
    "    for clf in classifiers:\n",
    "        results, embedding_matrix = train_and_evaluate(embedding_dict, emb, clf)\n",
    "        all_results.append(results)\n",
    "        key_string= emb + ' with ' + clf\n",
    "        graph_embeddings_dict[key_string]=embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564882c1-290d-4353-bd5e-c3f1b0e8bbc3",
   "metadata": {},
   "source": [
    "## Saving aggregate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbdb2ba7-d382-455c-af5a-acf40267ef6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved as ./wikics_analysis_results/wikics_seed46_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "# Define dataset name and seed\n",
    "dataset_name = \"wikics\"\n",
    "seed_value = SEED\n",
    "\n",
    "# Save as CSV file without sorting\n",
    "filename = f\"{dataset_name}_seed{seed_value}_results.csv\"\n",
    "filename='./wikics_analysis_results/'+filename\n",
    "df.to_csv(filename, index=False)\n",
    "\n",
    "print(f\"Results saved as {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f59fc91-4b52-42f2-8a1c-a723ddbfbced",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings= embedding_dict | graph_embeddings_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8eb75b6-ad8e-45a9-9d74-285d4bac59bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder_dict(original_dict, key_order):\n",
    "    \"\"\"\n",
    "    Reorders a dictionary based on a given list of keys.\n",
    "\n",
    "    Parameters:\n",
    "    - original_dict (dict): The dictionary to reorder.\n",
    "    - key_order (list): The list specifying the desired key order.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A new dictionary with keys ordered as per key_order.\n",
    "    \"\"\"\n",
    "    return {key: original_dict[key] for key in key_order if key in original_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad86bc5f-c709-4c94-ab34-592eaeaa2dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_order = ['random', 'random with gcn', 'random with gat', 'random with graphsage', 'deepwalk', 'deepwalk with gcn', 'deepwalk with gat', 'deepwalk with graphsage', 'node2vec','node2vec with gcn', 'node2vec with gat', 'node2vec with graphsage', 'vgae', 'vgae with gcn', 'vgae with gat', 'vgae with graphsage', 'dgi', 'dgi with gcn', 'dgi with gat', 'dgi with graphsage', 'modularity', 'modularity with gcn', 'modularity with gat', 'modularity with graphsage', 'given', 'given with gcn', 'given with gat', 'given with graphsage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fedc941c-326f-4726-9b05-35eea14d0911",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = reorder_dict(all_embeddings, key_order)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aa0385da-c362-4985-b1eb-e6b181b15c76",
   "metadata": {},
   "source": [
    "visualize_all_embeddings(all_embeddings, labels, label_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
